{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2024-08-18T01:34:36.391623+00:00",
  "repo": "samuel-lucas6/draft-lucas-bkdf",
  "labels": [
    {
      "name": "bug",
      "description": "Something isn't working",
      "color": "d73a4a"
    },
    {
      "name": "documentation",
      "description": "Improvements or additions to documentation",
      "color": "0075ca"
    },
    {
      "name": "duplicate",
      "description": "This issue or pull request already exists",
      "color": "cfd3d7"
    },
    {
      "name": "enhancement",
      "description": "New feature or request",
      "color": "a2eeef"
    },
    {
      "name": "good first issue",
      "description": "Good for newcomers",
      "color": "7057ff"
    },
    {
      "name": "help wanted",
      "description": "Extra attention is needed",
      "color": "008672"
    },
    {
      "name": "invalid",
      "description": "This doesn't seem right",
      "color": "e4e669"
    },
    {
      "name": "question",
      "description": "Further information is requested",
      "color": "d876e3"
    },
    {
      "name": "wontfix",
      "description": "This will not be worked on",
      "color": "ffffff"
    }
  ],
  "issues": [
    {
      "number": 1,
      "id": "I_kwDOK_bi8M563z51",
      "title": "Use UInt64 instead of BigInteger",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/1",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The `other` variable currently uses `BigInteger` before being converted to an `Int32`:\r\n\r\n```c#\r\nfor (int i = 0; i < delta; i++) {\r\n\tIntsToBlock(idxBlock, t, m, i);\r\n\tHash(idxBlock, counter++, salt, idxBlock);\r\n\tvar other = new BigInteger(idxBlock, isUnsigned: true, isBigEndian: false) % spaceCost;\r\n\tHash(buffer[m], counter++, buffer[m], buffer[(int)other]);\r\n}\r\n```\r\n\r\nThis is done for interoperability with [existing implementations](https://github.com/RustCrypto/password-hashes/pull/232), but it seems preferable to use `UInt64` like everywhere else. However, this would mean all implementations would have to be updated in line with the draft.",
      "createdAt": "2024-01-01T09:50:04Z",
      "updatedAt": "2024-05-12T13:54:41Z",
      "closedAt": "2024-05-12T13:54:41Z",
      "comments": []
    },
    {
      "number": 2,
      "id": "I_kwDOK_bi8M5630W8",
      "title": "Provide generic parameters/safe minimums",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/2",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "[OWASP](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html), [TobTu](https://tobtu.com/), the [Argon2 RFC](https://www.rfc-editor.org/rfc/rfc9106.html), etc provide recommended parameters. It would be good to do the same assuming they are realistic, but there's no guidance on parameters from the authors of Balloon. Furthermore, Balloon hasn't been benchmarked properly with different hash functions and parameters to determine suitable recommendations.",
      "createdAt": "2024-01-01T09:54:00Z",
      "updatedAt": "2024-07-14T08:40:11Z",
      "closedAt": "2024-07-07T10:18:07Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "The best way to do this is count the amount of hash block calculations and compare to PBKDF2 because a GPU attacker will be limited by compute instead of bandwidth. Balloon needs to use >1 MiB to start slowing down GPUs. >3 MiB will have a near linear slowdown.\r\n\r\nI'm going to use \"H/block\" to mean \"hash block calculations per block of memory\". This is how many hash blocks are calculated to output a hash. Depending on implementation and settings (I'll use \"delta\" or \"neighbors\" = 3). This is usually 3-17 H/block. Some bad implementations depend on salt length and worse depend on secret data and its length. Defender costs are [paper](https://eprint.iacr.org/2016/027.pdf) (14 H/block), [academic code](https://github.com/henrycg/balloon/blob/master/libballoon/hash_state.c#L145-L178) (3 H/block + 0.5 AES/block), [Rust's](https://github.com/RustCrypto/password-hashes/blob/master/balloon-hash/src/balloon.rs#L143-L201) (14-17+ H/block (depends on salt and secret data lengths)), [Python](https://github.com/nachonavarro/balloon-hashing/blob/master/balloon.py#L61-L94) (14-17+ H/block (depends on salt length)). Attacker costs are paper (8 H/block), academic code (3 H/block), Rust's (8 H/block), Python (8 H/block).\r\n\r\nRough settings for <10 KH/s/GPU (GPU being an RTX 4080 Super or \"2/3 of an RTX 4090\" which should be within a few percent of each other):\r\nBalloon-SHA-256:\r\nAcademic code: `m=256 KiB, t=48`; `m=512 KiB, t=24`; `m=1 MiB, t=12`; `m=2 MiB, t=3-6?`\r\nPaper/Rust's/Python: `m=256 KiB, t=18`; `m=512 KiB, t=9`; `m=1 MiB, t=5`; `m=2 MiB, t=2-3?`\r\n\r\nBalloon-SHA-512:\r\nAcademic code: `m=256 KiB, t=34`; `m=512 KiB, t=17`; `m=1 MiB, t=9`; `m=2 MiB, t=2-4?`\r\nPaper/Rust's/Python: `m=256 KiB, t=13`; `m=512 KiB, t=7`; `m=1 MiB, t=4`; `m=2 MiB, t=1-2?`\r\n\r\nI looked into what the best output size of SHAKE128 for max speed: 248, 520, 792, 1056, and 1328 are 1, 2, 3, 4, and 5 H/block. Best is SHAKE128 with 1328 bits of output but it's not a multiple of a cache line so 512 (2 H/block) or 1024 (4 H/block) would be better. But this puts it at about even with SHA-512 for the attacker. Now the only question is which is faster for the defender. SHAKE128-1024 might be faster even if it's slower than SHA-512 because of the larger block size. Also if the same hash function is used for the deterministic random lookups then SHAKE128-1024 will have an advantage when grabbing 64 bit at a time vs big int math. Note the \"academic code\" is SHA-256 for the hash and AES-128 for the deterministic random lookups. I just remembered that SHAKE128 has an internal parallelism of 5. Which means the slowdown for an attacker doesn't start until >5 MiB but to utilize that there's a performance hit. Yeah... I'll need to implement it to see where it lands. Not that I'm going to do that any time soon.",
          "createdAt": "2024-06-19T01:20:29Z",
          "updatedAt": "2024-06-19T01:20:29Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "After #16, are the academic code recommendations still ok? I've gone for the higher `t=` where you've put a question mark.",
          "createdAt": "2024-07-07T10:19:44Z",
          "updatedAt": "2024-07-07T10:19:44Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "With prefix MAC, there's no change. With HMAC, attacker costs will go from 3 H/block to 4 H/block. These formulas and settings are just until a public optimized GPU cracker is released and benchmarked on an RTX 4080 Super and/or an RTX 4090. Also this assumes that the GPU bottleneck is computational vs bandwidth. Which is true for 3 H/block, SHA2, and current gen GPUs.\r\n\r\nTL;DR (oh and the chart at the end):\r\n```\r\ntimeCost > (rawHashSpeed / 10000 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n\r\nSHA-256: timeCost > (1183275.4267 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\nSHA-512: timeCost > (416536.12 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n```\r\n\r\n----\r\n\r\nHashes calculated given settings (you can assume `attackerCostFill` is 1. This only fails with weird hashes like SHAKE128 with output of more than 1272 bits):\r\n```\r\nattackerCostFill = 1 H/block\r\n\r\ncost = (attackerCost * spaceCost * timeCost + attackerCostFill * spaceCost) * parallelism\r\n```\r\n\r\nGPU cost target for minimum settings \"<10 kH/s/GPU\" (note this \"H\" is password hashes vs raw hashes). Speeds are \"2/3 of an RTX 4090\" from [PBKDF2-HMAC-SHA256](https://gist.github.com/Chick3nman/32e662a5bb63bc4f51b847bb422222fd#file-rtx_4090_v6-2-6-benchmark-L1141-L1145) and [PBKDF2-HMAC-SHA512](https://gist.github.com/Chick3nman/32e662a5bb63bc4f51b847bb422222fd#file-rtx_4090_v6-2-6-benchmark-L1249-L1253) with 1000 iterations. Multiply by 2002 to get `rawHashSpeed`. Note using the raw hash benchmarks will give higher speeds because it can skip the first 1-ish and last 3-ish rounds. Also some of the message schedule calculations can be saved. Some of this is done for PBKDF2. It's just that it can only cheat on 3 out of the 2002 hashes. Note \"2/3 of an RTX 4090\" should be within a few percent of an RTX 4080 Super.\r\n```\r\nrawHashSpeed = 11,832,754,267 H/s (SHA-256*)\r\nrawHashSpeed = 4,165,361,200 H/s (SHA-512*)\r\n\r\ncost > rawHashSpeed / 10000\r\n```\r\n\r\nTogether and solve for `timeCost`:\r\n```\r\n(attackerCost * spaceCost * timeCost + spaceCost) * parallelism > rawHashSpeed / 10000\r\n\r\ntimeCost > (rawHashSpeed / 10000 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n\r\nSHA-256: timeCost > (1183275.4267 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\nSHA-512: timeCost > (416536.12 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n```\r\n\r\n`timeCost` given `attackerCost`, memory size, and `parallelism=1`:\r\n```\r\nSHA-256\r\n   | 256 KiB | 512 KiB | 1 MiB | 2 MiB\r\n---+---------+---------+-------+-------\r\n 3 |    48   |    24   |   12  |    6\r\n 4 |    36   |    18   |    9  |    5\r\n 8 |    18   |     9   |    5  |    3\r\n\r\nSHA-512\r\n   | 256 KiB | 512 KiB | 1 MiB | 2 MiB\r\n---+---------+---------+-------+-------\r\n 3 |    34   |    17   |    9  |    4\r\n 4 |    26   |    13   |    7  |    3\r\n 8 |    13   |     7   |    4  |    2\r\n```",
          "createdAt": "2024-07-09T00:56:23Z",
          "updatedAt": "2024-07-09T00:56:23Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Thanks for those formulas and figures.\r\n\r\n> I'm going to use \"H/block\" to mean \"hash block calculations per block of memory\". This is how many hash blocks are calculated to output a hash.\r\n\r\nI'm getting confused by this definition. For the BalloonCore function, there's 1 hash function call for the Expand phase and 2 for the Mix phase per Balloon block of memory.\r\n\r\nWith prefix MAC, the key is getting padded to the block size, meaning each hash function call is actually 2 internal blocks. With HMAC, there are 2 calls to the hash function, each doing 2 internal blocks because the key is again padded to the block size.\r\n\r\nSo, where is the 3 vs 4 H/block distinction coming from? Is it to do with caching the key? But then prefix MAC should also be 4 because the key takes up its own block to induce a random IV.",
          "createdAt": "2024-07-13T09:15:19Z",
          "updatedAt": "2024-07-13T09:15:19Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Is it to do with caching the key?\r\n\r\nYes. These numbers are what an attacker needs to do. A defender can do the same but it's not necessary. Although this will cause the defender to waste power and time. Or worse like with CVE-2013-1443. It was a PBKDF2 implementation that didn't use cached HMAC and needed to do 4+ blocks every iteration instead of 2+ blocks to add the key then 2 blocks every iteration (the CVE was DoS with long passwords because it needed to hash a long password every iteration).\r\n\r\n----\r\n\r\n```\r\ncurrent = H(pad_block(key) || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\n```\r\n`pad_block(key)` is one block but can be cached thus counts as 0.\r\n\r\n`previous || current`, `rand1 || rand2`, and `rand3 || LE64(counter++)` are one block each (SHA-256, SHA-512 or others but not all hashes work this way). Thus 3 blocks.\r\n\r\n----\r\n\r\n```\r\ncurrent = HMAC(key, || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\n```\r\nWhich is:\r\n```\r\nif (len(key) > block_size) key = H(key)\r\ninner   = H((pad_block(key) ^ inner_pad) || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\ncurrent = H((pad_block(key) ^ outer_pad) || inner)\r\n```\r\n`(pad_block(key) ^ inner_pad)` and `(pad_block(key) ^ outer_pad)` are one block each but can be cached thus counts as 0.\r\n\r\n`previous || current`, `rand1 || rand2`, `rand3 || LE64(counter++)`, and `inner` are one block each. Thus 4 blocks.\r\n\r\n----\r\n\r\nOh right, an attacker doesn't need to calculate the random offsets because 6-12 bytes of bandwidth is much cheaper than a hash calculation. So the attacker caches these too.",
          "createdAt": "2024-07-13T21:32:03Z",
          "updatedAt": "2024-07-13T21:32:03Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Appreciate it. That makes sense. Not sure how I didn't see that; think I was distracted by the non-mixing parts. I'll add the 4 H/block numbers to the document for HMAC-SHA256/HMAC-SHA512.",
          "createdAt": "2024-07-14T08:40:10Z",
          "updatedAt": "2024-07-14T08:40:10Z"
        }
      ]
    },
    {
      "number": 3,
      "id": "I_kwDOK_bi8M56304F",
      "title": "Should delta be fixed?",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/3",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The current draft allows the `delta` parameter to be configured, but this parameter isn't very well explained in the [paper](https://eprint.iacr.org/2016/027) and adds confusion for the user. Some [existing implementations](https://github.com/RustCrypto/password-hashes/tree/master/balloon-hash) don't allow this parameter to be adjusted.",
      "createdAt": "2024-01-01T09:58:25Z",
      "updatedAt": "2024-05-12T11:29:54Z",
      "closedAt": "2024-05-12T11:29:54Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "This will be fixed at 3 in the next version of the draft.",
          "createdAt": "2024-01-20T17:20:23Z",
          "updatedAt": "2024-01-20T17:20:23Z"
        }
      ]
    },
    {
      "number": 4,
      "id": "I_kwDOK_bi8M5632p5",
      "title": "Support key derivation properly",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/4",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Balloon has a limited output length, with the [paper](http://eprint.iacr.org/2016/027) only discussing it in terms of being a password hashing algorithm, not a password-based key derivation function. By contrast, [Wikipedia](https://en.wikipedia.org/wiki/Balloon_hashing) and [NIST](https://csrc.nist.gov/pubs/sp/800/63/b/upd2/final) call it a PBKDF.\r\n\r\nIt would be nice to have longer outputs, like with [scrypt](https://www.rfc-editor.org/rfc/rfc7914) and [Argon2](https://www.rfc-editor.org/rfc/rfc9106.html), without bringing in another primitive. For example, by doing something akin to [NIST's One-Step KDF](https://csrc.nist.gov/pubs/sp/800/56/c/r2/final) or [NIST's KDF in Feedback Mode](https://csrc.nist.gov/pubs/sp/800/108/r1/final). However, XOF functionality should be used when available like NIST's KDF using KMAC but for algorithms such as SHAKE and BLAKE3.\r\n\r\nLike #1, this would be a breaking change for existing implementations.",
      "createdAt": "2024-01-01T10:12:01Z",
      "updatedAt": "2024-05-19T08:47:18Z",
      "closedAt": "2024-05-19T08:47:17Z",
      "comments": []
    },
    {
      "number": 5,
      "id": "I_kwDOK_bi8M5633Pp",
      "title": "Treat Balloon as one algorithm",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/5",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Currently, Balloon and Balloon-M are both specified, with Balloon-M recommended if doing a cryptographic library implementation. I don't like algorithms with multiple variants as it complicates things, so perhaps only Balloon-M should be specified, with Balloon treated as an internal function like what [scrypt](https://www.rfc-editor.org/rfc/rfc7914#section-6) does with `scryptROMix`.",
      "createdAt": "2024-01-01T10:16:39Z",
      "updatedAt": "2024-05-12T11:24:37Z",
      "closedAt": "2024-05-12T11:24:37Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Balloon-M will be renamed to Balloon in the next version of the draft, and the current Balloon function will have to be renamed to something else (e.g. EME for Expand Mix Extract). This will leave one algorithm with support for parallelism.",
          "createdAt": "2024-01-20T17:22:55Z",
          "updatedAt": "2024-01-20T17:22:55Z"
        }
      ]
    },
    {
      "number": 6,
      "id": "I_kwDOK_bi8M56334O",
      "title": "Missing maximum constants",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/6",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The parameters should have a maximum length like in the [Argon2 RFC](https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1). `MAX_SPACECOST`, `MAX_TIMECOST`, `MAX_PARALLELISM`, and `MAX_DELTA` can be added as well as some for the password, salt, and output lengths.",
      "createdAt": "2024-01-01T10:21:35Z",
      "updatedAt": "2024-01-20T17:01:54Z",
      "closedAt": "2024-01-20T17:01:54Z",
      "comments": []
    },
    {
      "number": 7,
      "id": "I_kwDOK_bi8M5634V2",
      "title": "Support for a pepper",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/7",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "A secret key could be supported like in [Argon2](https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1). However, I'm not convinced this is a good idea because encrypting password hashes is [preferable](https://github.com/paragonie/password_lock?tab=readme-ov-file#how-is-this-different-than-peppering), as explained in the Security Considerations section. Supporting this would suggest otherwise, even though it could be useful for key derivation.",
      "createdAt": "2024-01-01T10:25:30Z",
      "updatedAt": "2024-06-23T16:46:32Z",
      "closedAt": "2024-06-23T08:24:34Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "I agree. But you might want to have \"extra salts\". This is useful for PAKEs where you include the user ID, server ID, OPRF salt (or salt), and local/secret salt (if there is one). This is just to avoid collisions for `H(salt || userId || serverId)` like `H(salt || \"user1\" || \"server\")` and `H(salt || \"user\" || \"1server\")` etc. It doesn't matter how you do it but the simplest is `salt' = H(H(salt) || H(userId) || H(serverId) || ... )`.",
          "createdAt": "2024-06-19T01:38:16Z",
          "updatedAt": "2024-06-19T01:38:16Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Could the user not just supply that via the existing salt parameter? They'd obviously have to do proper separation though like encoding the lengths.",
          "createdAt": "2024-06-20T16:43:19Z",
          "updatedAt": "2024-06-20T16:43:19Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "Yes, but having it as an option prevents the user of the API from needing to think about encoding lengths or other proper separation methods and maybe messing it up. Also it gives a common implemented method for this.",
          "createdAt": "2024-06-21T23:28:04Z",
          "updatedAt": "2024-06-21T23:28:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "I hear you. I've not seen any other algorithm do this though. What would the API look like? An array of salts and you append the length of each one?\r\n\r\nAs mentioned in #14, it will probably be easy to support a pepper once the switch from `Hash()` to `PRF()` is made.",
          "createdAt": "2024-06-22T11:35:06Z",
          "updatedAt": "2024-06-22T11:35:06Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "C\r\n```\r\nint balloon_kdf(\r\n\tvoid       *output,   size_t outputSize,\r\n\tconst void *password, size_t passwordSize,\r\n\tconst void *salt,     size_t saltSize,\r\n\tuint32_t    memory, uint32_t iterations, uint32_t parallelism,\r\n\tuint32_t    maxThreads, int wipeMem,\r\n\tsize_t      numExtraSalts = 0, void **extraSalts = NULL, size_t *extraSaltsSizes = NULL);\r\n```\r\nC++\r\n```\r\nint balloon_kdf(\r\n\tvoid *output, size_t outputSize,\r\n\tconst std:string &password, const std:string &salt,\r\n\tuint32_t memory, uint32_t iterations, uint32_t parallelism,\r\n\tuint32_t maxThreads, int wipeMem,\r\n\tconst std:vector<std:string> *extraSalts = NULL);\r\n```\r\nGo\r\n```\r\nfunc balloon_kdf(\r\n\toutputSize int,\r\n\tpassword []byte, salt []byte,\r\n\tmemory int, iterations int, parallelism int,\r\n\tmaxThreads int, wipeMem int,\r\n\textraSalts [][]byte) (output []byte, err error) {\r\n...\r\nkey, _ := balloon_kdf(\r\n\tkeySize,\r\n\t[]byte(\"password\"), []byte(\"salt\"),\r\n\tmemory, iterations, parallelism,\r\n\tmaxThreads, wipeMem,\r\n\tnil)\r\n```",
          "createdAt": "2024-06-23T16:46:31Z",
          "updatedAt": "2024-06-23T16:46:31Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "I_kwDOK_bi8M576e96",
      "title": "Reading about Balloon",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/8",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "I won't understand everything, but I can perhaps try and summarise bits in the Security Considerations section or use findings to inform tweaks. There are [lots](https://eprint.iacr.org/archive/versions/2016/027) of versions of the Balloon paper, so I'm not going to attempt to identify the differences between each one.\r\n\r\n- [x] [Balloon Hashing: Provably Space-Hard Hash Functions with Data-Independent Access Patterns](https://eprint.iacr.org/archive/2016/027/20160114:175127) (original Balloon paper)\r\n- [x] [Balloon Hashing: A Memory-Hard Function Providing Provable Protection Against Sequential Attacks](https://eprint.iacr.org/2016/027) (newest Balloon paper)\r\n- [x] [Balloon Hashing Asiacrypt 2016 talk](https://youtu.be/7vs47CYnDsQ) ([slides](https://people.csail.mit.edu/henrycg/files/academic/pres/asiacrypt16balloon-slides.pdf))\r\n- [ ] [Proof of Space from Stacked Expanders](https://eprint.iacr.org/2016/333)\r\n- [x] [Towards Practical Attacks on Argon2i and Balloon Hashing](https://eprint.iacr.org/2016/759)\r\n- [ ] [Depth-Robust Graphs and Their Cumulative Memory Complexity](https://eprint.iacr.org/2016/875)\r\n- [x] [Depth Robust Graphs and Their Cumulative Memory Complexity Eurocrypt 2017 talk](https://youtu.be/K1BdGP2ffSI) ([slides](https://eurocrypt.iacr.org/2017/slides/B05-depth-robust.pdf))\r\n- [x] [Bandwidth Hard Functions for ASIC Resistance](https://eprint.iacr.org/2017/225)\r\n\r\n[Link](https://eprint.iacr.org/search?q=balloon&title=&authors=&category=&submittedafter=&submittedbefore=&revisedafter=&revisedbefore=) to the full search results on ePrint Archive.\r\n\r\n",
      "createdAt": "2024-01-12T14:10:52Z",
      "updatedAt": "2024-01-27T17:22:45Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 9,
      "id": "I_kwDOK_bi8M58s6qv",
      "title": "Fix the modulo bias",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/9",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "`spaceCost` can be required to be a power of two.",
      "createdAt": "2024-01-20T16:41:51Z",
      "updatedAt": "2024-05-18T10:55:13Z",
      "closedAt": "2024-05-18T10:55:13Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Another approach would be using UInt128 and doing NIST's [Simple Modular Method](https://crypto.stackexchange.com/a/50569). However, that goes against #1 unless UInt64 is replaced with UInt128 everywhere.",
          "createdAt": "2024-02-23T18:40:55Z",
          "updatedAt": "2024-02-23T18:40:55Z"
        }
      ]
    },
    {
      "number": 10,
      "id": "I_kwDOK_bi8M58s-1n",
      "title": "Create a release for the interoperable version",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/10",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Publishing an Internet-Draft for the version interoperable with current implementations will likely cause confusion when breaking changes are made to improve the algorithm. Therefore, I will create a GitHub release instead for future reference if people need backwards compatibility.",
      "createdAt": "2024-01-20T17:18:48Z",
      "updatedAt": "2024-05-12T11:03:34Z",
      "closedAt": "2024-05-12T11:03:34Z",
      "comments": []
    },
    {
      "number": 12,
      "id": "I_kwDOK_bi8M6JW9no",
      "title": "Prevent canonicalization attacks",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/12",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The current concatenation of the password and salt means you can shift bytes between the two parameters and get the same output, which should not be possible.\r\n\r\nThe easiest way to fix this is to append the lengths. Technically, one length will do but both are normally included in practice (e.g., in AEAD schemes).",
      "createdAt": "2024-05-19T08:31:53Z",
      "updatedAt": "2024-05-19T08:50:19Z",
      "closedAt": "2024-05-19T08:50:19Z",
      "comments": []
    },
    {
      "number": 13,
      "id": "I_kwDOK_bi8M6JXD4m",
      "title": "Update the test vectors and encoded hash",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/13",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Once the design has been finalised, these need to be updated since breaking changes have been made.",
      "createdAt": "2024-05-19T09:40:21Z",
      "updatedAt": "2024-07-27T14:17:02Z",
      "closedAt": null,
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "List of hash functions/XOFs to consider including test vectors for, with the ones to probably skip crossed out:\r\n\r\n1. ~BLAKE2s-256~\r\n2. **BLAKE2b-256**\r\n3. **BLAKE2b-512**\r\n4. ~BLAKE2X~\r\n5. **BLAKE3** (256 bit output or XOF, not both)\r\n6. ~SHA-224~\r\n7. **SHA-256**\r\n8. ~SHA-384~\r\n9. **SHA-512**\r\n10. **HMAC-SHA256**\r\n11. ~HMAC-SHA384~\r\n12. **HMAC-SHA512**\r\n17. ~SHA3-224~\r\n18. **SHA3-256**\r\n19. ~SHA3-384~\r\n20. **SHA3-512**\r\n21. ~KMAC128~\r\n22. ~KMAC256~\r\n23. ~KMACXOF128~\r\n24. ~KMACXOF256~\r\n25. **SHAKE128**\r\n14. **SHAKE256**\r\n15. ~cSHAKE128~\r\n16. ~cSHAKE256~\r\n17. ~TurboSHAKE128~\r\n18. ~TurboSHAKE256~\r\n26. **KangarooTwelve**\r\n27. ~MarsupilamiFourteen~\r\n\r\nThat's still over 10 algorithms... Got to hate how many variants there are.",
          "createdAt": "2024-07-27T14:17:02Z",
          "updatedAt": "2024-07-27T14:17:02Z"
        }
      ]
    },
    {
      "number": 14,
      "id": "I_kwDOK_bi8M6M3xDS",
      "title": "Fixes and suggestions",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/14",
      "state": "OPEN",
      "author": "Sc00bz",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L184\r\n`List` should be called `Array`. This can be called an array of arrays or 2D array. Maybe consider `ByteArray` and `BlockArray` which cover the two use cases.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L186-L187\r\nConsider making these 32 bit functions and keeping `LE64(x)` for `counter`. Since these are all defined as 32 bit max integers. Except `MAX_SPACECOST` but that's 0 which is less than `MIN_SPACECOST`. Also related:\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L218\r\nConsider making `spaceCost` an integer 0 to 32 and represents 2**`spaceCost` blocks of memory.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L189\r\nReplace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L194\r\nAll mentions of XOF should be removed except this one because you are converting an XOF into a hash and this part might be missed. Also you are restricting XOFs more so than necessary. XOFs should not output more data than its internal state and should only call the internal base hash function the least amount of times to output anything (e.g. SHAKE128 has an internal state of 1600 bits but will call the internal base hash function more than the minimum for >1344 bits. Thus the max output for SHAKE128 is 1344 bits thus \"SHAKE128-1344\" or is it \"SHAKE128/1344\").\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L240\r\nand\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L285\r\nConsider removing `LE64(length)`. For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove `LE64(length)` then they can just ask for more output. Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. `encryptionKey = Balloon(...); macKey = Balloon(...);` and only do `macKey = Balloon(...); checkMac(macKey, mac, data)`).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L289-L294\r\nConsider changing this to:\r\n```\r\nprevious = buffer[spaceCost - 1]\r\nfor t = 0 to timeCost - 1\r\n    for m = 0 to spaceCost - 1\r\n```\r\nAnd add `previous = buffer[m]` to the end of the loop just after `buffer[m]` is set. A lot of implementations copied the paper verbatim on this or used an if statement. Also you can just return `previous`.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L296\r\nThis should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since `spaceCost` is a power of 2 you could grab the exact number of bits needed which will save calculations. Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (`oprfSalt = hash(password) ** serverSalt`). Maybe something like `Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))`. Also the paper's version is `Hash(LE64(counter++) || salt || LE64(iteration))`. Unless you want the access pattern to be the same across all threads thus enabling SIMD and better bandwidth utilization (but there's no mention of this).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L305\r\nAdd:\r\n* `x % spaceCost` can be done with a bit mask `x & (spaceCost - 1)` because spaceCost is a power of 2.\r\n* Instead of `Ceiling(length / HASH_LEN)` one can do `Floor((length + HASH_LEN - 1) / HASH_LEN)` or `(length + HASH_LEN - 1) / HASH_LEN` where / is integer divide. (Side note: I've seen people include math.h and convert to and from floating points.)\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L338\r\nSee https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/2#issuecomment-2177344918 Note the current draft is 3 H/block for an attacker which is the same for the \"academic code\" minimum settings.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L340\r\nOPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L342\r\nFor password hashing, anything at least 80 bits is fine for anything properly key stretched but NIST would probably want at least 112 bits. BUT obviously there's not much difference in storage space than 128 bit hash. For key derivation, NIST recommends at least 112 bit (because of 3DES).\r\nAlso this contradicts at least 128 bits and at most 256 bits from:\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L374\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L352\r\nvs\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L363\r\nShouldn't that be `$balloon-sha256$` or is it `blake2b-512`?\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L376\r\n\"Similarly, systems MUST check for overly large user-specified parameters (e.g. passwords) to prevent denial-of-service attacks.\" That's only for poorly designed algorithms which Balloon should not be. Currently it hashes the password and salt `parallelism`+1 times. It would be better if it was just once or twice.\r\n\r\nThere are 3 steps to a good key stretching algorithm:\r\n1) Hash inputs: `seed = H(inputs); [seedNoSecrets = H(non-secret-inputs)]`\r\n2) Do work: `work = doWork(settings, seed[, seedNoSecrets])`\r\n3) Output: `out = kdf(work, (inputs or seed), outSize, ...)`\r\n\r\nOne can make a good key stretching algorithm without those steps. This just prevents bad design choices (CVE-2014-9034, CVE-2016-20013) and bad implementations (CVE-2013-1443).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L380\r\n\"authenticated encryption with associated data (AEAD) scheme\" No, authenticated is not needed since it's a password hash that can be replaced. It's more important to be deterministically encrypted. In fact this is the one time ECB is safe to use unless you want to store more than one blocks worth of hash. In that case use NULL-IV-CBC-CTS. This way you can have an HSM that only encrypts and the server can compare encrypted outputs. I just realized this doesn't mention that the only thing that needs to be encrypted is the hash part. Also it should be decoded into binary data before encrypted.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L382\r\nNIST would probably say at least 112 bits and at most 256 bits.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L392\r\nIt's more of a bandwidth vs memory transactions thing with GPUs. GPUs have wide memory buses. 128-384 bits for GeForce RTX 4000 series and Radeon RX 7000 series and historically up to 512 bits of GDDR. Other GPUs with HBM (vs GDDR) have bus widths of 1024 to 5120 bits.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L461\r\nTest Vector 4 has an invalid `spaceCost` of 3.",
      "createdAt": "2024-06-20T03:32:44Z",
      "updatedAt": "2024-08-03T15:56:33Z",
      "closedAt": null,
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Hi Steve, thanks for your feedback; I'll definitely be giving you a mention in the Acknowledgements. I'll start working on these and do a proper reply at the weekend when I'm hopefully feeling fresh.\r\n\r\nSome of those things just haven't been updated whilst other parts have, like the test vectors. One major planned change is switching `Hash()` to `PRF()` to allow the use of HMAC. Then unkeyed hashes would use prefix MAC with the key padded to the block size. It's not ideal trying to cater for every possible hash function.",
          "createdAt": "2024-06-20T16:40:50Z",
          "updatedAt": "2024-06-20T16:40:50Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> One major planned change is switching Hash() to PRF() to allow the use of HMAC.\r\n\r\nThis will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC.\r\n\r\n> Then unkeyed hashes would use prefix MAC with the key padded to the block size.\r\n\r\nAh this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike CVE-2013-1443, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4\\*iterations vs 2\\*iterations+2).",
          "createdAt": "2024-06-21T23:26:35Z",
          "updatedAt": "2024-06-21T23:26:35Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Big thanks for this again. There's some great stuff here.\r\n\r\n> List should be called Array. This can be called an array of arrays or 2D array. Maybe consider ByteArray and BlockArray which cover the two use cases.\r\n\r\nYes, that's a good idea.\r\n\r\n> Consider making these 32 bit functions and keeping LE64(x) for counter. Since these are all defined as 32 bit max integers. Except MAX_SPACECOST but that's 0 which is less than MIN_SPACECOST. Also related:\r\n\r\n`LE64()` was chosen for consistency everywhere, but I agree those could be switched to `LE32()`. The `MAX_` parameters were chosen to avoid the counter overflowing.\r\n\r\n> Consider making spaceCost an integer 0 to 32 and represents 2**spaceCost blocks of memory.\r\n\r\nThat's sensible now it's a power of 2.\r\n\r\n> Replace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n\r\nHow about `the number x`?\r\n\r\n> All mentions of XOF should be removed except this one because you are converting an XOF into a hash and this part might be missed.\r\n\r\nFair point.\r\n\r\n> Also you are restricting XOFs more so than necessary. XOFs should not output more data than its internal state and should only call the internal base hash function the least amount of times to output anything (e.g. SHAKE128 has an internal state of 1600 bits but will call the internal base hash function more than the minimum for >1344 bits. Thus the max output for SHAKE128 is 1344 bits thus \"SHAKE128-1344\" or is it \"SHAKE128/1344\").\r\n\r\nI see what you mean. This was restricted for simplicity in terms of explaining what to do and because there are APIs where you use an XOF as a hash function. As an example, BLAKE3 can be used as a hash function or an XOF, which would lead to two incompatible variants for the same algorithm.\r\n\r\n> Consider removing LE64(length). For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove LE64(length) then they can just ask for more output.\r\n\r\nI get you. This was inspired by Argon2's variable-length hash function.\r\n\r\n> Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. encryptionKey = Balloon(...); macKey = Balloon(...); and only do macKey = Balloon(...); checkMac(macKey, mac, data)).\r\n\r\nI agree. This is actually something I've been discussing with Henry because he proposed getting rid of the KDF and running Balloon repeatedly to generate more output like PBKDF2, which I've argued is a bad idea for this reason/because it reduces the parameters.\r\n\r\n> Consider changing this to:\r\n> previous = buffer[spaceCost - 1]\r\n> for t = 0 to timeCost - 1\r\n>     for m = 0 to spaceCost - 1\r\n> And add previous = buffer[m] to the end of the loop just after buffer[m] is set. A lot of implementations copied the paper verbatim on this or used an if statement. Also you can just return previous.\r\n\r\nGood spot. I'll rearrange this.\r\n\r\n> This should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since spaceCost is a power of 2 you could grab the exact number of bits needed which will save calculations.\r\n\r\nI'm not sure what you mean here. It's written as `pseudorandom = Hash(LE64(counter++) || salt)` because hash APIs output a full hash.\r\n\r\n> Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (oprfSalt = hash(password) ** serverSalt). Maybe something like Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration)).\r\n\r\nThat's an interesting point. That was just from the paper.\r\n\r\n> Also the paper's version is Hash(LE64(counter++) || salt || LE64(iteration)). Unless you want the access pattern to be the same across all threads thus enabling SIMD and better bandwidth utilization (but there's no mention of this).\r\n\r\n`iteration` was added recently rather than having domain separation in the salt, and I managed to miss that.\r\n\r\n> Add:\r\n> x % spaceCost can be done with a bit mask x & (spaceCost - 1) because spaceCost is a power of 2.\r\n> Instead of Ceiling(length / HASH_LEN) one can do Floor((length + HASH_LEN - 1) / HASH_LEN) or (length + HASH_LEN - 1) / HASH_LEN where / is integer divide. (Side note: I've seen people include math.h and convert to and from floating points.)\r\n\r\nI'll add those.\r\n\r\n> See https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/2#issuecomment-2177344918 Note the current draft is 3 H/block for an attacker which is the same for the \"academic code\" minimum settings.\r\n\r\nThanks for investigating that.\r\n\r\n> OPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n\r\nYeah, I haven't thought about PAKEs at all. They're not something I've looked into, and it doesn't sound like they're frequently used. The 128 bits recommendation is following the Argon2 RFC.\r\n\r\n> For password hashing, anything at least 80 bits is fine for anything properly key stretched but NIST would probably want at least 112 bits. BUT obviously there's not much difference in storage space than 128 bit hash. For key derivation, NIST recommends at least 112 bit (because of 3DES).\r\n\r\nThe password hash length recommendation could be changed to 128 bits. I'd prefer to leave the key derivation recommendation as is. These are only recommendations, not MUSTs.\r\n\r\n> Also this contradicts at least 128 bits and at most 256 bits from:\r\n\r\nI don't think that does contradict anything because it's referring to the salt, which I've recommended 128 or 256 bits for before. SHOULD is equivalent to RECOMMENDED, and SHOULD NOT is equivalent to NOT RECOMMENDED, so they're not absolutes again.\r\n\r\n> Shouldn't that be $balloon-sha256$ or is it blake2b-512?\r\n\r\nYep, that hash needs to be updated. It was a SHA-256 example because the Rust implementation, which the draft was originally based on, used SHA-256 test vectors.\r\n\r\n> \"Similarly, systems MUST check for overly large user-specified parameters (e.g. passwords) to prevent denial-of-service attacks.\" That's only for poorly designed algorithms which Balloon should not be. Currently it hashes the password and salt parallelism+1 times. It would be better if it was just once or twice.\r\n\r\nYes, I see that now. That's what people have meant about prehashing the password. The password will only be hashed once when the algorithm is switched to being keyed.\r\n\r\n> \"authenticated encryption with associated data (AEAD) scheme\" No, authenticated is not needed since it's a password hash that can be replaced. It's more important to be deterministically encrypted. In fact this is the one time ECB is safe to use unless you want to store more than one blocks worth of hash. In that case use NULL-IV-CBC-CTS. This way you can have an HSM that only encrypts and the server can compare encrypted outputs. I just realized this doesn't mention that the only thing that needs to be encrypted is the hash part. Also it should be decoded into binary data before encrypted.\r\n\r\nI don't know how this is done in practice, but I've said AEAD schemes because they're more commonly used in general for encryption. I first heard about this idea from [password_lock](https://github.com/paragonie/password_lock), which claims to do authenticated encryption and I think encrypts a string. I can mention that only the hash needs to be encrypted.\r\n\r\n> NIST would probably say at least 112 bits and at most 256 bits.\r\n\r\nThis is only a recommendation, and if NIST wanted to approve this, they could make their own recommendations. I don't want to be recommending anything below 128 bits.\r\n\r\n> It's more of a bandwidth vs memory transactions thing with GPUs. GPUs have wide memory buses. 128-384 bits for GeForce RTX 4000 series and Radeon RX 7000 series and historically up to 512 bits of GDDR. Other GPUs with HBM (vs GDDR) have bus widths of 1024 to 5120 bits.\r\n\r\nYeah, I won't pretend to understand cache hardness. It could do with being properly defined and explained somewhere in the literature. It sounds like you need an understanding of GPU architecture.\r\n\r\n> Test Vector 4 has an invalid spaceCost of 3.\r\n\r\nThe test vectors are from the old Rust implementation so are out of date. They'll be updated when the design is finalised, and it would be good to have test vectors for all the major hash functions, although that will be a pain.\r\n\r\n> This will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC. \r\n\r\n> Ah this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike https://github.com/advisories/GHSA-4c42-4rxm-x6qf, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4*iterations vs 2*iterations+2).\r\n\r\nThe idea is to allow the use of HMAC because that's probably what NIST wants whilst allowing everyone else to use an ordinary hash function/non-approved algorithm instead (e.g., BLAKE2). It's not ideal though because of things like keyed BLAKE2/BLAKE3 vs prefix MAC for BLAKE2/BLAKE3, which may cause confusion/interoperability issues.\r\n\r\nThe plan is to do `key = PRF(emptyKey, password || salt || password.Length || salt.Length)` and then use that key as the key everywhere else, except when computing the pseudorandom bytes since that should be password-independent. That can use an empty key again. This isn't ideal with prefix MAC but is like HKDF-Extract with HMAC.\r\n\r\nThis would allow easily supporting a pepper because that initial `emptyKey` could be the pepper, and it would be restricted to something like 512 bits to avoid HMAC key hashing, which was a HMAC design flaw.",
          "createdAt": "2024-06-22T11:31:03Z",
          "updatedAt": "2024-06-22T11:31:03Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> > Replace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n>\r\n> How about the number x?\r\n\r\nYeah that's fine.\r\n\r\n> > Consider removing LE64(length). For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove LE64(length) then they can just ask for more output.\r\n>\r\n> I get you. This was inspired by Argon2's variable-length hash function.\r\n\r\nPBKDF2 doesn't do this. Which means Balloon doesn't need to do this. And it's better if it doesn't.\r\n\r\n> > Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. encryptionKey = Balloon(...); macKey = Balloon(...); and only do macKey = Balloon(...); checkMac(macKey, mac, data)).\r\n>\r\n> I agree. This is actually something I've been discussing with Henry because he proposed getting rid of the KDF and running Balloon repeatedly to generate more output like PBKDF2, which I've argued is a bad idea for this reason/because it reduces the parameters.\r\n\r\nThat is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n\r\nMicrosoft used `PBKDF2-HMAC-SHA1(pw, salt, iterations:4096, outLen:256 bits)` as a hash because \"it's good enough for WiFi\". But an attacker only needs to calculate the first 160 bits. Doing half the work as a defender.\r\n\r\n1Password used `key || iv = PBKDF2-HMAC-SHA256(pw, salt, iterations:100000, outLen:384 bits)` to decrypt a 256 bit key in CBC mode. Again an attacker only needs the first 256 bits and decrypt the padding and compare to \"\\x10\\x10...\\x10\". Doing half the work as a defender.\r\n\r\nI'm sure there are several others.\r\n\r\n> > This should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since spaceCost is a power of 2 you could grab the exact number of bits needed which will save calculations.\r\n>\r\n> I'm not sure what you mean here. It's written as pseudorandom = Hash(LE64(counter++) || salt) because hash APIs output a full hash.\r\n\r\nOh the counter is the same... OK `counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN)` instead of 0. Or have different counters maybe `H(\"0\" || LE64(counter0++) || ...)` and `H(\"1\" || LE64(counter1++) || ...)`. And give a description or an example like `pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...}` and `pseudorandomStream.popBitsLE(12)` returns 0x321 and the next call returns 0x654.\r\n```\r\ncounter = Ceiling(((3 * spaceCostLog2 * timeCost) << spaceCostLog2) / HASH_BIT_LEN)\r\npseudorandomStream =\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(0) || LE64(iteration) || salt) ||\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(1) || LE64(iteration) || salt) ||\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(2) || LE64(iteration) || salt) ||\r\n    ...\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(counter-1) || LE64(iteration) || salt)\r\n\r\nbuffer[0] = PRF(key, LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(length) || LE64(iteration))\r\nfor m = 1 to spaceCost - 1\r\n    buffer[m] = PRF(key, LE64(counter++) || buffer[m - 1])\r\n\r\nemptyKey = ByteArray(0)\r\nprevious = buffer[spaceCost - 1]\r\nfor t = 0 to timeCost - 1\r\n    for m = 0 to spaceCost - 1\r\n        other1 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        other2 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        other3 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        buffer[m] = PRF(key, LE64(counter++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])\r\n        previous = buffer[m]\r\n```\r\n\r\n> > Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (oprfSalt = hash(password) ** serverSalt). Maybe something like Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration)).\r\n>\r\n> That's an interesting point. That was just from the paper.\r\n\r\nI remember there being a conversation on the PHC mailing list about whether salt should be included for secret independent reads. I remember at least one submission that did this. I'm pretty sure it was determined to be better not to include salt. Also Argon2i doesn't include the salt.\r\n\r\n> > OPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n>\r\n> Yeah, I haven't thought about PAKEs at all. They're not something I've looked into, and it doesn't sound like they're frequently used. The 128 bits recommendation is following the Argon2 RFC.\r\n\r\nWhatsApp, and 1Password use PAKEs. I think also Apple and Signal. The RFC recommends 128 bit salts, but they are very lax on requirements 8 to 2^(32)-1 bytes:\r\n\r\n\"Nonce S, which is a salt for password hashing applications. It MUST have a length not greater than 2^(32)-1 bytes. 16 bytes is RECOMMENDED for password hashing. The salt SHOULD be unique for each password.\" https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1-2.2\r\n\r\n\"Select the salt length. A length of 128 bits is sufficient for all applications but can be reduced to 64 bits in the case of space constraints.\" https://www.rfc-editor.org/rfc/rfc9106.html#section-4-6.7\r\n\r\n> > Also this contradicts at least 128 bits and at most 256 bits from:\r\n>\r\n> I don't think that does contradict anything because it's referring to the salt, which I've recommended 128 or 256 bits for before. SHOULD is equivalent to RECOMMENDED, and SHOULD NOT is equivalent to NOT RECOMMENDED, so they're not absolutes again.\r\n\r\nYeah I read that wrong.\r\n\r\n> > This will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC.\r\n> >\r\n> > Ah this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike https://github.com/advisories/GHSA-4c42-4rxm-x6qf, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4iterations vs 2iterations+2).\r\n>\r\n> The idea is to allow the use of HMAC because that's probably what NIST wants whilst allowing everyone else to use an ordinary hash function/non-approved algorithm instead (e.g., BLAKE2). It's not ideal though because of things like keyed BLAKE2/BLAKE3 vs prefix MAC for BLAKE2/BLAKE3, which may cause confusion/interoperability issues.\r\n>\r\n> The plan is to do key = PRF(emptyKey, password || salt || password.Length || salt.Length) and then use that key as the key everywhere else, except when computing the pseudorandom bytes since that should be password-independent. That can use an empty key again. This isn't ideal with prefix MAC but is like HKDF-Extract with HMAC.\r\n>\r\n> This would allow easily supporting a pepper because that initial emptyKey could be the pepper, and it would be restricted to something like 512 bits to avoid HMAC key hashing, which was a HMAC design flaw.\r\n\r\nPrefix MAC for BLAKE2/BLAKE3 is bad because it doesn't do the block operation until there's more than a block of data. Since the last block can be full. I feel like I'm saying this weirdly. The last block has a flag that states it's the last block and it can be full and no data is added for padding. Thus giving it a full block after initialization it will wait for finish to be called or more data before it mixes the block. So if it was `PRF(key, BE64(counter++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])` then one could `blake2b_update(ctx, ZeroPad(key, 128))`, `blake2b_update(ctx, \"\\0\")`, make a copy of `ctx`, `blake2b_update(ctx, BE56(counter++))`... Or if it was `PRF(key, \"1\" || LE64(counter1++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])` (using two counters like above).\r\n\r\nIt would be best to state that Balloon with prefix MAC is invalid for BLAKE2 and BLAKE3. And that the only valid method is using the built in MAC for BLAKE2 and BLAKE3.",
          "createdAt": "2024-06-23T19:13:33Z",
          "updatedAt": "2024-06-23T19:13:33Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Sorry for my slow replies, got a lot going on at the moment.\r\n\r\n> PBKDF2 doesn't do this. Which means Balloon doesn't need to do this. And it's better if it doesn't.\r\n\r\nYeah, I'll try to remove this at the weekend.\r\n\r\n> That is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n\r\nThanks for the examples. I was aware of 1Password having a problem.\r\n\r\nHowever, it turns out that I've misunderstood what Henry meant. His proposal is actually to grab more bytes/blocks from the final mixed buffer, meaning you don't have to do any extra hashing (no KDF and no rerunning the algorithm).\r\n\r\nOf course, the obvious limitation is that the output length is now limited by the space cost. To get around that, you end up rerunning the Mix phase, which introduces this PBKDF2 footgun again and complicates the code. Another issue might be with collision resistance when parallelism is used.\r\n\r\nI understand the appeal, but I think using a KDF is cleaner. I'm interested to know your thoughts.\r\n\r\n> Oh the counter is the same... OK counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN) instead of 0. Or have different counters maybe H(\"0\" || LE64(counter0++) || ...) and H(\"1\" || LE64(counter1++) || ...). And give a description or an example like pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...} and pseudorandomStream.popBitsLE(12) returns 0x321 and the next call returns 0x654.\r\n\r\nI'm a bit confused by your last sentence, and is the purpose of using separate counters to allow easier precomputation?\r\n\r\n> I remember there being a conversation on the PHC mailing list about whether salt should be included for secret independent reads. I remember at least one submission that did this. I'm pretty sure it was determined to be better not to include salt. Also Argon2i doesn't include the salt.\r\n\r\nI'll try to find that.\r\n\r\n> WhatsApp, and 1Password use PAKEs. I think also Apple and Signal. The RFC recommends 128 bit salts, but they are very lax on requirements 8 to 2^(32)-1 bytes:\r\n\r\nYeah, I can imagine some of the bigger companies using them/them being used more in the future.\r\n\r\nAnd yes, I could add a comment about smaller salts being acceptable, but the wording doesn't prohibit any size of salt from being used currently. It can even be empty because that's what the scrypt and Argon2 RFCs seem to allow.\r\n\r\n> It would be best to state that Balloon with prefix MAC is invalid for BLAKE2 and BLAKE3. And that the only valid method is using the built in MAC for BLAKE2 and BLAKE3.\r\n\r\nI've been planning to make it a bit clearer. I'll say something like _If the hash function supports a key parameter (e.g. BLAKE2 [RFC]), it MUST be used. Otherwise, if the hash function does not have a key parameter, prefix MAC MUST be used..._.",
          "createdAt": "2024-06-27T20:11:01Z",
          "updatedAt": "2024-06-27T20:11:01Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Sorry for my slow replies, got a lot going on at the moment.\r\n\r\nDon't worry about.\r\n\r\n> > That is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n> \r\n> Thanks for the examples. I was aware of 1Password having a problem.\r\n> \r\n> However, it turns out that I've misunderstood what Henry meant. His proposal is actually to grab more bytes/blocks from the final mixed buffer, meaning you don't have to do any extra hashing (no KDF and no rerunning the algorithm).\r\n> \r\n> Of course, the obvious limitation is that the output length is now limited by the space cost. To get around that, you end up rerunning the Mix phase, which introduces this PBKDF2 footgun again and complicates the code. Another issue might be with collision resistance when parallelism is used.\r\n> \r\n> I understand the appeal, but I think using a KDF is cleaner. I'm interested to know your thoughts.\r\n\r\nDefinitely KDF. If you output the first hash from the memory an attacker can skip the last iteration. Also currently it's `4*t*m*p` hash blocks to do the main work and HKDF is `2*ceiling(outputLength/hashLength)+6` hash blocks. Getting `4*t*m*p` down to `~3.2*t*m*p` will benefit much more. Using a pseudorandom stream will remove about `0.8*t*m*p` hash blocks.\r\n\r\n> > Oh the counter is the same... OK counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN) instead of 0. Or have different counters maybe H(\"0\" || LE64(counter0++) || ...) and H(\"1\" || LE64(counter1++) || ...). And give a description or an example like pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...} and pseudorandomStream.popBitsLE(12) returns 0x321 and the next call returns 0x654.\r\n> \r\n> I'm a bit confused by your last sentence\r\n\r\n`pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...}` is defining the example byte data in `pseudorandomStream` and `pseudorandomStream.popBitsLE(12)` gets 12 bits from `pseudorandomStream` which is `0x321 == (0x21 | (0x43 << 8)) & ((1 << 12) - 1)`. Now `pseudorandomStream={0x4 (4 bits), 0x65, 0x87, ...}` and the next `pseudorandomStream.popBitsLE(12)` call returns `0x654 == (0x4 | (0x65 << 4)) & ((1 << 12) - 1)`.\r\n\r\n> and is the purpose of using separate counters to allow easier precomputation?\r\n\r\nNo, I was trying to keep the counters from overlapping or having explicit domain separation with \"0\" and \"1\".\r\n\r\n`X = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN)`\r\n\r\nIf you start the pseudorandom stream counter at `0` it will end at `X-1`. Starting the other counter at `X` will make sure they don't overlap. You could just start both at zero because you're hashing two different fixed length strings (1, 64 bit int and 4, 32 bit ints vs 1, 64 bit int and 5 hashes).",
          "createdAt": "2024-06-28T13:28:12Z",
          "updatedAt": "2024-06-28T13:28:12Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Ok I've addressed most of this feedback now. I think the outstanding points are:\r\n\r\n- `LE32()` for lengths\r\n- `spaceCost` being an integer between 1-32\r\n- Supporting larger outputs with XOFs (the block size/rate)\r\n- A separate counter for the memory accesses\r\n- Update the test vectors (waiting until the design has been finalised)\r\n\r\nI like the `spaceCost` idea from a user's perspective, but it feels a bit awkward to write in the draft. I already wrote it up and reversed the changes.\r\n\r\nI don't understand how the pseudorandom stream idea affects the hash blocks because you still need to compute the same number of hashes surely. If we ignore the separate counter thing, it just feels like moving the computation from inside the loop to before any loops.",
          "createdAt": "2024-07-13T14:29:48Z",
          "updatedAt": "2024-07-13T14:29:48Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> * `LE32()` for lengths\r\n\r\nIt doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n```\r\npseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n                   LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n```\r\nWait a second shouldn't `HASH_LEN` be `HASH_BLOCK_LEN`?\r\n\r\n> * `spaceCost` being an integer between 1-32\r\n>\r\n> [...]\r\n> I like the `spaceCost` idea from a user's perspective, but it feels a bit awkward to write in the draft. I already wrote it up and reversed the changes.\r\n\r\nWell 0-32 because current range is 1 (2\\*\\*0) to 4294967296 (2\\*\\*32). This also doesn't need to be in the specification. It will be like scrypt's `N`. Which some implementations ask for log2 of `N`. I don't know how it's stored in the standard hash...\r\n\r\n```\r\n$7$DU..../....2Q9obwLhin8qvQl6sisAO/$sHayJj/JBdcuD4lJ1AxiwCo9e5XSi8TcINcmyID12i8\r\n```\r\n\r\nOK?... Ahh https://github.com/besser82/libxcrypt/blob/72f75aa370ae96ccd2cc44ea3cf4182d8679ffbe/lib/crypt-scrypt.c#L222 it's log2 of N. That hash decodes to N=1<<b64ToInt(\"D\"), r=b64ToInt(\"U....\"), p=b64ToInt(\"/....\"), salt=\"2Q9obwLhin8qvQl6sisAO/\", hash=\"sHayJj/JBdcuD4lJ1AxiwCo9e5XSi8TcINcmyID12i8\"... I give up I'll just assume it's base64 with \"./0-9A-Za-z\". So N=2\\*\\*15, r=32, p=1. I hate this decoder key BS to figure out the settings. \"Wow you saved 2 characters and wasted an hour of my time\" (and likely several other people's time too).\r\n\r\nI also found a non-standard one that did `N$r$p$salt$hash`.\r\n\r\n> * A separate counter for the memory accesses\r\n>\r\n> [...]\r\n> I don't understand how the pseudorandom stream idea affects the hash blocks because you still need to compute the same number of hashes surely. If we ignore the separate counter thing, it just feels like moving the computation from inside the loop to before any loops.\r\n\r\nUsing the pseudorandom stream idea with SHA-512 and 4 MiB (`spaceCost=2**16`), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks). I benchmarked this on a i5-6500 with DDR4-2133 (average of 10 runs) and it's 368 ms vs 555 ms (SHA-512, 4 MiB (`spaceCost=2**16`), `timeCost=3`) and 643 ms vs 795 ms (SHA-256, 4 MiB (`spaceCost=2**17`), `timeCost=3`). I did 1 MiB to 64 MiB and without the pseudorandom stream it takes 1.57x to 1.45x longer for SHA-512 and 1.29x to 1.14x longer for SHA-256. If you graph these they both start at the maximum at 1 MiB then decrease to the minimum at 16 MiB then increase a little. I also did SHAKE128/1024 and it's 1.33x to 1.24x. I need a better implementation of SHAKE128 that uses AVX2. Also it would be interesting to see how SHA-256 performs with SHA instructions (and SHA-512 when CPUs with those instructions are available).\r\n\r\nOh right, the SHA-256 code encodes `spaceCost`, `timeCost`, `parallelism`, and `iteration` as 32 bit integers. I also did everything in \"hash endian\" to skip conversions. Also I used functions `hash_updateNative(...)` and `hash_finishNative(...)` that take `uint32_t`s or `uint64_t`s depending on hash.",
          "createdAt": "2024-07-13T23:07:53Z",
          "updatedAt": "2024-07-13T23:07:53Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Wait a second shouldn't `HASH_LEN` be `HASH_BLOCK_LEN`?\r\n\r\nOops, no. `PRF(key, message)` I should of noticed the comma vs concatenation since I split the line right there. I was thinking of prefix MAC. Also I said \"this will be 2 blocks\" I meant with cached prefix MAC or cached keyed BLAKE2 etc.",
          "createdAt": "2024-07-14T00:30:04Z",
          "updatedAt": "2024-07-14T00:30:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> It doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n>\r\n> pseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n>                    LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n\r\nIgnoring the key, I think the message should fit in 1 block (40 bytes/320 bits when the block size is 512 bits).\r\n\r\n> Wait a second shouldn't HASH_LEN be HASH_BLOCK_LEN?\r\n\r\nIt's a bit confusing, but I say `you MUST perform prefix MAC and pad the key with zeros to the block size (1024 bits for SHA-512)` for non-keyed hashes in the Conventions and Definitions section.\r\n\r\nThe reason the key is padded to `HASH_LEN` here is because that's what HKDF-Extract does for the salt, and you can't write `HASH_BLOCK_LEN` because that would exceed the BLAKE2 key size, for example. It's problematic to specify when the supported key size varies by algorithm.\r\n\r\n> Well 0-32 because current range is 1 (2**0) to 4294967296 (2**32). This also doesn't need to be in the specification. It will be like scrypt's N. Which some implementations ask for log2 of N.\r\n\r\nYeah, my bad.\r\n\r\nGood point, although it would encourage a consistent API like what's been done with the `associatedData` parameter. Otherwise, I doubt most people would implement it that way. And as you say, the stored hash should be consistent and not difficult to parse.\r\n\r\n> Using the pseudorandom stream idea with SHA-512 and 4 MiB (spaceCost=2**16), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks).\r\n\r\nOh I think I'm getting it now. So, the idea is to use more of each hash rather than using truncated hashes? Then the second part of the idea is to switch from `LE64()` to `LE16()` to get even more random indices out of each hash? Although how is 16 bits enough for a random index when `spaceCost` can be up to 4294967296?",
          "createdAt": "2024-07-14T17:18:47Z",
          "updatedAt": "2024-07-14T17:18:47Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "Just found a bug in my code. It's now faster:\r\n\r\nSHA-512, 4 MiB (`spaceCost=2**16`), `timeCost=3`:\r\n<s>368 ms vs 555 ms</s>\r\n258 ms vs 327 ms\r\n\r\nSHA-256, 4 MiB (`spaceCost=2**17`), `timeCost=3`:\r\n<s>643 ms vs 795 ms</s>\r\n465 ms vs 551 ms\r\n\r\n1 MiB to 64 MiB and without the pseudorandom stream it takes <s>1.57x to 1.45x</s> 1.30x to 1.17x longer for SHA-512 and <s>1.29x to 1.14x</s> 1.22x to 1.08x longer for SHA-256. If you graph these they both start at the maximum at 1 MiB then decrease to the minimum at <s>16</s> 32 MiB then increase a little. I also did SHAKE128/1024 and it's <s>1.33x to 1.24x</s> 1.20x to 1.10x.\r\n\r\n> > It doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n> > pseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n> > LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n> \r\n> Ignoring the key, I think the message should fit in 1 block (40 bytes/320 bits when the block size is 512 bits).\r\n> \r\n> > Wait a second shouldn't HASH_LEN be HASH_BLOCK_LEN?\r\n> \r\n> It's a bit confusing, but I say `you MUST perform prefix MAC and pad the key with zeros to the block size (1024 bits for SHA-512)` for non-keyed hashes in the Conventions and Definitions section.\r\n> \r\n> The reason the key is padded to `HASH_LEN` here is because that's what HKDF-Extract does for the salt, and you can't write `HASH_BLOCK_LEN` because that would exceed the BLAKE2 key size, for example. It's problematic to specify when the supported key size varies by algorithm.\r\n> \r\n\r\nYeah ignore that. I think my brain seg faulted.\r\n\r\n> > Using the pseudorandom stream idea with SHA-512 and 4 MiB (spaceCost=2**16), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks).\r\n> \r\n> Oh I think I'm getting it now. So, the idea is to use more of each hash rather than using truncated hashes? Then the second part of the idea is to switch from `LE64()` to `LE16()` to get even more random indices out of each hash? Although how is 16 bits enough for a random index when `spaceCost` can be up to 4294967296?\r\n\r\nIt's not always 16 bits. It's log 2 of `spaceCost` bits. Here's the code I used... maybe I should just post the whole thing and not just the pseudorandom stream. It has something that I was going to bring up after this issue is closed. Also `HASH_UINT_BLOCK` is 8 for SHA2 and 16 for SHAKE128. `hash_uint` is `uint32_t` for SHA-256 and `uint64_t` for SHA-512 and SHAKE128.\r\n\r\n```\r\nstruct balloonRand_ctx\r\n{\r\n\tuint64_t   streamCounter;\r\n\thash_ctx  *ctx;\r\n\thash_uint *stream;\r\n\thash_uint *streamData;\r\n\thash_uint *mem;\r\n\tuint32_t   memory; // log2(spaceCost)\r\n\tuint32_t   memoryMask; // spaceCost - 1\r\n\tuint32_t   streamDataLeft;\r\n};\r\n\r\nhash_uint *hash_balloonRand(balloonRand_ctx &ctx)\r\n{\r\n\thash_uint *streamData     = ctx.streamData;\r\n\tuint32_t   memory         = ctx.memory;\r\n\tuint32_t   streamDataLeft = ctx.streamDataLeft;\r\n\tsize_t     curPos         = streamDataLeft / (8 * sizeof(hash_uint));\r\n\tuint32_t   bits           = streamDataLeft % (8 * sizeof(hash_uint));\r\n\thash_uint  offset         = streamData[curPos];\r\n\r\n\tif (streamDataLeft < memory)\r\n\t{\r\n\t\t// Hash\r\n\t\tuint64_t streamCounter = ctx.streamCounter;\r\n#ifdef HASH_UINT_IS_64\r\n\t\tctx.stream[1] = streamCounter;\r\n\t\thash_updateNative(ctx.ctx, ctx.stream + 1, 4); // 4 uint64_t's\r\n#else\r\n\t\tctx.stream[0] = (uint32_t) (streamCounter >> 32);\r\n\t\tctx.stream[1] = (uint32_t)  streamCounter;\r\n\t\thash_updateNative(ctx.ctx, ctx.stream, 5); // 5 uint32_t's\r\n#endif\r\n\t\thash_finishNative(ctx.ctx, streamData);\r\n\t\tctx.streamCounter = streamCounter + 1;\r\n\t\tstreamDataLeft += 8 * HASH_SIZE;\r\n\r\n\t\t// Add new stream data\r\n\t\thash_uint tmp  = streamData[HASH_UINT_BLOCK - 1];\r\n\t\toffset        |= tmp << bits;\r\n\r\n\t\t// Update stream data\r\n\t\tstreamData[HASH_UINT_BLOCK - 1] = tmp >> (memory - bits);\r\n\t}\r\n\telse if (bits < memory)\r\n\t{\r\n\t\t// Add stream data\r\n\t\thash_uint tmp  = streamData[curPos - 1];\r\n\t\toffset        |= tmp << bits;\r\n\r\n\t\t// Update stream data\r\n\t\tstreamData[curPos - 1] = tmp >> (memory - bits);\r\n\t}\r\n\telse\r\n\t{\r\n\t\t// Update stream data\r\n\t\tstreamData[curPos] = offset >> memory;\r\n\t}\r\n\tctx.streamDataLeft = streamDataLeft - memory;\r\n\r\n\treturn ctx.mem + HASH_UINT_BLOCK * (offset & ctx.memoryMask);\r\n}\r\n```\r\n```\r\nballoonRand_ctx randCtx;\r\nhash_ctx   ctx2;\r\nhash_uint *mem;\r\nhash_uint  stream[5] = {0, 0, memory, iterations, parallelism};\r\nhash_uint  streamData[HASH_UINT_BLOCK];\r\n\r\nmem = new hash_uint[((size_t) HASH_UINT_BLOCK) << memory];\r\nrandCtx.streamCounter  = 0;\r\nrandCtx.ctx            = &ctx2;\r\nrandCtx.stream         = stream;\r\nrandCtx.streamData     = streamData;\r\nrandCtx.mem            = mem;\r\nrandCtx.memory         = memory;\r\nrandCtx.memoryMask     = (1 << memory) - 1;\r\nrandCtx.streamDataLeft = 0;\r\n\r\n// ...\r\n\r\nhash_uint *other1 = hash_balloonRand(randCtx);\r\nhash_uint *other2 = hash_balloonRand(randCtx);\r\nhash_uint *other3 = hash_balloonRand(randCtx);\r\n```",
          "createdAt": "2024-07-15T06:06:48Z",
          "updatedAt": "2024-07-15T06:06:48Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> spaceCost being an integer between 0-32\r\n\r\nThis is done now. What do you think of the pseudocode for this/encoding `2^spaceCost` rather than `spaceCost`?\r\n\r\n> Supporting larger outputs with XOFs (the block size/rate)\r\n\r\nI've said 1024 bits (just realised there was a typo in that commit where I said 1024 bytes) if using an XOF.\r\n\r\nI'm not especially happy with it. It works for SHAKE/KangarooTwelve/MarsupilamiFourteen but not BLAKE3. I'd say the block size, except that doesn't account for padding/being a multiple of a cache line. Maybe I should say something like the nearest power of 2 to the block size.\r\n\r\n> It's not always 16 bits. It's log 2 of spaceCost bits.\r\n\r\nMy concern is this looks more difficult to implement than just `LE32()` or `LE64()`, and ease of understanding/implementation is one of the main selling points of the algorithm.",
          "createdAt": "2024-07-20T17:04:04Z",
          "updatedAt": "2024-07-20T17:04:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "@Sc00bz I think I've addressed all of your feedback now.\r\n\r\nI'm not doing `log2(spaceCost)` at the moment but switched from `LE64()` to `LE32()` besides the counter and am precomputing the pseudorandom bytes, which should still be a significant performance boost (e.g., 3 random indices per hash => 7, 8, 12, 16, or 32 per hash depending on the hash function/XOF). The downside is the additional complexity and increased memory usage.\r\n\r\n> It has something that I was going to bring up after this issue is closed.\r\n\r\nWhat are you talking about here? Are you happy to close this issue?",
          "createdAt": "2024-07-27T13:58:13Z",
          "updatedAt": "2024-07-27T13:58:13Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "@Sc00bz I found the conversations on the [phc-discussions mailing list](https://lists.openwall.net/phc-discussions/) you were talking about by converting the list to [files](https://github.com/samuel-lucas6/phc-discussions) and searching for `salt`, `password-independent`, `data-independent`, `salt-dependent`, `visitation pattern`, and `access pattern`:\r\n\r\n- [2014/09/19/1](https://lists.openwall.net/phc-discussions/2014/09/19/1): The salt and thus memory access pattern is unique per user. This forces the attacker to compute the access pattern for each entry in the database.\r\n- [2014/09/19/2](https://lists.openwall.net/phc-discussions/2014/09/19/2): If the memory access pattern depends on the salt, it's still known at the time of computation, so the necessary data can still be prefetched from the memory.\r\n- [2014/09/19/4](https://lists.openwall.net/phc-discussions/2014/09/19/4): The salt should be treated as public.\r\n- [2014/09/19/4](https://lists.openwall.net/phc-discussions/2014/09/19/4): A predictable but wildly irregular pattern is harder to optimize but can be optimized. It's typically a situation that urges the good guys to omit optimization (to avoid complexity) but urges attackers to do the optimization and thus gain an advantage. We want optimization options to either not be there or so easy that everybody will implement them. Difficult optimizations mean an advantage to attackers and a disadvantage to defenders.\r\n- [2014/09/19/6](https://lists.openwall.net/phc-discussions/2014/09/19/6): Since for a given salt, all the memory access patterns will be the same, independent of the password guess, I can interleave the memory for several guesses together, so that when I run them in lock-step, I reduce the cache-miss penalty for reading small blocks of memory. That's just one example, but there are a number of them.\r\n- [2014/09/19/6](https://lists.openwall.net/phc-discussions/2014/09/19/6): Some timing information can be leaked. It might be possible for an attacker to detect who has logged in based on a cache timing signature, for example.\r\n- [2015/05/05/15](https://lists.openwall.net/phc-discussions/2015/05/05/15): Some salts/parameters will end up leading to weaker visitation patterns than others. This is unlikely to be critical in the long run, but that would be similar to having \"weak keys\" in cryptographic algorithms. So, if those are avoidable, it would probably be better.\r\n- [2015/07/01/2](https://lists.openwall.net/phc-discussions/2015/07/01/2): Assuming I know the salt, and I am able to observe via a timing side channel the first few memory accesses from hashing the correct password, then I am able to reject an incorrect guess at the password without having pay most of the cost that should be imposed by the work factor, no?\r\n- [2015/07/02/1](https://lists.openwall.net/phc-discussions/2015/07/02/1): An attacker will be able to use cache-timing of salt-derived memory access to determine who is logging in.  I personally am not too concerned about this potential metadata leak.  This is nearly equivalent to what is leaked by hybrid algorithms that have a resistant first loop followed by an unpredictable second loop.\r\n- [2015/07/22/3](https://lists.openwall.net/phc-discussions/2015/07/22/3): All cache-timing measurements will only leak information about the salt, which is usually already known/public.\r\n- [2016/01/12/6](https://lists.openwall.net/phc-discussions/2016/01/12/6): I see the risk that anything chosen randomly might be suboptimal, especially if it depends on a value (like the salt) out of control. I don't like their approach for the same reason.\r\n- [2016/01/12/7](https://lists.openwall.net/phc-discussions/2016/01/12/7): The salt should not be public. You lose defence against important metadata when using the salt in that an attacker with cache-timing can determine when a user logs in.\r\n\r\nPros:\r\n- Unique access pattern per user, whereas the cost parameters may be shared across all users in a database.\r\n- Ordinary salt sizes are less than or equal to the amount of data being hashed when hashing `spaceCost || timeCost || parallelism || parallelismIteration`, so there's typically no performance difference. You can't cache the hash state either way since the counter comes first. Then the salt length doesn't need to be encoded because the counter is fixed in length.\r\n\r\nCons:\r\n- Hard to optimise (compared to a fixed access pattern).\r\n- Might leak who has logged in.\r\n- Certain salts will lead to weaker access patterns.\r\n- The salt is leaked from a cache-timing attack when it shouldn't be public.\r\n\r\nOn reflection, I think removing the salt from the access pattern derivation is a bad idea since the attacker potentially only has to precompute it once for all users in a database. This feels like a bigger problem than the cons.\r\n\r\nI should've done this research prior to making the change really, but the mailing list has no method of searching and there are thousands of emails. It took hours to compile this list.\r\n\r\n---\r\nAs for `log2(spaceCost)` vs `LE32(spaceCost)`, I'm in two minds about this. The former is clearly more efficient, but it's more error prone and annoying to implement. There will be an existing API in standard libraries for `LE32()`, whereas the implementer has to do bit fiddling to grab something like 17 bits. Some values don't evenly divide either.\r\n\r\nBalloon was really designed as an algorithm that just calls other existing functions. That's why the performance isn't optimal.",
          "createdAt": "2024-08-03T15:56:32Z",
          "updatedAt": "2024-08-03T15:56:32Z"
        }
      ]
    },
    {
      "number": 15,
      "id": "I_kwDOK_bi8M6NIim1",
      "title": "Rename the draft/algorithm to Balloon KDF (BKDF)",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/15",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "1. The current naming is confusing because there's Balloon and Balloon Hashing, with the latter implying Balloon isn't a KDF.\r\n2. The design has been modified, so it makes sense to have a different name. Otherwise, people may think this is the same algorithm as other versions/variants.\r\n3. BKDF follows the same naming as PBKDF2 and HKDF in that it's an acronym.",
      "createdAt": "2024-06-22T13:31:46Z",
      "updatedAt": "2024-07-13T09:37:12Z",
      "closedAt": "2024-07-13T09:37:12Z",
      "comments": []
    },
    {
      "number": 16,
      "id": "I_kwDOK_bi8M6NIjK_",
      "title": "Support using HMAC",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/16",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "`Hash(message)` can be replaced with `PRF(key, message)` to support the use of HMAC, which NIST would likely prefer. This then helps with only hashing the password once (discussed in #14) and adding a pepper (#7).\r\n\r\nHowever, to support ordinary hash functions still, prefix MAC can be used, padding the key to the block size to [induce a random IV](https://eprint.iacr.org/2010/264). When the hash function supports a key parameter (e.g., keyed BLAKE2), that can be used instead, which basically does the same thing internally.\r\n\r\nGeneration of the pseudorandom bytes won't use the same key to stay password-independent.",
      "createdAt": "2024-06-22T13:38:04Z",
      "updatedAt": "2024-06-22T14:11:31Z",
      "closedAt": "2024-06-22T14:11:31Z",
      "comments": []
    },
    {
      "number": 17,
      "id": "I_kwDOK_bi8M6NIj9X",
      "title": "Decide whether to keep parallelism",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/17",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Argon2 and scrypt have a parallelism parameter, but it's [often not used](https://crypto.stackexchange.com/a/84085)/[recommended to stay at 1](https://github.com/Sc00bz/bscrypt?tab=readme-ov-file#settings) and [sometimes implemented serially](https://words.filippo.io/the-scrypt-parameters/). More parameters also means more confusion, like setting the cost parameter for bcrypt is much simpler than setting the parameters for memory-hard algorithms.\r\n\r\nOn the other hand, removing this parameter could affect interoperability, with people implementing parallelism themselves. It also doesn't add much code complexity.",
      "createdAt": "2024-06-22T13:46:47Z",
      "updatedAt": "2024-07-27T13:49:27Z",
      "closedAt": "2024-07-27T13:49:27Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "It should be kept.\r\n\r\n> [often not used](https://crypto.stackexchange.com/a/84085)\r\n\r\nThis Stack Exchange answer is wrong. Also parallelism on Argon2 is different than how Balloon's parallelism has been implemented. Argon2 splits memory into lanes and each lane can be run by a different thread. The threads sync four times an iteration. Balloon and scrypt run the base function multiple times in parallel and combine the output.\r\n\r\n> The parallelism was probably one reason why Argon2 won the Password Hashing Competition.\r\n\r\nWe understood that you could just call the base function multiple times in parallel and multiple submissions had parallelism built in. Maybe they mean the specific way Argon2 does parallelism.\r\n\r\n> As of that time, about 50 percent have quad-core processors in their computer. This would suggest to increase the parallelism factor to 8 (twice the number of cores), but for smartphones with a single core this would roughly quadruple the execution time. [...] If you assume that the vast majority of your users have at least two processor cores, you can set the parallelism factor to 4, if you are more careful, to 2.\r\n\r\nThis \"twice the number of cores\" thing is actually bad for Argon2 and originated from the RFC. You should never try to have parallelism greater than the number of cores. Doing twice makes Argon2 half as memory hard. Memory hardness of Argon2 is m/p vs \"m\" for Balloon and scrypt. Also the RFC has bad settings \"m=2 GiB, t=1 or m=64 MiB, t=3\". The first one does over 10x the work of the second. The second should be at least t=32 and really a lot more since it doesn't use as much memory. Accounting for reaching the attacker's max GPU memory bottleneck it should be like t=256 to make them closer.\r\n\r\n----\r\n\r\n> [recommended to stay at 1](https://github.com/Sc00bz/bscrypt?tab=readme-ov-file#settings)\r\n\r\nIt's a little nuanced (note it doesn't mention client side since I assumed most will do p=1, 2, 4, or cores. I guess I should fix it):\r\n* Server side hashing or \"I don't know\": p=1\r\n* Server side hashing with queuing system: p<=cores (test for best p)\r\n* Client side KDF: p=2, 4, 6, 8, or cores (are good choices and set max threads to ceiling(p/ceiling(p/cores)) basically you'd want to run 4 threads for p=8 instead of 6 threads on 6 core CPUs) \\*\r\n\r\n\"Cores\" meaning probably just performance cores but this is another can of worms. Also with scrypt you can use p as a time parameter.\r\n\r\n\\* Advice on parallelism is not for Argon2. For Argon2, set p=1, 2, maybe 4, or cores (set max threads to ceiling(p/ceiling(p/cores))). Since you want to be sure that p<=cores. Otherwise you give the attacker an advantage.\r\n\r\n----\r\n\r\n> [sometimes implemented serially](https://words.filippo.io/the-scrypt-parameters/)\r\n\r\nThat's only for scrypt because everyone uses the official code or rewrites that copying the lack threads. Argon2's [official code can spawn threads](https://github.com/P-H-C/phc-winner-argon2/blob/master/src/core.c#L291) and most uses have threads.",
          "createdAt": "2024-06-23T20:09:27Z",
          "updatedAt": "2024-06-23T20:09:27Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Thanks for the info. What I was getting at with the first link is that libsodium limits the parallelism to 1 for hashing. The parallelism recommendation can perhaps be reworded again, although it gets quite complicated to explain. I know only scrypt does it serially, and it would be good to keep it that way. I don't see any point promoting that for Balloon.\r\n\r\nAnd I forgot to say that I'm happy to keep parallelism. I don't think it complicates the code much. Other people may disagree/think fewer parameters is best.",
          "createdAt": "2024-06-27T20:17:07Z",
          "updatedAt": "2024-06-27T20:19:30Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "I thought that libsodium used threads for Argon2 (just look you're right). I thought PHP used libsodium for Argon2, but it looks like they use a different implementation because PHP's Argon2 uses threads.\r\n\r\nFor fewer parameters, you could define a simplified API function for Balloon:\r\n```\r\nballoon_hash(pw, m, t, p, extraSalts, pepper)\r\nballoon_verify(hash, pw, extraSalts, pepper)\r\nballoon_kdf(pw, salt, m, t, p, extraSalts, pepper)\r\n\r\nballoon_hashSimple(pw, cost)      // convert cost into m and t and calls balloon_hash(pw, m, t, 1, NULL, NULL)\r\nballoon_verifySimple(hash, pw)    //                               calls balloon_verify(hash, pw, NULL, NULL)\r\nballoon_kdfSimple(pw, salt, cost) // convert cost into m and t and calls balloon_kdf(pw, salt, m, t, 2, NULL, NULL)\r\n```\r\n\r\nFor \"convert cost into m and t\", you could do something like this (increasing cost by 1 increases the costs by a factor of about square root 2):\r\n```\r\nm = 1 << (cost / 2 + 14)\r\nt = 5 + 2 * (cost % 2) // 5 * 2^0.5 ~ 7.071\r\n```\r\nOr instead of cost have m and t. Or pick m to be 2 MiB for hashing and 8 MiB for KDF (or something) and instead of cost have t.",
          "createdAt": "2024-06-28T13:58:41Z",
          "updatedAt": "2024-06-28T13:58:41Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "I'm going to close this because I think it's sensible to keep parallelism. If anyone disagrees, feel free to reopen this issue.",
          "createdAt": "2024-07-27T13:49:27Z",
          "updatedAt": "2024-07-27T13:49:27Z"
        }
      ]
    },
    {
      "number": 18,
      "id": "I_kwDOK_bi8M6NRZSA",
      "title": "Support associated data",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/18",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "As discussed in #7:\r\n\r\n> I agree. But you might want to have \"extra salts\". This is useful for PAKEs where you include the user ID, server ID, OPRF salt (or salt), and local/secret salt (if there is one). This is just to avoid collisions for H(salt || userId || serverId) like H(salt || \"user1\" || \"server\") and H(salt || \"user\" || \"1server\") etc. It doesn't matter how you do it but the simplest is salt' = H(H(salt) || H(userId) || H(serverId) || ... ).\r\n\r\n> Yes, but having it as an option prevents the user of the API from needing to think about encoding lengths or other proper separation methods and maybe messing it up. Also it gives a common implemented method for this.\r\n\r\nIt adds a little complexity and not sure how to define the max lengths, like the max number of associated data parameters and the max length of each. The length encoding would also need to be changed to keep the loop code tidy. For example:\r\n\r\n```\r\nkey = PRF(key, LE64(password.Length) || password || LE64(salt.Length) || salt || LE64(associatedData1.Length) || associatedData1 || ...)\r\n```",
      "createdAt": "2024-06-24T12:38:47Z",
      "updatedAt": "2024-07-13T14:04:15Z",
      "closedAt": "2024-07-13T14:04:15Z",
      "comments": []
    }
  ],
  "pulls": [
    {
      "number": 11,
      "id": "PR_kwDOK_bi8M5nra-D",
      "title": "Add implementations for Dart, Julia, Kotlin, Ruby",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/pull/11",
      "state": "MERGED",
      "author": "elliotwutingfeng",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "I've implemented Balloon in Dart, Julia, Kotlin, and Ruby. Mostly as programming exercises to familiarise myself with said languages. They are all direct ports of [nachonavarro/balloon-hashing](https://github.com/nachonavarro/balloon-hashing). Feel free to include them in the README.",
      "createdAt": "2024-02-22T18:11:59Z",
      "updatedAt": "2024-02-23T18:41:17Z",
      "baseRepository": "samuel-lucas6/draft-lucas-bkdf",
      "baseRefName": "main",
      "baseRefOid": "de520e78f3fb57cbbbb5b150d9a5d39227c74f21",
      "headRepository": "elliotwutingfeng/draft-lucas-balloon-hashing",
      "headRefName": "patch-1",
      "headRefOid": "2b8021f9f66ad95136376375d3ff6b11c3aaf59c",
      "closedAt": "2024-02-23T18:33:58Z",
      "mergedAt": "2024-02-23T18:33:58Z",
      "mergedBy": "samuel-lucas6",
      "mergeCommit": {
        "oid": "aebec5f69d1fc31108afa098a5152143d2bab61b"
      },
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Awesome, sorry I missed them.\r\n\r\nPlease keep an eye on this repository because there will eventually be breaking changes to the algorithm.",
          "createdAt": "2024-02-23T18:33:27Z",
          "updatedAt": "2024-02-23T18:33:27Z"
        }
      ],
      "reviews": []
    }
  ]
}