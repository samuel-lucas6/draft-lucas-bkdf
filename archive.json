{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2024-12-15T01:56:01.381038+00:00",
  "repo": "samuel-lucas6/draft-lucas-bkdf",
  "labels": [
    {
      "name": "bug",
      "description": "Something isn't working",
      "color": "d73a4a"
    },
    {
      "name": "documentation",
      "description": "Improvements or additions to documentation",
      "color": "0075ca"
    },
    {
      "name": "duplicate",
      "description": "This issue or pull request already exists",
      "color": "cfd3d7"
    },
    {
      "name": "enhancement",
      "description": "New feature or request",
      "color": "a2eeef"
    },
    {
      "name": "good first issue",
      "description": "Good for newcomers",
      "color": "7057ff"
    },
    {
      "name": "help wanted",
      "description": "Extra attention is needed",
      "color": "008672"
    },
    {
      "name": "invalid",
      "description": "This doesn't seem right",
      "color": "e4e669"
    },
    {
      "name": "question",
      "description": "Further information is requested",
      "color": "d876e3"
    },
    {
      "name": "wontfix",
      "description": "This will not be worked on",
      "color": "ffffff"
    }
  ],
  "issues": [
    {
      "number": 1,
      "id": "I_kwDOK_bi8M563z51",
      "title": "Use UInt64 instead of BigInteger",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/1",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The `other` variable currently uses `BigInteger` before being converted to an `Int32`:\r\n\r\n```c#\r\nfor (int i = 0; i < delta; i++) {\r\n\tIntsToBlock(idxBlock, t, m, i);\r\n\tHash(idxBlock, counter++, salt, idxBlock);\r\n\tvar other = new BigInteger(idxBlock, isUnsigned: true, isBigEndian: false) % spaceCost;\r\n\tHash(buffer[m], counter++, buffer[m], buffer[(int)other]);\r\n}\r\n```\r\n\r\nThis is done for interoperability with [existing implementations](https://github.com/RustCrypto/password-hashes/pull/232), but it seems preferable to use `UInt64` like everywhere else. However, this would mean all implementations would have to be updated in line with the draft.",
      "createdAt": "2024-01-01T09:50:04Z",
      "updatedAt": "2024-05-12T13:54:41Z",
      "closedAt": "2024-05-12T13:54:41Z",
      "comments": []
    },
    {
      "number": 2,
      "id": "I_kwDOK_bi8M5630W8",
      "title": "Provide generic parameters/safe minimums",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/2",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "[OWASP](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html), [TobTu](https://tobtu.com/), the [Argon2 RFC](https://www.rfc-editor.org/rfc/rfc9106.html), etc provide recommended parameters. It would be good to do the same assuming they are realistic, but there's no guidance on parameters from the authors of Balloon. Furthermore, Balloon hasn't been benchmarked properly with different hash functions and parameters to determine suitable recommendations.",
      "createdAt": "2024-01-01T09:54:00Z",
      "updatedAt": "2024-07-14T08:40:11Z",
      "closedAt": "2024-07-07T10:18:07Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "The best way to do this is count the amount of hash block calculations and compare to PBKDF2 because a GPU attacker will be limited by compute instead of bandwidth. Balloon needs to use >1 MiB to start slowing down GPUs. >3 MiB will have a near linear slowdown.\r\n\r\nI'm going to use \"H/block\" to mean \"hash block calculations per block of memory\". This is how many hash blocks are calculated to output a hash. Depending on implementation and settings (I'll use \"delta\" or \"neighbors\" = 3). This is usually 3-17 H/block. Some bad implementations depend on salt length and worse depend on secret data and its length. Defender costs are [paper](https://eprint.iacr.org/2016/027.pdf) (14 H/block), [academic code](https://github.com/henrycg/balloon/blob/master/libballoon/hash_state.c#L145-L178) (3 H/block + 0.5 AES/block), [Rust's](https://github.com/RustCrypto/password-hashes/blob/master/balloon-hash/src/balloon.rs#L143-L201) (14-17+ H/block (depends on salt and secret data lengths)), [Python](https://github.com/nachonavarro/balloon-hashing/blob/master/balloon.py#L61-L94) (14-17+ H/block (depends on salt length)). Attacker costs are paper (8 H/block), academic code (3 H/block), Rust's (8 H/block), Python (8 H/block).\r\n\r\nRough settings for <10 KH/s/GPU (GPU being an RTX 4080 Super or \"2/3 of an RTX 4090\" which should be within a few percent of each other):\r\nBalloon-SHA-256:\r\nAcademic code: `m=256 KiB, t=48`; `m=512 KiB, t=24`; `m=1 MiB, t=12`; `m=2 MiB, t=3-6?`\r\nPaper/Rust's/Python: `m=256 KiB, t=18`; `m=512 KiB, t=9`; `m=1 MiB, t=5`; `m=2 MiB, t=2-3?`\r\n\r\nBalloon-SHA-512:\r\nAcademic code: `m=256 KiB, t=34`; `m=512 KiB, t=17`; `m=1 MiB, t=9`; `m=2 MiB, t=2-4?`\r\nPaper/Rust's/Python: `m=256 KiB, t=13`; `m=512 KiB, t=7`; `m=1 MiB, t=4`; `m=2 MiB, t=1-2?`\r\n\r\nI looked into what the best output size of SHAKE128 for max speed: 248, 520, 792, 1056, and 1328 are 1, 2, 3, 4, and 5 H/block. Best is SHAKE128 with 1328 bits of output but it's not a multiple of a cache line so 512 (2 H/block) or 1024 (4 H/block) would be better. But this puts it at about even with SHA-512 for the attacker. Now the only question is which is faster for the defender. SHAKE128-1024 might be faster even if it's slower than SHA-512 because of the larger block size. Also if the same hash function is used for the deterministic random lookups then SHAKE128-1024 will have an advantage when grabbing 64 bit at a time vs big int math. Note the \"academic code\" is SHA-256 for the hash and AES-128 for the deterministic random lookups. I just remembered that SHAKE128 has an internal parallelism of 5. Which means the slowdown for an attacker doesn't start until >5 MiB but to utilize that there's a performance hit. Yeah... I'll need to implement it to see where it lands. Not that I'm going to do that any time soon.",
          "createdAt": "2024-06-19T01:20:29Z",
          "updatedAt": "2024-06-19T01:20:29Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "After #16, are the academic code recommendations still ok? I've gone for the higher `t=` where you've put a question mark.",
          "createdAt": "2024-07-07T10:19:44Z",
          "updatedAt": "2024-07-07T10:19:44Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "With prefix MAC, there's no change. With HMAC, attacker costs will go from 3 H/block to 4 H/block. These formulas and settings are just until a public optimized GPU cracker is released and benchmarked on an RTX 4080 Super and/or an RTX 4090. Also this assumes that the GPU bottleneck is computational vs bandwidth. Which is true for 3 H/block, SHA2, and current gen GPUs.\r\n\r\nTL;DR (oh and the chart at the end):\r\n```\r\ntimeCost > (rawHashSpeed / 10000 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n\r\nSHA-256: timeCost > (1183275.4267 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\nSHA-512: timeCost > (416536.12 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n```\r\n\r\n----\r\n\r\nHashes calculated given settings (you can assume `attackerCostFill` is 1. This only fails with weird hashes like SHAKE128 with output of more than 1272 bits):\r\n```\r\nattackerCostFill = 1 H/block\r\n\r\ncost = (attackerCost * spaceCost * timeCost + attackerCostFill * spaceCost) * parallelism\r\n```\r\n\r\nGPU cost target for minimum settings \"<10 kH/s/GPU\" (note this \"H\" is password hashes vs raw hashes). Speeds are \"2/3 of an RTX 4090\" from [PBKDF2-HMAC-SHA256](https://gist.github.com/Chick3nman/32e662a5bb63bc4f51b847bb422222fd#file-rtx_4090_v6-2-6-benchmark-L1141-L1145) and [PBKDF2-HMAC-SHA512](https://gist.github.com/Chick3nman/32e662a5bb63bc4f51b847bb422222fd#file-rtx_4090_v6-2-6-benchmark-L1249-L1253) with 1000 iterations. Multiply by 2002 to get `rawHashSpeed`. Note using the raw hash benchmarks will give higher speeds because it can skip the first 1-ish and last 3-ish rounds. Also some of the message schedule calculations can be saved. Some of this is done for PBKDF2. It's just that it can only cheat on 3 out of the 2002 hashes. Note \"2/3 of an RTX 4090\" should be within a few percent of an RTX 4080 Super.\r\n```\r\nrawHashSpeed = 11,832,754,267 H/s (SHA-256*)\r\nrawHashSpeed = 4,165,361,200 H/s (SHA-512*)\r\n\r\ncost > rawHashSpeed / 10000\r\n```\r\n\r\nTogether and solve for `timeCost`:\r\n```\r\n(attackerCost * spaceCost * timeCost + spaceCost) * parallelism > rawHashSpeed / 10000\r\n\r\ntimeCost > (rawHashSpeed / 10000 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n\r\nSHA-256: timeCost > (1183275.4267 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\nSHA-512: timeCost > (416536.12 / parallelism - spaceCost) / (attackerCost * spaceCost)\r\n```\r\n\r\n`timeCost` given `attackerCost`, memory size, and `parallelism=1`:\r\n```\r\nSHA-256\r\n   | 256 KiB | 512 KiB | 1 MiB | 2 MiB\r\n---+---------+---------+-------+-------\r\n 3 |    48   |    24   |   12  |    6\r\n 4 |    36   |    18   |    9  |    5\r\n 8 |    18   |     9   |    5  |    3\r\n\r\nSHA-512\r\n   | 256 KiB | 512 KiB | 1 MiB | 2 MiB\r\n---+---------+---------+-------+-------\r\n 3 |    34   |    17   |    9  |    4\r\n 4 |    26   |    13   |    7  |    3\r\n 8 |    13   |     7   |    4  |    2\r\n```",
          "createdAt": "2024-07-09T00:56:23Z",
          "updatedAt": "2024-07-09T00:56:23Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Thanks for those formulas and figures.\r\n\r\n> I'm going to use \"H/block\" to mean \"hash block calculations per block of memory\". This is how many hash blocks are calculated to output a hash.\r\n\r\nI'm getting confused by this definition. For the BalloonCore function, there's 1 hash function call for the Expand phase and 2 for the Mix phase per Balloon block of memory.\r\n\r\nWith prefix MAC, the key is getting padded to the block size, meaning each hash function call is actually 2 internal blocks. With HMAC, there are 2 calls to the hash function, each doing 2 internal blocks because the key is again padded to the block size.\r\n\r\nSo, where is the 3 vs 4 H/block distinction coming from? Is it to do with caching the key? But then prefix MAC should also be 4 because the key takes up its own block to induce a random IV.",
          "createdAt": "2024-07-13T09:15:19Z",
          "updatedAt": "2024-07-13T09:15:19Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Is it to do with caching the key?\r\n\r\nYes. These numbers are what an attacker needs to do. A defender can do the same but it's not necessary. Although this will cause the defender to waste power and time. Or worse like with CVE-2013-1443. It was a PBKDF2 implementation that didn't use cached HMAC and needed to do 4+ blocks every iteration instead of 2+ blocks to add the key then 2 blocks every iteration (the CVE was DoS with long passwords because it needed to hash a long password every iteration).\r\n\r\n----\r\n\r\n```\r\ncurrent = H(pad_block(key) || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\n```\r\n`pad_block(key)` is one block but can be cached thus counts as 0.\r\n\r\n`previous || current`, `rand1 || rand2`, and `rand3 || LE64(counter++)` are one block each (SHA-256, SHA-512 or others but not all hashes work this way). Thus 3 blocks.\r\n\r\n----\r\n\r\n```\r\ncurrent = HMAC(key, || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\n```\r\nWhich is:\r\n```\r\nif (len(key) > block_size) key = H(key)\r\ninner   = H((pad_block(key) ^ inner_pad) || previous || current || rand1 || rand2 || rand3 || LE64(counter++))\r\ncurrent = H((pad_block(key) ^ outer_pad) || inner)\r\n```\r\n`(pad_block(key) ^ inner_pad)` and `(pad_block(key) ^ outer_pad)` are one block each but can be cached thus counts as 0.\r\n\r\n`previous || current`, `rand1 || rand2`, `rand3 || LE64(counter++)`, and `inner` are one block each. Thus 4 blocks.\r\n\r\n----\r\n\r\nOh right, an attacker doesn't need to calculate the random offsets because 6-12 bytes of bandwidth is much cheaper than a hash calculation. So the attacker caches these too.",
          "createdAt": "2024-07-13T21:32:03Z",
          "updatedAt": "2024-07-13T21:32:03Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Appreciate it. That makes sense. Not sure how I didn't see that; think I was distracted by the non-mixing parts. I'll add the 4 H/block numbers to the document for HMAC-SHA256/HMAC-SHA512.",
          "createdAt": "2024-07-14T08:40:10Z",
          "updatedAt": "2024-07-14T08:40:10Z"
        }
      ]
    },
    {
      "number": 3,
      "id": "I_kwDOK_bi8M56304F",
      "title": "Should delta be fixed?",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/3",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The current draft allows the `delta` parameter to be configured, but this parameter isn't very well explained in the [paper](https://eprint.iacr.org/2016/027) and adds confusion for the user. Some [existing implementations](https://github.com/RustCrypto/password-hashes/tree/master/balloon-hash) don't allow this parameter to be adjusted.",
      "createdAt": "2024-01-01T09:58:25Z",
      "updatedAt": "2024-05-12T11:29:54Z",
      "closedAt": "2024-05-12T11:29:54Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "This will be fixed at 3 in the next version of the draft.",
          "createdAt": "2024-01-20T17:20:23Z",
          "updatedAt": "2024-01-20T17:20:23Z"
        }
      ]
    },
    {
      "number": 4,
      "id": "I_kwDOK_bi8M5632p5",
      "title": "Support key derivation properly",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/4",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Balloon has a limited output length, with the [paper](http://eprint.iacr.org/2016/027) only discussing it in terms of being a password hashing algorithm, not a password-based key derivation function. By contrast, [Wikipedia](https://en.wikipedia.org/wiki/Balloon_hashing) and [NIST](https://csrc.nist.gov/pubs/sp/800/63/b/upd2/final) call it a PBKDF.\r\n\r\nIt would be nice to have longer outputs, like with [scrypt](https://www.rfc-editor.org/rfc/rfc7914) and [Argon2](https://www.rfc-editor.org/rfc/rfc9106.html), without bringing in another primitive. For example, by doing something akin to [NIST's One-Step KDF](https://csrc.nist.gov/pubs/sp/800/56/c/r2/final) or [NIST's KDF in Feedback Mode](https://csrc.nist.gov/pubs/sp/800/108/r1/final). However, XOF functionality should be used when available like NIST's KDF using KMAC but for algorithms such as SHAKE and BLAKE3.\r\n\r\nLike #1, this would be a breaking change for existing implementations.",
      "createdAt": "2024-01-01T10:12:01Z",
      "updatedAt": "2024-05-19T08:47:18Z",
      "closedAt": "2024-05-19T08:47:17Z",
      "comments": []
    },
    {
      "number": 5,
      "id": "I_kwDOK_bi8M5633Pp",
      "title": "Treat Balloon as one algorithm",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/5",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Currently, Balloon and Balloon-M are both specified, with Balloon-M recommended if doing a cryptographic library implementation. I don't like algorithms with multiple variants as it complicates things, so perhaps only Balloon-M should be specified, with Balloon treated as an internal function like what [scrypt](https://www.rfc-editor.org/rfc/rfc7914#section-6) does with `scryptROMix`.",
      "createdAt": "2024-01-01T10:16:39Z",
      "updatedAt": "2024-05-12T11:24:37Z",
      "closedAt": "2024-05-12T11:24:37Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Balloon-M will be renamed to Balloon in the next version of the draft, and the current Balloon function will have to be renamed to something else (e.g. EME for Expand Mix Extract). This will leave one algorithm with support for parallelism.",
          "createdAt": "2024-01-20T17:22:55Z",
          "updatedAt": "2024-01-20T17:22:55Z"
        }
      ]
    },
    {
      "number": 6,
      "id": "I_kwDOK_bi8M56334O",
      "title": "Missing maximum constants",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/6",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The parameters should have a maximum length like in the [Argon2 RFC](https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1). `MAX_SPACECOST`, `MAX_TIMECOST`, `MAX_PARALLELISM`, and `MAX_DELTA` can be added as well as some for the password, salt, and output lengths.",
      "createdAt": "2024-01-01T10:21:35Z",
      "updatedAt": "2024-01-20T17:01:54Z",
      "closedAt": "2024-01-20T17:01:54Z",
      "comments": []
    },
    {
      "number": 7,
      "id": "I_kwDOK_bi8M5634V2",
      "title": "Support for a pepper",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/7",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "A secret key could be supported like in [Argon2](https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1). However, I'm not convinced this is a good idea because encrypting password hashes is [preferable](https://github.com/paragonie/password_lock?tab=readme-ov-file#how-is-this-different-than-peppering), as explained in the Security Considerations section. Supporting this would suggest otherwise, even though it could be useful for key derivation.",
      "createdAt": "2024-01-01T10:25:30Z",
      "updatedAt": "2024-11-16T12:19:51Z",
      "closedAt": "2024-06-23T08:24:34Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "I agree. But you might want to have \"extra salts\". This is useful for PAKEs where you include the user ID, server ID, OPRF salt (or salt), and local/secret salt (if there is one). This is just to avoid collisions for `H(salt || userId || serverId)` like `H(salt || \"user1\" || \"server\")` and `H(salt || \"user\" || \"1server\")` etc. It doesn't matter how you do it but the simplest is `salt' = H(H(salt) || H(userId) || H(serverId) || ... )`.",
          "createdAt": "2024-06-19T01:38:16Z",
          "updatedAt": "2024-06-19T01:38:16Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Could the user not just supply that via the existing salt parameter? They'd obviously have to do proper separation though like encoding the lengths.",
          "createdAt": "2024-06-20T16:43:19Z",
          "updatedAt": "2024-06-20T16:43:19Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "Yes, but having it as an option prevents the user of the API from needing to think about encoding lengths or other proper separation methods and maybe messing it up. Also it gives a common implemented method for this.",
          "createdAt": "2024-06-21T23:28:04Z",
          "updatedAt": "2024-06-21T23:28:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "I hear you. I've not seen any other algorithm do this though. What would the API look like? An array of salts and you append the length of each one?\r\n\r\nAs mentioned in #14, it will probably be easy to support a pepper once the switch from `Hash()` to `PRF()` is made.",
          "createdAt": "2024-06-22T11:35:06Z",
          "updatedAt": "2024-06-22T11:35:06Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "C\r\n```\r\nint balloon_kdf(\r\n\tvoid       *output,   size_t outputSize,\r\n\tconst void *password, size_t passwordSize,\r\n\tconst void *salt,     size_t saltSize,\r\n\tuint32_t    memory, uint32_t iterations, uint32_t parallelism,\r\n\tuint32_t    maxThreads, int wipeMem,\r\n\tsize_t      numExtraSalts = 0, void **extraSalts = NULL, size_t *extraSaltsSizes = NULL);\r\n```\r\nC++\r\n```\r\nint balloon_kdf(\r\n\tvoid *output, size_t outputSize,\r\n\tconst std:string &password, const std:string &salt,\r\n\tuint32_t memory, uint32_t iterations, uint32_t parallelism,\r\n\tuint32_t maxThreads, int wipeMem,\r\n\tconst std:vector<std:string> *extraSalts = NULL);\r\n```\r\nGo\r\n```\r\nfunc balloon_kdf(\r\n\toutputSize int,\r\n\tpassword []byte, salt []byte,\r\n\tmemory int, iterations int, parallelism int,\r\n\tmaxThreads int, wipeMem int,\r\n\textraSalts [][]byte) (output []byte, err error) {\r\n...\r\nkey, _ := balloon_kdf(\r\n\tkeySize,\r\n\t[]byte(\"password\"), []byte(\"salt\"),\r\n\tmemory, iterations, parallelism,\r\n\tmaxThreads, wipeMem,\r\n\tnil)\r\n```",
          "createdAt": "2024-06-23T16:46:31Z",
          "updatedAt": "2024-06-23T16:46:31Z"
        },
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "Sorry for replying late, but I think having an extra \"pepper\", in addition to \"salt\" might be very confusing for the wast majority of non-cryptography-savvy developers.\r\n\r\nThe developers that do want \"peppers\" know what they are doing, and they could just fold that into the \"salt\" (or \"associated data\").\r\n\r\nThe current algorithm treats the \"pepper\" as the initial `key` for the `PRF`, meanwhile the \"salt\", \"personalization\" and \"associated data\" is just concatenated to the \"password\" as inputs to the said `PRF`.  But this is just by choice.  It could just as well \"merged\" the salt, pepper, personalization, associated data, into the `key` for the `PRF`.\r\n\r\n----\r\n\r\n> [...] I agree. But you might want to have \"extra salts\". [...]\r\n\r\n> [...] Yes, but having it as an option prevents the user of the API from needing to think about encoding lengths or other proper separation methods and maybe messing it up.\r\n\r\nThen, to make sure the user doesn't just shoot himself in the foot with normalizing multiple salts, peppers, and associated data, (plus personalization), why don't we allow the developer to provide a list of salts.  (Just like in the snippets above, but without the `salt` argument, just keeping the `extraSalts`.)\r\n\r\nThis way the interface greatly simplifies, and allows the user to choose how many salts, peppers, and associated data to provide.\r\n\r\n----\r\n\r\nThe personalization is perhaps best kept as a separate argument, to make sure that it is hard-coded as a constant to provide application separation.\r\n",
          "createdAt": "2024-11-15T17:33:08Z",
          "updatedAt": "2024-11-15T17:33:08Z"
        },
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "Also, while reading the RFC draft, I see that the pepper can be at most as long as the `KEY_LEN`, which makes it quite different than the rest of the inputs (password, salt, associated data, personalization, etc.) which can have arbitrary sizes (withit limits).\r\n\r\nWhat should a developer do, when he has a longer pepper than the `KEY_LEN`?  Should he hash it?\r\n\r\nThus, if we want to help the developer in taking the pepper off his hands, we've went just half the way.\r\n\r\n----\r\n\r\nAlso, there is something strange in the way the pepper is canonicalized:\r\n* the pepper contents, padded to `KEY_LEN` is used as the `PRF` key, thus without canonicalization (as a self-contained key);\r\n* but then the pepper length is passed as the `PRF` input, thus applying the pepper canonicalization at this second step;\r\n\r\nAlthough, most likely from a cryptographic point of view it doesn't mater at all (as long as the length is merged somewhere), the implementation seems \"strange\" or \"non-symmetrical\".\r\n",
          "createdAt": "2024-11-15T17:42:32Z",
          "updatedAt": "2024-11-15T17:42:32Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> Sorry for replying late, but I think having an extra \"pepper\", in addition to \"salt\" might be very confusing for the wast majority of non-cryptography-savvy developers.\r\n\r\nI think the draft makes the difference pretty clear, there's a [Wikipedia page](https://en.wikipedia.org/wiki/Pepper_(cryptography)), it's discussed by [OWASP](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html#peppering), and Argon2 supports a pepper, although annoyingly calls it 'secret value'.\r\n\r\nThe only issue with calling it a pepper is that the word has been used to mean something you rediscover, except I don't think that's caught on compared to it being a secret key. I wish people would just name things properly.\r\n\r\n> The developers that do want \"peppers\" know what they are doing, and they could just fold that into the \"salt\" (or \"associated data\").\r\n\r\nTrue, but it's nice separating these things. This makes code clearer, avoids worrying about fixed-length arguments/length encoding, and gives each parameter one purpose. Furthermore, there's a PRF key slot to use and feeding a key into that is theoretically better than feeding a key midway through the message.\r\n\r\n> It could just as well \"merged\" the salt, pepper, personalization, associated data, into the key for the PRF.\r\n\r\nOnly if you hashed that data; otherwise, the key would have a variable length, which isn't possible with certain functions and also a bad idea with HMAC because it affects it being a dual-PRF. And the issue with hashing is that the algorithm takes a keyed function, so this is basically what's already being done (you'd have to use an empty PRF key).\r\n\r\n> Then, to make sure the user doesn't just shoot himself in the foot with normalizing multiple salts, peppers, and associated data, (plus personalization), why don't we allow the developer to provide a list of salts.\r\n\r\na) this doesn't align with existing functions, which will cause confusion, b) this is annoying to implement, and c) barely anybody will use the `associatedData` parameter. I think it complicates rather than simplifies things for little benefit, and there's nothing stopping a particular implementation supporting associated data in a way that encodes the length of each part.\r\n\r\n> What should a developer do, when he has a longer pepper than the KEY_LEN? Should he hash it?\r\n\r\nThey shouldn't use a pepper longer than `KEY_LEN` because that key size is already big enough (128+ bits). Therefore, whilst this could be mentioned, I don't think it's necessary.\r\n\r\n> Also, there is something strange in the way the pepper is canonicalized:\r\n\r\nThis came about after I finally skim read the horrible [dual-PRF paper](https://eprint.iacr.org/2023/861) people were talking about. You need to encode the key length for HMAC/prefix MAC to be a dual-PRF. Doing that next to the key like KMAC doesn't work with certain functions due to key size restrictions, and as you say, this makes no practical difference.",
          "createdAt": "2024-11-16T12:19:50Z",
          "updatedAt": "2024-11-16T12:19:50Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "I_kwDOK_bi8M576e96",
      "title": "Reading about Balloon",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/8",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "I won't understand everything, but I can perhaps try and summarise bits in the Security Considerations section or use findings to inform tweaks. There are [lots](https://eprint.iacr.org/archive/versions/2016/027) of versions of the Balloon paper, so I'm not going to attempt to identify the differences between each one.\r\n\r\n- [x] [Balloon Hashing: Provably Space-Hard Hash Functions with Data-Independent Access Patterns](https://eprint.iacr.org/archive/2016/027/20160114:175127) (original Balloon paper)\r\n- [x] [Balloon Hashing: A Memory-Hard Function Providing Provable Protection Against Sequential Attacks](https://eprint.iacr.org/2016/027) (newest Balloon paper)\r\n- [x] [Balloon Hashing Asiacrypt 2016 talk](https://youtu.be/7vs47CYnDsQ) ([slides](https://people.csail.mit.edu/henrycg/files/academic/pres/asiacrypt16balloon-slides.pdf))\r\n- [ ] [Proof of Space from Stacked Expanders](https://eprint.iacr.org/2016/333)\r\n- [x] [Towards Practical Attacks on Argon2i and Balloon Hashing](https://eprint.iacr.org/2016/759)\r\n- [ ] [Depth-Robust Graphs and Their Cumulative Memory Complexity](https://eprint.iacr.org/2016/875)\r\n- [x] [Depth Robust Graphs and Their Cumulative Memory Complexity Eurocrypt 2017 talk](https://youtu.be/K1BdGP2ffSI) ([slides](https://eurocrypt.iacr.org/2017/slides/B05-depth-robust.pdf))\r\n- [x] [Bandwidth Hard Functions for ASIC Resistance](https://eprint.iacr.org/2017/225)\r\n\r\n[Link](https://eprint.iacr.org/search?q=balloon&title=&authors=&category=&submittedafter=&submittedbefore=&revisedafter=&revisedbefore=) to the full search results on ePrint Archive.\r\n\r\n",
      "createdAt": "2024-01-12T14:10:52Z",
      "updatedAt": "2024-01-27T17:22:45Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 9,
      "id": "I_kwDOK_bi8M58s6qv",
      "title": "Fix the modulo bias",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/9",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "`spaceCost` can be required to be a power of two.",
      "createdAt": "2024-01-20T16:41:51Z",
      "updatedAt": "2024-05-18T10:55:13Z",
      "closedAt": "2024-05-18T10:55:13Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Another approach would be using UInt128 and doing NIST's [Simple Modular Method](https://crypto.stackexchange.com/a/50569). However, that goes against #1 unless UInt64 is replaced with UInt128 everywhere.",
          "createdAt": "2024-02-23T18:40:55Z",
          "updatedAt": "2024-02-23T18:40:55Z"
        }
      ]
    },
    {
      "number": 10,
      "id": "I_kwDOK_bi8M58s-1n",
      "title": "Create a release for the interoperable version",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/10",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Publishing an Internet-Draft for the version interoperable with current implementations will likely cause confusion when breaking changes are made to improve the algorithm. Therefore, I will create a GitHub release instead for future reference if people need backwards compatibility.",
      "createdAt": "2024-01-20T17:18:48Z",
      "updatedAt": "2024-05-12T11:03:34Z",
      "closedAt": "2024-05-12T11:03:34Z",
      "comments": []
    },
    {
      "number": 12,
      "id": "I_kwDOK_bi8M6JW9no",
      "title": "Prevent canonicalization attacks",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/12",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "The current concatenation of the password and salt means you can shift bytes between the two parameters and get the same output, which should not be possible.\r\n\r\nThe easiest way to fix this is to append the lengths. Technically, one length will do but both are normally included in practice (e.g., in AEAD schemes).",
      "createdAt": "2024-05-19T08:31:53Z",
      "updatedAt": "2024-05-19T08:50:19Z",
      "closedAt": "2024-05-19T08:50:19Z",
      "comments": []
    },
    {
      "number": 13,
      "id": "I_kwDOK_bi8M6JXD4m",
      "title": "Update the test vectors and encoded hash",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/13",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Once the design has been finalised, these need to be updated since breaking changes have been made.",
      "createdAt": "2024-05-19T09:40:21Z",
      "updatedAt": "2024-07-27T14:17:02Z",
      "closedAt": null,
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "List of hash functions/XOFs to consider including test vectors for, with the ones to probably skip crossed out:\r\n\r\n1. ~BLAKE2s-256~\r\n2. **BLAKE2b-256**\r\n3. **BLAKE2b-512**\r\n4. ~BLAKE2X~\r\n5. **BLAKE3** (256 bit output or XOF, not both)\r\n6. ~SHA-224~\r\n7. **SHA-256**\r\n8. ~SHA-384~\r\n9. **SHA-512**\r\n10. **HMAC-SHA256**\r\n11. ~HMAC-SHA384~\r\n12. **HMAC-SHA512**\r\n17. ~SHA3-224~\r\n18. **SHA3-256**\r\n19. ~SHA3-384~\r\n20. **SHA3-512**\r\n21. ~KMAC128~\r\n22. ~KMAC256~\r\n23. ~KMACXOF128~\r\n24. ~KMACXOF256~\r\n25. **SHAKE128**\r\n14. **SHAKE256**\r\n15. ~cSHAKE128~\r\n16. ~cSHAKE256~\r\n17. ~TurboSHAKE128~\r\n18. ~TurboSHAKE256~\r\n26. **KangarooTwelve**\r\n27. ~MarsupilamiFourteen~\r\n\r\nThat's still over 10 algorithms... Got to hate how many variants there are.",
          "createdAt": "2024-07-27T14:17:02Z",
          "updatedAt": "2024-07-27T14:17:02Z"
        }
      ]
    },
    {
      "number": 14,
      "id": "I_kwDOK_bi8M6M3xDS",
      "title": "Fixes and suggestions",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/14",
      "state": "CLOSED",
      "author": "Sc00bz",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L184\r\n`List` should be called `Array`. This can be called an array of arrays or 2D array. Maybe consider `ByteArray` and `BlockArray` which cover the two use cases.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L186-L187\r\nConsider making these 32 bit functions and keeping `LE64(x)` for `counter`. Since these are all defined as 32 bit max integers. Except `MAX_SPACECOST` but that's 0 which is less than `MIN_SPACECOST`. Also related:\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L218\r\nConsider making `spaceCost` an integer 0 to 32 and represents 2**`spaceCost` blocks of memory.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L189\r\nReplace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L194\r\nAll mentions of XOF should be removed except this one because you are converting an XOF into a hash and this part might be missed. Also you are restricting XOFs more so than necessary. XOFs should not output more data than its internal state and should only call the internal base hash function the least amount of times to output anything (e.g. SHAKE128 has an internal state of 1600 bits but will call the internal base hash function more than the minimum for >1344 bits. Thus the max output for SHAKE128 is 1344 bits thus \"SHAKE128-1344\" or is it \"SHAKE128/1344\").\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L240\r\nand\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L285\r\nConsider removing `LE64(length)`. For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove `LE64(length)` then they can just ask for more output. Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. `encryptionKey = Balloon(...); macKey = Balloon(...);` and only do `macKey = Balloon(...); checkMac(macKey, mac, data)`).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L289-L294\r\nConsider changing this to:\r\n```\r\nprevious = buffer[spaceCost - 1]\r\nfor t = 0 to timeCost - 1\r\n    for m = 0 to spaceCost - 1\r\n```\r\nAnd add `previous = buffer[m]` to the end of the loop just after `buffer[m]` is set. A lot of implementations copied the paper verbatim on this or used an if statement. Also you can just return `previous`.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L296\r\nThis should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since `spaceCost` is a power of 2 you could grab the exact number of bits needed which will save calculations. Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (`oprfSalt = hash(password) ** serverSalt`). Maybe something like `Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))`. Also the paper's version is `Hash(LE64(counter++) || salt || LE64(iteration))`. Unless you want the access pattern to be the same across all threads thus enabling SIMD and better bandwidth utilization (but there's no mention of this).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L305\r\nAdd:\r\n* `x % spaceCost` can be done with a bit mask `x & (spaceCost - 1)` because spaceCost is a power of 2.\r\n* Instead of `Ceiling(length / HASH_LEN)` one can do `Floor((length + HASH_LEN - 1) / HASH_LEN)` or `(length + HASH_LEN - 1) / HASH_LEN` where / is integer divide. (Side note: I've seen people include math.h and convert to and from floating points.)\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L338\r\nSee https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/2#issuecomment-2177344918 Note the current draft is 3 H/block for an attacker which is the same for the \"academic code\" minimum settings.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L340\r\nOPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L342\r\nFor password hashing, anything at least 80 bits is fine for anything properly key stretched but NIST would probably want at least 112 bits. BUT obviously there's not much difference in storage space than 128 bit hash. For key derivation, NIST recommends at least 112 bit (because of 3DES).\r\nAlso this contradicts at least 128 bits and at most 256 bits from:\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L374\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L352\r\nvs\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L363\r\nShouldn't that be `$balloon-sha256$` or is it `blake2b-512`?\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L376\r\n\"Similarly, systems MUST check for overly large user-specified parameters (e.g. passwords) to prevent denial-of-service attacks.\" That's only for poorly designed algorithms which Balloon should not be. Currently it hashes the password and salt `parallelism`+1 times. It would be better if it was just once or twice.\r\n\r\nThere are 3 steps to a good key stretching algorithm:\r\n1) Hash inputs: `seed = H(inputs); [seedNoSecrets = H(non-secret-inputs)]`\r\n2) Do work: `work = doWork(settings, seed[, seedNoSecrets])`\r\n3) Output: `out = kdf(work, (inputs or seed), outSize, ...)`\r\n\r\nOne can make a good key stretching algorithm without those steps. This just prevents bad design choices (CVE-2014-9034, CVE-2016-20013) and bad implementations (CVE-2013-1443).\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L380\r\n\"authenticated encryption with associated data (AEAD) scheme\" No, authenticated is not needed since it's a password hash that can be replaced. It's more important to be deterministically encrypted. In fact this is the one time ECB is safe to use unless you want to store more than one blocks worth of hash. In that case use NULL-IV-CBC-CTS. This way you can have an HSM that only encrypts and the server can compare encrypted outputs. I just realized this doesn't mention that the only thing that needs to be encrypted is the hash part. Also it should be decoded into binary data before encrypted.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L382\r\nNIST would probably say at least 112 bits and at most 256 bits.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L392\r\nIt's more of a bandwidth vs memory transactions thing with GPUs. GPUs have wide memory buses. 128-384 bits for GeForce RTX 4000 series and Radeon RX 7000 series and historically up to 512 bits of GDDR. Other GPUs with HBM (vs GDDR) have bus widths of 1024 to 5120 bits.\r\n\r\n----\r\n\r\nhttps://github.com/samuel-lucas6/draft-lucas-balloon-hashing/blob/bfa686ed8e1bf5e3b81d35316ba27d5d23bea41b/draft-lucas-balloon-hashing.md?plain=1#L461\r\nTest Vector 4 has an invalid `spaceCost` of 3.",
      "createdAt": "2024-06-20T03:32:44Z",
      "updatedAt": "2024-08-20T17:44:28Z",
      "closedAt": "2024-08-20T17:44:28Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Hi Steve, thanks for your feedback; I'll definitely be giving you a mention in the Acknowledgements. I'll start working on these and do a proper reply at the weekend when I'm hopefully feeling fresh.\r\n\r\nSome of those things just haven't been updated whilst other parts have, like the test vectors. One major planned change is switching `Hash()` to `PRF()` to allow the use of HMAC. Then unkeyed hashes would use prefix MAC with the key padded to the block size. It's not ideal trying to cater for every possible hash function.",
          "createdAt": "2024-06-20T16:40:50Z",
          "updatedAt": "2024-06-20T16:40:50Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> One major planned change is switching Hash() to PRF() to allow the use of HMAC.\r\n\r\nThis will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC.\r\n\r\n> Then unkeyed hashes would use prefix MAC with the key padded to the block size.\r\n\r\nAh this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike CVE-2013-1443, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4\\*iterations vs 2\\*iterations+2).",
          "createdAt": "2024-06-21T23:26:35Z",
          "updatedAt": "2024-06-21T23:26:35Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Big thanks for this again. There's some great stuff here.\r\n\r\n> List should be called Array. This can be called an array of arrays or 2D array. Maybe consider ByteArray and BlockArray which cover the two use cases.\r\n\r\nYes, that's a good idea.\r\n\r\n> Consider making these 32 bit functions and keeping LE64(x) for counter. Since these are all defined as 32 bit max integers. Except MAX_SPACECOST but that's 0 which is less than MIN_SPACECOST. Also related:\r\n\r\n`LE64()` was chosen for consistency everywhere, but I agree those could be switched to `LE32()`. The `MAX_` parameters were chosen to avoid the counter overflowing.\r\n\r\n> Consider making spaceCost an integer 0 to 32 and represents 2**spaceCost blocks of memory.\r\n\r\nThat's sensible now it's a power of 2.\r\n\r\n> Replace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n\r\nHow about `the number x`?\r\n\r\n> All mentions of XOF should be removed except this one because you are converting an XOF into a hash and this part might be missed.\r\n\r\nFair point.\r\n\r\n> Also you are restricting XOFs more so than necessary. XOFs should not output more data than its internal state and should only call the internal base hash function the least amount of times to output anything (e.g. SHAKE128 has an internal state of 1600 bits but will call the internal base hash function more than the minimum for >1344 bits. Thus the max output for SHAKE128 is 1344 bits thus \"SHAKE128-1344\" or is it \"SHAKE128/1344\").\r\n\r\nI see what you mean. This was restricted for simplicity in terms of explaining what to do and because there are APIs where you use an XOF as a hash function. As an example, BLAKE3 can be used as a hash function or an XOF, which would lead to two incompatible variants for the same algorithm.\r\n\r\n> Consider removing LE64(length). For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove LE64(length) then they can just ask for more output.\r\n\r\nI get you. This was inspired by Argon2's variable-length hash function.\r\n\r\n> Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. encryptionKey = Balloon(...); macKey = Balloon(...); and only do macKey = Balloon(...); checkMac(macKey, mac, data)).\r\n\r\nI agree. This is actually something I've been discussing with Henry because he proposed getting rid of the KDF and running Balloon repeatedly to generate more output like PBKDF2, which I've argued is a bad idea for this reason/because it reduces the parameters.\r\n\r\n> Consider changing this to:\r\n> previous = buffer[spaceCost - 1]\r\n> for t = 0 to timeCost - 1\r\n>     for m = 0 to spaceCost - 1\r\n> And add previous = buffer[m] to the end of the loop just after buffer[m] is set. A lot of implementations copied the paper verbatim on this or used an if statement. Also you can just return previous.\r\n\r\nGood spot. I'll rearrange this.\r\n\r\n> This should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since spaceCost is a power of 2 you could grab the exact number of bits needed which will save calculations.\r\n\r\nI'm not sure what you mean here. It's written as `pseudorandom = Hash(LE64(counter++) || salt)` because hash APIs output a full hash.\r\n\r\n> Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (oprfSalt = hash(password) ** serverSalt). Maybe something like Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration)).\r\n\r\nThat's an interesting point. That was just from the paper.\r\n\r\n> Also the paper's version is Hash(LE64(counter++) || salt || LE64(iteration)). Unless you want the access pattern to be the same across all threads thus enabling SIMD and better bandwidth utilization (but there's no mention of this).\r\n\r\n`iteration` was added recently rather than having domain separation in the salt, and I managed to miss that.\r\n\r\n> Add:\r\n> x % spaceCost can be done with a bit mask x & (spaceCost - 1) because spaceCost is a power of 2.\r\n> Instead of Ceiling(length / HASH_LEN) one can do Floor((length + HASH_LEN - 1) / HASH_LEN) or (length + HASH_LEN - 1) / HASH_LEN where / is integer divide. (Side note: I've seen people include math.h and convert to and from floating points.)\r\n\r\nI'll add those.\r\n\r\n> See https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/2#issuecomment-2177344918 Note the current draft is 3 H/block for an attacker which is the same for the \"academic code\" minimum settings.\r\n\r\nThanks for investigating that.\r\n\r\n> OPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n\r\nYeah, I haven't thought about PAKEs at all. They're not something I've looked into, and it doesn't sound like they're frequently used. The 128 bits recommendation is following the Argon2 RFC.\r\n\r\n> For password hashing, anything at least 80 bits is fine for anything properly key stretched but NIST would probably want at least 112 bits. BUT obviously there's not much difference in storage space than 128 bit hash. For key derivation, NIST recommends at least 112 bit (because of 3DES).\r\n\r\nThe password hash length recommendation could be changed to 128 bits. I'd prefer to leave the key derivation recommendation as is. These are only recommendations, not MUSTs.\r\n\r\n> Also this contradicts at least 128 bits and at most 256 bits from:\r\n\r\nI don't think that does contradict anything because it's referring to the salt, which I've recommended 128 or 256 bits for before. SHOULD is equivalent to RECOMMENDED, and SHOULD NOT is equivalent to NOT RECOMMENDED, so they're not absolutes again.\r\n\r\n> Shouldn't that be $balloon-sha256$ or is it blake2b-512?\r\n\r\nYep, that hash needs to be updated. It was a SHA-256 example because the Rust implementation, which the draft was originally based on, used SHA-256 test vectors.\r\n\r\n> \"Similarly, systems MUST check for overly large user-specified parameters (e.g. passwords) to prevent denial-of-service attacks.\" That's only for poorly designed algorithms which Balloon should not be. Currently it hashes the password and salt parallelism+1 times. It would be better if it was just once or twice.\r\n\r\nYes, I see that now. That's what people have meant about prehashing the password. The password will only be hashed once when the algorithm is switched to being keyed.\r\n\r\n> \"authenticated encryption with associated data (AEAD) scheme\" No, authenticated is not needed since it's a password hash that can be replaced. It's more important to be deterministically encrypted. In fact this is the one time ECB is safe to use unless you want to store more than one blocks worth of hash. In that case use NULL-IV-CBC-CTS. This way you can have an HSM that only encrypts and the server can compare encrypted outputs. I just realized this doesn't mention that the only thing that needs to be encrypted is the hash part. Also it should be decoded into binary data before encrypted.\r\n\r\nI don't know how this is done in practice, but I've said AEAD schemes because they're more commonly used in general for encryption. I first heard about this idea from [password_lock](https://github.com/paragonie/password_lock), which claims to do authenticated encryption and I think encrypts a string. I can mention that only the hash needs to be encrypted.\r\n\r\n> NIST would probably say at least 112 bits and at most 256 bits.\r\n\r\nThis is only a recommendation, and if NIST wanted to approve this, they could make their own recommendations. I don't want to be recommending anything below 128 bits.\r\n\r\n> It's more of a bandwidth vs memory transactions thing with GPUs. GPUs have wide memory buses. 128-384 bits for GeForce RTX 4000 series and Radeon RX 7000 series and historically up to 512 bits of GDDR. Other GPUs with HBM (vs GDDR) have bus widths of 1024 to 5120 bits.\r\n\r\nYeah, I won't pretend to understand cache hardness. It could do with being properly defined and explained somewhere in the literature. It sounds like you need an understanding of GPU architecture.\r\n\r\n> Test Vector 4 has an invalid spaceCost of 3.\r\n\r\nThe test vectors are from the old Rust implementation so are out of date. They'll be updated when the design is finalised, and it would be good to have test vectors for all the major hash functions, although that will be a pain.\r\n\r\n> This will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC. \r\n\r\n> Ah this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike https://github.com/advisories/GHSA-4c42-4rxm-x6qf, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4*iterations vs 2*iterations+2).\r\n\r\nThe idea is to allow the use of HMAC because that's probably what NIST wants whilst allowing everyone else to use an ordinary hash function/non-approved algorithm instead (e.g., BLAKE2). It's not ideal though because of things like keyed BLAKE2/BLAKE3 vs prefix MAC for BLAKE2/BLAKE3, which may cause confusion/interoperability issues.\r\n\r\nThe plan is to do `key = PRF(emptyKey, password || salt || password.Length || salt.Length)` and then use that key as the key everywhere else, except when computing the pseudorandom bytes since that should be password-independent. That can use an empty key again. This isn't ideal with prefix MAC but is like HKDF-Extract with HMAC.\r\n\r\nThis would allow easily supporting a pepper because that initial `emptyKey` could be the pepper, and it would be restricted to something like 512 bits to avoid HMAC key hashing, which was a HMAC design flaw.",
          "createdAt": "2024-06-22T11:31:03Z",
          "updatedAt": "2024-06-22T11:31:03Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> > Replace \"integer\" with \"float\" or \"floating point\". Or remove \"the integer\".\r\n>\r\n> How about the number x?\r\n\r\nYeah that's fine.\r\n\r\n> > Consider removing LE64(length). For a KDF, let's say someone uses the exact output from Balloon then later realizes they need another key while preserving the original key. Then they would have to run Balloon twice, but if you remove LE64(length) then they can just ask for more output.\r\n>\r\n> I get you. This was inspired by Argon2's variable-length hash function.\r\n\r\nPBKDF2 doesn't do this. Which means Balloon doesn't need to do this. And it's better if it doesn't.\r\n\r\n> > Also in the Security Considerations section it should be stated to only run the password KDF once and derive all the keys needed from that output. Since an attacker will run which ever password KDF that will give them a password check (e.g. encryptionKey = Balloon(...); macKey = Balloon(...); and only do macKey = Balloon(...); checkMac(macKey, mac, data)).\r\n>\r\n> I agree. This is actually something I've been discussing with Henry because he proposed getting rid of the KDF and running Balloon repeatedly to generate more output like PBKDF2, which I've argued is a bad idea for this reason/because it reduces the parameters.\r\n\r\nThat is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n\r\nMicrosoft used `PBKDF2-HMAC-SHA1(pw, salt, iterations:4096, outLen:256 bits)` as a hash because \"it's good enough for WiFi\". But an attacker only needs to calculate the first 160 bits. Doing half the work as a defender.\r\n\r\n1Password used `key || iv = PBKDF2-HMAC-SHA256(pw, salt, iterations:100000, outLen:384 bits)` to decrypt a 256 bit key in CBC mode. Again an attacker only needs the first 256 bits and decrypt the padding and compare to \"\\x10\\x10...\\x10\". Doing half the work as a defender.\r\n\r\nI'm sure there are several others.\r\n\r\n> > This should be more like the academic code. Where it's a bit stream and you grab what you need from it. https://github.com/henrycg/balloon/blob/35d7da79f42b4f9078ba6f39e1e0a5a37bafa4c1/libballoon/hash_state.c#L167 Since spaceCost is a power of 2 you could grab the exact number of bits needed which will save calculations.\r\n>\r\n> I'm not sure what you mean here. It's written as pseudorandom = Hash(LE64(counter++) || salt) because hash APIs output a full hash.\r\n\r\nOh the counter is the same... OK `counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN)` instead of 0. Or have different counters maybe `H(\"0\" || LE64(counter0++) || ...)` and `H(\"1\" || LE64(counter1++) || ...)`. And give a description or an example like `pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...}` and `pseudorandomStream.popBitsLE(12)` returns 0x321 and the next call returns 0x654.\r\n```\r\ncounter = Ceiling(((3 * spaceCostLog2 * timeCost) << spaceCostLog2) / HASH_BIT_LEN)\r\npseudorandomStream =\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(0) || LE64(iteration) || salt) ||\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(1) || LE64(iteration) || salt) ||\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(2) || LE64(iteration) || salt) ||\r\n    ...\r\n    PRF(ZeroPad(emptyKey, HASH_LEN), LE64(counter-1) || LE64(iteration) || salt)\r\n\r\nbuffer[0] = PRF(key, LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(length) || LE64(iteration))\r\nfor m = 1 to spaceCost - 1\r\n    buffer[m] = PRF(key, LE64(counter++) || buffer[m - 1])\r\n\r\nemptyKey = ByteArray(0)\r\nprevious = buffer[spaceCost - 1]\r\nfor t = 0 to timeCost - 1\r\n    for m = 0 to spaceCost - 1\r\n        other1 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        other2 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        other3 = pseudorandomStream.popBitsLE(spaceCostLog2)\r\n        buffer[m] = PRF(key, LE64(counter++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])\r\n        previous = buffer[m]\r\n```\r\n\r\n> > Also reconsider including the salt because PAKEs with an OPRF will have a salt that includes the password (oprfSalt = hash(password) ** serverSalt). Maybe something like Hash(LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration)).\r\n>\r\n> That's an interesting point. That was just from the paper.\r\n\r\nI remember there being a conversation on the PHC mailing list about whether salt should be included for secret independent reads. I remember at least one submission that did this. I'm pretty sure it was determined to be better not to include salt. Also Argon2i doesn't include the salt.\r\n\r\n> > OPRF salts are \"variable\" length based on elliptic curve or finite field prime. Also see https://github.com/samuel-lucas6/draft-lucas-balloon-hashing/issues/7#issuecomment-2177358941 about \"extra salts\". Also for password hashing this can be as low at like 32 bits unless you're Facebook scale then 40-48 bits. It's a whole thing about max collisions being relatively low and most are unique. BUT obviously there's not much difference in storage space than 128 bit salts.\r\n>\r\n> Yeah, I haven't thought about PAKEs at all. They're not something I've looked into, and it doesn't sound like they're frequently used. The 128 bits recommendation is following the Argon2 RFC.\r\n\r\nWhatsApp, and 1Password use PAKEs. I think also Apple and Signal. The RFC recommends 128 bit salts, but they are very lax on requirements 8 to 2^(32)-1 bytes:\r\n\r\n\"Nonce S, which is a salt for password hashing applications. It MUST have a length not greater than 2^(32)-1 bytes. 16 bytes is RECOMMENDED for password hashing. The salt SHOULD be unique for each password.\" https://www.rfc-editor.org/rfc/rfc9106.html#section-3.1-2.2\r\n\r\n\"Select the salt length. A length of 128 bits is sufficient for all applications but can be reduced to 64 bits in the case of space constraints.\" https://www.rfc-editor.org/rfc/rfc9106.html#section-4-6.7\r\n\r\n> > Also this contradicts at least 128 bits and at most 256 bits from:\r\n>\r\n> I don't think that does contradict anything because it's referring to the salt, which I've recommended 128 or 256 bits for before. SHOULD is equivalent to RECOMMENDED, and SHOULD NOT is equivalent to NOT RECOMMENDED, so they're not absolutes again.\r\n\r\nYeah I read that wrong.\r\n\r\n> > This will make it slower and it's already slow. I guess this will only make it 33% slower (3 vs 4 H/block). Assuming cached HMAC.\r\n> >\r\n> > Ah this won't make it slower. Assuming the implementation caches the state after the key is added. Unlike https://github.com/advisories/GHSA-4c42-4rxm-x6qf, PBKDF2 DoS with long password. Besides doing twice the work for normal sized passwords (4iterations vs 2iterations+2).\r\n>\r\n> The idea is to allow the use of HMAC because that's probably what NIST wants whilst allowing everyone else to use an ordinary hash function/non-approved algorithm instead (e.g., BLAKE2). It's not ideal though because of things like keyed BLAKE2/BLAKE3 vs prefix MAC for BLAKE2/BLAKE3, which may cause confusion/interoperability issues.\r\n>\r\n> The plan is to do key = PRF(emptyKey, password || salt || password.Length || salt.Length) and then use that key as the key everywhere else, except when computing the pseudorandom bytes since that should be password-independent. That can use an empty key again. This isn't ideal with prefix MAC but is like HKDF-Extract with HMAC.\r\n>\r\n> This would allow easily supporting a pepper because that initial emptyKey could be the pepper, and it would be restricted to something like 512 bits to avoid HMAC key hashing, which was a HMAC design flaw.\r\n\r\nPrefix MAC for BLAKE2/BLAKE3 is bad because it doesn't do the block operation until there's more than a block of data. Since the last block can be full. I feel like I'm saying this weirdly. The last block has a flag that states it's the last block and it can be full and no data is added for padding. Thus giving it a full block after initialization it will wait for finish to be called or more data before it mixes the block. So if it was `PRF(key, BE64(counter++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])` then one could `blake2b_update(ctx, ZeroPad(key, 128))`, `blake2b_update(ctx, \"\\0\")`, make a copy of `ctx`, `blake2b_update(ctx, BE56(counter++))`... Or if it was `PRF(key, \"1\" || LE64(counter1++) || previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3])` (using two counters like above).\r\n\r\nIt would be best to state that Balloon with prefix MAC is invalid for BLAKE2 and BLAKE3. And that the only valid method is using the built in MAC for BLAKE2 and BLAKE3.",
          "createdAt": "2024-06-23T19:13:33Z",
          "updatedAt": "2024-06-23T19:13:33Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Sorry for my slow replies, got a lot going on at the moment.\r\n\r\n> PBKDF2 doesn't do this. Which means Balloon doesn't need to do this. And it's better if it doesn't.\r\n\r\nYeah, I'll try to remove this at the weekend.\r\n\r\n> That is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n\r\nThanks for the examples. I was aware of 1Password having a problem.\r\n\r\nHowever, it turns out that I've misunderstood what Henry meant. His proposal is actually to grab more bytes/blocks from the final mixed buffer, meaning you don't have to do any extra hashing (no KDF and no rerunning the algorithm).\r\n\r\nOf course, the obvious limitation is that the output length is now limited by the space cost. To get around that, you end up rerunning the Mix phase, which introduces this PBKDF2 footgun again and complicates the code. Another issue might be with collision resistance when parallelism is used.\r\n\r\nI understand the appeal, but I think using a KDF is cleaner. I'm interested to know your thoughts.\r\n\r\n> Oh the counter is the same... OK counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN) instead of 0. Or have different counters maybe H(\"0\" || LE64(counter0++) || ...) and H(\"1\" || LE64(counter1++) || ...). And give a description or an example like pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...} and pseudorandomStream.popBitsLE(12) returns 0x321 and the next call returns 0x654.\r\n\r\nI'm a bit confused by your last sentence, and is the purpose of using separate counters to allow easier precomputation?\r\n\r\n> I remember there being a conversation on the PHC mailing list about whether salt should be included for secret independent reads. I remember at least one submission that did this. I'm pretty sure it was determined to be better not to include salt. Also Argon2i doesn't include the salt.\r\n\r\nI'll try to find that.\r\n\r\n> WhatsApp, and 1Password use PAKEs. I think also Apple and Signal. The RFC recommends 128 bit salts, but they are very lax on requirements 8 to 2^(32)-1 bytes:\r\n\r\nYeah, I can imagine some of the bigger companies using them/them being used more in the future.\r\n\r\nAnd yes, I could add a comment about smaller salts being acceptable, but the wording doesn't prohibit any size of salt from being used currently. It can even be empty because that's what the scrypt and Argon2 RFCs seem to allow.\r\n\r\n> It would be best to state that Balloon with prefix MAC is invalid for BLAKE2 and BLAKE3. And that the only valid method is using the built in MAC for BLAKE2 and BLAKE3.\r\n\r\nI've been planning to make it a bit clearer. I'll say something like _If the hash function supports a key parameter (e.g. BLAKE2 [RFC]), it MUST be used. Otherwise, if the hash function does not have a key parameter, prefix MAC MUST be used..._.",
          "createdAt": "2024-06-27T20:11:01Z",
          "updatedAt": "2024-06-27T20:11:01Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Sorry for my slow replies, got a lot going on at the moment.\r\n\r\nDon't worry about.\r\n\r\n> > That is a bad idea. PBKDF2's footgun exists because they wanted to do the least amount of changes/effort to make PBKDF output variable length.\r\n> \r\n> Thanks for the examples. I was aware of 1Password having a problem.\r\n> \r\n> However, it turns out that I've misunderstood what Henry meant. His proposal is actually to grab more bytes/blocks from the final mixed buffer, meaning you don't have to do any extra hashing (no KDF and no rerunning the algorithm).\r\n> \r\n> Of course, the obvious limitation is that the output length is now limited by the space cost. To get around that, you end up rerunning the Mix phase, which introduces this PBKDF2 footgun again and complicates the code. Another issue might be with collision resistance when parallelism is used.\r\n> \r\n> I understand the appeal, but I think using a KDF is cleaner. I'm interested to know your thoughts.\r\n\r\nDefinitely KDF. If you output the first hash from the memory an attacker can skip the last iteration. Also currently it's `4*t*m*p` hash blocks to do the main work and HKDF is `2*ceiling(outputLength/hashLength)+6` hash blocks. Getting `4*t*m*p` down to `~3.2*t*m*p` will benefit much more. Using a pseudorandom stream will remove about `0.8*t*m*p` hash blocks.\r\n\r\n> > Oh the counter is the same... OK counter = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN) instead of 0. Or have different counters maybe H(\"0\" || LE64(counter0++) || ...) and H(\"1\" || LE64(counter1++) || ...). And give a description or an example like pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...} and pseudorandomStream.popBitsLE(12) returns 0x321 and the next call returns 0x654.\r\n> \r\n> I'm a bit confused by your last sentence\r\n\r\n`pseudorandomStream={0x21, 0x43, 0x65, 0x87, ...}` is defining the example byte data in `pseudorandomStream` and `pseudorandomStream.popBitsLE(12)` gets 12 bits from `pseudorandomStream` which is `0x321 == (0x21 | (0x43 << 8)) & ((1 << 12) - 1)`. Now `pseudorandomStream={0x4 (4 bits), 0x65, 0x87, ...}` and the next `pseudorandomStream.popBitsLE(12)` call returns `0x654 == (0x4 | (0x65 << 4)) & ((1 << 12) - 1)`.\r\n\r\n> and is the purpose of using separate counters to allow easier precomputation?\r\n\r\nNo, I was trying to keep the counters from overlapping or having explicit domain separation with \"0\" and \"1\".\r\n\r\n`X = Ceiling(3 * spaceCostLog2 * 2^spaceCostLog2 * timeCost / HASH_BIT_LEN)`\r\n\r\nIf you start the pseudorandom stream counter at `0` it will end at `X-1`. Starting the other counter at `X` will make sure they don't overlap. You could just start both at zero because you're hashing two different fixed length strings (1, 64 bit int and 4, 32 bit ints vs 1, 64 bit int and 5 hashes).",
          "createdAt": "2024-06-28T13:28:12Z",
          "updatedAt": "2024-06-28T13:28:12Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Ok I've addressed most of this feedback now. I think the outstanding points are:\r\n\r\n- `LE32()` for lengths\r\n- `spaceCost` being an integer between 1-32\r\n- Supporting larger outputs with XOFs (the block size/rate)\r\n- A separate counter for the memory accesses\r\n- Update the test vectors (waiting until the design has been finalised)\r\n\r\nI like the `spaceCost` idea from a user's perspective, but it feels a bit awkward to write in the draft. I already wrote it up and reversed the changes.\r\n\r\nI don't understand how the pseudorandom stream idea affects the hash blocks because you still need to compute the same number of hashes surely. If we ignore the separate counter thing, it just feels like moving the computation from inside the loop to before any loops.",
          "createdAt": "2024-07-13T14:29:48Z",
          "updatedAt": "2024-07-13T14:29:48Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> * `LE32()` for lengths\r\n\r\nIt doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n```\r\npseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n                   LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n```\r\nWait a second shouldn't `HASH_LEN` be `HASH_BLOCK_LEN`?\r\n\r\n> * `spaceCost` being an integer between 1-32\r\n>\r\n> [...]\r\n> I like the `spaceCost` idea from a user's perspective, but it feels a bit awkward to write in the draft. I already wrote it up and reversed the changes.\r\n\r\nWell 0-32 because current range is 1 (2\\*\\*0) to 4294967296 (2\\*\\*32). This also doesn't need to be in the specification. It will be like scrypt's `N`. Which some implementations ask for log2 of `N`. I don't know how it's stored in the standard hash...\r\n\r\n```\r\n$7$DU..../....2Q9obwLhin8qvQl6sisAO/$sHayJj/JBdcuD4lJ1AxiwCo9e5XSi8TcINcmyID12i8\r\n```\r\n\r\nOK?... Ahh https://github.com/besser82/libxcrypt/blob/72f75aa370ae96ccd2cc44ea3cf4182d8679ffbe/lib/crypt-scrypt.c#L222 it's log2 of N. That hash decodes to N=1<<b64ToInt(\"D\"), r=b64ToInt(\"U....\"), p=b64ToInt(\"/....\"), salt=\"2Q9obwLhin8qvQl6sisAO/\", hash=\"sHayJj/JBdcuD4lJ1AxiwCo9e5XSi8TcINcmyID12i8\"... I give up I'll just assume it's base64 with \"./0-9A-Za-z\". So N=2\\*\\*15, r=32, p=1. I hate this decoder key BS to figure out the settings. \"Wow you saved 2 characters and wasted an hour of my time\" (and likely several other people's time too).\r\n\r\nI also found a non-standard one that did `N$r$p$salt$hash`.\r\n\r\n> * A separate counter for the memory accesses\r\n>\r\n> [...]\r\n> I don't understand how the pseudorandom stream idea affects the hash blocks because you still need to compute the same number of hashes surely. If we ignore the separate counter thing, it just feels like moving the computation from inside the loop to before any loops.\r\n\r\nUsing the pseudorandom stream idea with SHA-512 and 4 MiB (`spaceCost=2**16`), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks). I benchmarked this on a i5-6500 with DDR4-2133 (average of 10 runs) and it's 368 ms vs 555 ms (SHA-512, 4 MiB (`spaceCost=2**16`), `timeCost=3`) and 643 ms vs 795 ms (SHA-256, 4 MiB (`spaceCost=2**17`), `timeCost=3`). I did 1 MiB to 64 MiB and without the pseudorandom stream it takes 1.57x to 1.45x longer for SHA-512 and 1.29x to 1.14x longer for SHA-256. If you graph these they both start at the maximum at 1 MiB then decrease to the minimum at 16 MiB then increase a little. I also did SHAKE128/1024 and it's 1.33x to 1.24x. I need a better implementation of SHAKE128 that uses AVX2. Also it would be interesting to see how SHA-256 performs with SHA instructions (and SHA-512 when CPUs with those instructions are available).\r\n\r\nOh right, the SHA-256 code encodes `spaceCost`, `timeCost`, `parallelism`, and `iteration` as 32 bit integers. I also did everything in \"hash endian\" to skip conversions. Also I used functions `hash_updateNative(...)` and `hash_finishNative(...)` that take `uint32_t`s or `uint64_t`s depending on hash.",
          "createdAt": "2024-07-13T23:07:53Z",
          "updatedAt": "2024-07-13T23:07:53Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "> Wait a second shouldn't `HASH_LEN` be `HASH_BLOCK_LEN`?\r\n\r\nOops, no. `PRF(key, message)` I should of noticed the comma vs concatenation since I split the line right there. I was thinking of prefix MAC. Also I said \"this will be 2 blocks\" I meant with cached prefix MAC or cached keyed BLAKE2 etc.",
          "createdAt": "2024-07-14T00:30:04Z",
          "updatedAt": "2024-07-14T00:30:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> It doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n>\r\n> pseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n>                    LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n\r\nIgnoring the key, I think the message should fit in 1 block (40 bytes/320 bits when the block size is 512 bits).\r\n\r\n> Wait a second shouldn't HASH_LEN be HASH_BLOCK_LEN?\r\n\r\nIt's a bit confusing, but I say `you MUST perform prefix MAC and pad the key with zeros to the block size (1024 bits for SHA-512)` for non-keyed hashes in the Conventions and Definitions section.\r\n\r\nThe reason the key is padded to `HASH_LEN` here is because that's what HKDF-Extract does for the salt, and you can't write `HASH_BLOCK_LEN` because that would exceed the BLAKE2 key size, for example. It's problematic to specify when the supported key size varies by algorithm.\r\n\r\n> Well 0-32 because current range is 1 (2**0) to 4294967296 (2**32). This also doesn't need to be in the specification. It will be like scrypt's N. Which some implementations ask for log2 of N.\r\n\r\nYeah, my bad.\r\n\r\nGood point, although it would encourage a consistent API like what's been done with the `associatedData` parameter. Otherwise, I doubt most people would implement it that way. And as you say, the stored hash should be consistent and not difficult to parse.\r\n\r\n> Using the pseudorandom stream idea with SHA-512 and 4 MiB (spaceCost=2**16), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks).\r\n\r\nOh I think I'm getting it now. So, the idea is to use more of each hash rather than using truncated hashes? Then the second part of the idea is to switch from `LE64()` to `LE16()` to get even more random indices out of each hash? Although how is 16 bits enough for a random index when `spaceCost` can be up to 4294967296?",
          "createdAt": "2024-07-14T17:18:47Z",
          "updatedAt": "2024-07-14T17:18:47Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "Just found a bug in my code. It's now faster:\r\n\r\nSHA-512, 4 MiB (`spaceCost=2**16`), `timeCost=3`:\r\n<s>368 ms vs 555 ms</s>\r\n258 ms vs 327 ms\r\n\r\nSHA-256, 4 MiB (`spaceCost=2**17`), `timeCost=3`:\r\n<s>643 ms vs 795 ms</s>\r\n465 ms vs 551 ms\r\n\r\n1 MiB to 64 MiB and without the pseudorandom stream it takes <s>1.57x to 1.45x</s> 1.30x to 1.17x longer for SHA-512 and <s>1.29x to 1.14x</s> 1.22x to 1.08x longer for SHA-256. If you graph these they both start at the maximum at 1 MiB then decrease to the minimum at <s>16</s> 32 MiB then increase a little. I also did SHAKE128/1024 and it's <s>1.33x to 1.24x</s> 1.20x to 1.10x.\r\n\r\n> > It doesn't really matter except for here and with SHA-256 because this will be 2 blocks:\r\n> > pseudorandom = PRF(ZeroPad(emptyKey, HASH_LEN),\r\n> > LE64(counter++) || LE64(spaceCost) || LE64(timeCost) || LE64(parallelism) || LE64(iteration))\r\n> \r\n> Ignoring the key, I think the message should fit in 1 block (40 bytes/320 bits when the block size is 512 bits).\r\n> \r\n> > Wait a second shouldn't HASH_LEN be HASH_BLOCK_LEN?\r\n> \r\n> It's a bit confusing, but I say `you MUST perform prefix MAC and pad the key with zeros to the block size (1024 bits for SHA-512)` for non-keyed hashes in the Conventions and Definitions section.\r\n> \r\n> The reason the key is padded to `HASH_LEN` here is because that's what HKDF-Extract does for the salt, and you can't write `HASH_BLOCK_LEN` because that would exceed the BLAKE2 key size, for example. It's problematic to specify when the supported key size varies by algorithm.\r\n> \r\n\r\nYeah ignore that. I think my brain seg faulted.\r\n\r\n> > Using the pseudorandom stream idea with SHA-512 and 4 MiB (spaceCost=2**16), you do 1 hash for every 10.67 blocks vs every block. With those settings, you are only using 16 bits for each random offset (48 bits/block and 512/48=10.67 blocks).\r\n> \r\n> Oh I think I'm getting it now. So, the idea is to use more of each hash rather than using truncated hashes? Then the second part of the idea is to switch from `LE64()` to `LE16()` to get even more random indices out of each hash? Although how is 16 bits enough for a random index when `spaceCost` can be up to 4294967296?\r\n\r\nIt's not always 16 bits. It's log 2 of `spaceCost` bits. Here's the code I used... maybe I should just post the whole thing and not just the pseudorandom stream. It has something that I was going to bring up after this issue is closed. Also `HASH_UINT_BLOCK` is 8 for SHA2 and 16 for SHAKE128. `hash_uint` is `uint32_t` for SHA-256 and `uint64_t` for SHA-512 and SHAKE128.\r\n\r\n```\r\nstruct balloonRand_ctx\r\n{\r\n\tuint64_t   streamCounter;\r\n\thash_ctx  *ctx;\r\n\thash_uint *stream;\r\n\thash_uint *streamData;\r\n\thash_uint *mem;\r\n\tuint32_t   memory; // log2(spaceCost)\r\n\tuint32_t   memoryMask; // spaceCost - 1\r\n\tuint32_t   streamDataLeft;\r\n};\r\n\r\nhash_uint *hash_balloonRand(balloonRand_ctx &ctx)\r\n{\r\n\thash_uint *streamData     = ctx.streamData;\r\n\tuint32_t   memory         = ctx.memory;\r\n\tuint32_t   streamDataLeft = ctx.streamDataLeft;\r\n\tsize_t     curPos         = streamDataLeft / (8 * sizeof(hash_uint));\r\n\tuint32_t   bits           = streamDataLeft % (8 * sizeof(hash_uint));\r\n\thash_uint  offset         = streamData[curPos];\r\n\r\n\tif (streamDataLeft < memory)\r\n\t{\r\n\t\t// Hash\r\n\t\tuint64_t streamCounter = ctx.streamCounter;\r\n#ifdef HASH_UINT_IS_64\r\n\t\tctx.stream[1] = streamCounter;\r\n\t\thash_updateNative(ctx.ctx, ctx.stream + 1, 4); // 4 uint64_t's\r\n#else\r\n\t\tctx.stream[0] = (uint32_t) (streamCounter >> 32);\r\n\t\tctx.stream[1] = (uint32_t)  streamCounter;\r\n\t\thash_updateNative(ctx.ctx, ctx.stream, 5); // 5 uint32_t's\r\n#endif\r\n\t\thash_finishNative(ctx.ctx, streamData);\r\n\t\tctx.streamCounter = streamCounter + 1;\r\n\t\tstreamDataLeft += 8 * HASH_SIZE;\r\n\r\n\t\t// Add new stream data\r\n\t\thash_uint tmp  = streamData[HASH_UINT_BLOCK - 1];\r\n\t\toffset        |= tmp << bits;\r\n\r\n\t\t// Update stream data\r\n\t\tstreamData[HASH_UINT_BLOCK - 1] = tmp >> (memory - bits);\r\n\t}\r\n\telse if (bits < memory)\r\n\t{\r\n\t\t// Add stream data\r\n\t\thash_uint tmp  = streamData[curPos - 1];\r\n\t\toffset        |= tmp << bits;\r\n\r\n\t\t// Update stream data\r\n\t\tstreamData[curPos - 1] = tmp >> (memory - bits);\r\n\t}\r\n\telse\r\n\t{\r\n\t\t// Update stream data\r\n\t\tstreamData[curPos] = offset >> memory;\r\n\t}\r\n\tctx.streamDataLeft = streamDataLeft - memory;\r\n\r\n\treturn ctx.mem + HASH_UINT_BLOCK * (offset & ctx.memoryMask);\r\n}\r\n```\r\n```\r\nballoonRand_ctx randCtx;\r\nhash_ctx   ctx2;\r\nhash_uint *mem;\r\nhash_uint  stream[5] = {0, 0, memory, iterations, parallelism};\r\nhash_uint  streamData[HASH_UINT_BLOCK];\r\n\r\nmem = new hash_uint[((size_t) HASH_UINT_BLOCK) << memory];\r\nrandCtx.streamCounter  = 0;\r\nrandCtx.ctx            = &ctx2;\r\nrandCtx.stream         = stream;\r\nrandCtx.streamData     = streamData;\r\nrandCtx.mem            = mem;\r\nrandCtx.memory         = memory;\r\nrandCtx.memoryMask     = (1 << memory) - 1;\r\nrandCtx.streamDataLeft = 0;\r\n\r\n// ...\r\n\r\nhash_uint *other1 = hash_balloonRand(randCtx);\r\nhash_uint *other2 = hash_balloonRand(randCtx);\r\nhash_uint *other3 = hash_balloonRand(randCtx);\r\n```",
          "createdAt": "2024-07-15T06:06:48Z",
          "updatedAt": "2024-07-15T06:06:48Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> spaceCost being an integer between 0-32\r\n\r\nThis is done now. What do you think of the pseudocode for this/encoding `2^spaceCost` rather than `spaceCost`?\r\n\r\n> Supporting larger outputs with XOFs (the block size/rate)\r\n\r\nI've said 1024 bits (just realised there was a typo in that commit where I said 1024 bytes) if using an XOF.\r\n\r\nI'm not especially happy with it. It works for SHAKE/KangarooTwelve/MarsupilamiFourteen but not BLAKE3. I'd say the block size, except that doesn't account for padding/being a multiple of a cache line. Maybe I should say something like the nearest power of 2 to the block size.\r\n\r\n> It's not always 16 bits. It's log 2 of spaceCost bits.\r\n\r\nMy concern is this looks more difficult to implement than just `LE32()` or `LE64()`, and ease of understanding/implementation is one of the main selling points of the algorithm.",
          "createdAt": "2024-07-20T17:04:04Z",
          "updatedAt": "2024-07-20T17:04:04Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "@Sc00bz I think I've addressed all of your feedback now.\r\n\r\nI'm not doing `log2(spaceCost)` at the moment but switched from `LE64()` to `LE32()` besides the counter and am precomputing the pseudorandom bytes, which should still be a significant performance boost (e.g., 3 random indices per hash => 7, 8, 12, 16, or 32 per hash depending on the hash function/XOF). The downside is the additional complexity and increased memory usage.\r\n\r\n> It has something that I was going to bring up after this issue is closed.\r\n\r\nWhat are you talking about here? Are you happy to close this issue?",
          "createdAt": "2024-07-27T13:58:13Z",
          "updatedAt": "2024-07-27T13:58:13Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "@Sc00bz I found the conversations on the [phc-discussions mailing list](https://lists.openwall.net/phc-discussions/) you were talking about by converting the list to [files](https://github.com/samuel-lucas6/phc-discussions) and searching for `salt`, `password-independent`, `data-independent`, `salt-dependent`, `visitation pattern`, and `access pattern`:\r\n\r\n- [2014/09/19/1](https://lists.openwall.net/phc-discussions/2014/09/19/1): The salt and thus memory access pattern is unique per user. This forces the attacker to compute the access pattern for each entry in the database.\r\n- [2014/09/19/2](https://lists.openwall.net/phc-discussions/2014/09/19/2): If the memory access pattern depends on the salt, it's still known at the time of computation, so the necessary data can still be prefetched from the memory.\r\n- [2014/09/19/4](https://lists.openwall.net/phc-discussions/2014/09/19/4): The salt should be treated as public.\r\n- [2014/09/19/4](https://lists.openwall.net/phc-discussions/2014/09/19/4): A predictable but wildly irregular pattern is harder to optimize but can be optimized. It's typically a situation that urges the good guys to omit optimization (to avoid complexity) but urges attackers to do the optimization and thus gain an advantage. We want optimization options to either not be there or so easy that everybody will implement them. Difficult optimizations mean an advantage to attackers and a disadvantage to defenders.\r\n- [2014/09/19/6](https://lists.openwall.net/phc-discussions/2014/09/19/6): Since for a given salt, all the memory access patterns will be the same, independent of the password guess, I can interleave the memory for several guesses together, so that when I run them in lock-step, I reduce the cache-miss penalty for reading small blocks of memory. That's just one example, but there are a number of them.\r\n- [2014/09/19/6](https://lists.openwall.net/phc-discussions/2014/09/19/6): Some timing information can be leaked. It might be possible for an attacker to detect who has logged in based on a cache timing signature, for example.\r\n- [2015/05/05/15](https://lists.openwall.net/phc-discussions/2015/05/05/15): Some salts/parameters will end up leading to weaker visitation patterns than others. This is unlikely to be critical in the long run, but that would be similar to having \"weak keys\" in cryptographic algorithms. So, if those are avoidable, it would probably be better.\r\n- [2015/07/01/2](https://lists.openwall.net/phc-discussions/2015/07/01/2): Assuming I know the salt, and I am able to observe via a timing side channel the first few memory accesses from hashing the correct password, then I am able to reject an incorrect guess at the password without having pay most of the cost that should be imposed by the work factor, no?\r\n- [2015/07/02/1](https://lists.openwall.net/phc-discussions/2015/07/02/1): An attacker will be able to use cache-timing of salt-derived memory access to determine who is logging in.  I personally am not too concerned about this potential metadata leak.  This is nearly equivalent to what is leaked by hybrid algorithms that have a resistant first loop followed by an unpredictable second loop.\r\n- [2015/07/22/3](https://lists.openwall.net/phc-discussions/2015/07/22/3): All cache-timing measurements will only leak information about the salt, which is usually already known/public.\r\n- [2016/01/12/6](https://lists.openwall.net/phc-discussions/2016/01/12/6): I see the risk that anything chosen randomly might be suboptimal, especially if it depends on a value (like the salt) out of control. I don't like their approach for the same reason.\r\n- [2016/01/12/7](https://lists.openwall.net/phc-discussions/2016/01/12/7): The salt should not be public. You lose defence against important metadata when using the salt in that an attacker with cache-timing can determine when a user logs in.\r\n\r\nPros:\r\n- Unique access pattern per user, whereas the cost parameters may be shared across all users in a database.\r\n- Ordinary salt sizes are less than or equal to the amount of data being hashed when hashing `spaceCost || timeCost || parallelism || parallelismIteration`, so there's typically no performance difference. You can't cache the hash state either way since the counter comes first. Then the salt length doesn't need to be encoded because the counter is fixed in length.\r\n\r\nCons:\r\n- Hard to optimise (compared to a fixed access pattern).\r\n- Might leak who has logged in.\r\n- Certain salts will lead to weaker access patterns.\r\n- The salt is leaked from a cache-timing attack when it shouldn't be public.\r\n\r\nOn reflection, I think removing the salt from the access pattern derivation is a bad idea since the attacker potentially only has to precompute it once for all users in a database. This feels like a bigger problem than the cons.\r\n\r\nI should've done this research prior to making the change really, but the mailing list has no method of searching and there are thousands of emails. It took hours to compile this list.\r\n\r\n---\r\nAs for `log2(spaceCost)` vs `LE32(spaceCost)`, I'm in two minds about this. The former is clearly more efficient, but it's more error prone and annoying to implement. There will be an existing API in standard libraries for `LE32()`, whereas the implementer has to do bit fiddling to grab something like 17 bits. Some values don't evenly divide either.\r\n\r\nBalloon was really designed as an algorithm that just calls other existing functions. That's why the performance isn't optimal.",
          "createdAt": "2024-08-03T15:56:32Z",
          "updatedAt": "2024-08-03T15:56:32Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Since there's been no reply for a month, I'm going to close this issue. I'll open some separate issues for some outstanding questions.",
          "createdAt": "2024-08-20T17:44:28Z",
          "updatedAt": "2024-08-20T17:44:28Z"
        }
      ]
    },
    {
      "number": 15,
      "id": "I_kwDOK_bi8M6NIim1",
      "title": "Rename the draft/algorithm to Balloon KDF (BKDF)",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/15",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "1. The current naming is confusing because there's Balloon and Balloon Hashing, with the latter implying Balloon isn't a KDF.\r\n2. The design has been modified, so it makes sense to have a different name. Otherwise, people may think this is the same algorithm as other versions/variants.\r\n3. BKDF follows the same naming as PBKDF2 and HKDF in that it's an acronym.",
      "createdAt": "2024-06-22T13:31:46Z",
      "updatedAt": "2024-07-13T09:37:12Z",
      "closedAt": "2024-07-13T09:37:12Z",
      "comments": []
    },
    {
      "number": 16,
      "id": "I_kwDOK_bi8M6NIjK_",
      "title": "Support using HMAC",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/16",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "`Hash(message)` can be replaced with `PRF(key, message)` to support the use of HMAC, which NIST would likely prefer. This then helps with only hashing the password once (discussed in #14) and adding a pepper (#7).\r\n\r\nHowever, to support ordinary hash functions still, prefix MAC can be used, padding the key to the block size to [induce a random IV](https://eprint.iacr.org/2010/264). When the hash function supports a key parameter (e.g., keyed BLAKE2), that can be used instead, which basically does the same thing internally.\r\n\r\nGeneration of the pseudorandom bytes won't use the same key to stay password-independent.",
      "createdAt": "2024-06-22T13:38:04Z",
      "updatedAt": "2024-06-22T14:11:31Z",
      "closedAt": "2024-06-22T14:11:31Z",
      "comments": []
    },
    {
      "number": 17,
      "id": "I_kwDOK_bi8M6NIj9X",
      "title": "Decide whether to keep parallelism",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/17",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "Argon2 and scrypt have a parallelism parameter, but it's [often not used](https://crypto.stackexchange.com/a/84085)/[recommended to stay at 1](https://github.com/Sc00bz/bscrypt?tab=readme-ov-file#settings) and [sometimes implemented serially](https://words.filippo.io/the-scrypt-parameters/). More parameters also means more confusion, like setting the cost parameter for bcrypt is much simpler than setting the parameters for memory-hard algorithms.\r\n\r\nOn the other hand, removing this parameter could affect interoperability, with people implementing parallelism themselves. It also doesn't add much code complexity.",
      "createdAt": "2024-06-22T13:46:47Z",
      "updatedAt": "2024-07-27T13:49:27Z",
      "closedAt": "2024-07-27T13:49:27Z",
      "comments": [
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "It should be kept.\r\n\r\n> [often not used](https://crypto.stackexchange.com/a/84085)\r\n\r\nThis Stack Exchange answer is wrong. Also parallelism on Argon2 is different than how Balloon's parallelism has been implemented. Argon2 splits memory into lanes and each lane can be run by a different thread. The threads sync four times an iteration. Balloon and scrypt run the base function multiple times in parallel and combine the output.\r\n\r\n> The parallelism was probably one reason why Argon2 won the Password Hashing Competition.\r\n\r\nWe understood that you could just call the base function multiple times in parallel and multiple submissions had parallelism built in. Maybe they mean the specific way Argon2 does parallelism.\r\n\r\n> As of that time, about 50 percent have quad-core processors in their computer. This would suggest to increase the parallelism factor to 8 (twice the number of cores), but for smartphones with a single core this would roughly quadruple the execution time. [...] If you assume that the vast majority of your users have at least two processor cores, you can set the parallelism factor to 4, if you are more careful, to 2.\r\n\r\nThis \"twice the number of cores\" thing is actually bad for Argon2 and originated from the RFC. You should never try to have parallelism greater than the number of cores. Doing twice makes Argon2 half as memory hard. Memory hardness of Argon2 is m/p vs \"m\" for Balloon and scrypt. Also the RFC has bad settings \"m=2 GiB, t=1 or m=64 MiB, t=3\". The first one does over 10x the work of the second. The second should be at least t=32 and really a lot more since it doesn't use as much memory. Accounting for reaching the attacker's max GPU memory bottleneck it should be like t=256 to make them closer.\r\n\r\n----\r\n\r\n> [recommended to stay at 1](https://github.com/Sc00bz/bscrypt?tab=readme-ov-file#settings)\r\n\r\nIt's a little nuanced (note it doesn't mention client side since I assumed most will do p=1, 2, 4, or cores. I guess I should fix it):\r\n* Server side hashing or \"I don't know\": p=1\r\n* Server side hashing with queuing system: p<=cores (test for best p)\r\n* Client side KDF: p=2, 4, 6, 8, or cores (are good choices and set max threads to ceiling(p/ceiling(p/cores)) basically you'd want to run 4 threads for p=8 instead of 6 threads on 6 core CPUs) \\*\r\n\r\n\"Cores\" meaning probably just performance cores but this is another can of worms. Also with scrypt you can use p as a time parameter.\r\n\r\n\\* Advice on parallelism is not for Argon2. For Argon2, set p=1, 2, maybe 4, or cores (set max threads to ceiling(p/ceiling(p/cores))). Since you want to be sure that p<=cores. Otherwise you give the attacker an advantage.\r\n\r\n----\r\n\r\n> [sometimes implemented serially](https://words.filippo.io/the-scrypt-parameters/)\r\n\r\nThat's only for scrypt because everyone uses the official code or rewrites that copying the lack threads. Argon2's [official code can spawn threads](https://github.com/P-H-C/phc-winner-argon2/blob/master/src/core.c#L291) and most uses have threads.",
          "createdAt": "2024-06-23T20:09:27Z",
          "updatedAt": "2024-06-23T20:09:27Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Thanks for the info. What I was getting at with the first link is that libsodium limits the parallelism to 1 for hashing. The parallelism recommendation can perhaps be reworded again, although it gets quite complicated to explain. I know only scrypt does it serially, and it would be good to keep it that way. I don't see any point promoting that for Balloon.\r\n\r\nAnd I forgot to say that I'm happy to keep parallelism. I don't think it complicates the code much. Other people may disagree/think fewer parameters is best.",
          "createdAt": "2024-06-27T20:17:07Z",
          "updatedAt": "2024-06-27T20:19:30Z"
        },
        {
          "author": "Sc00bz",
          "authorAssociation": "NONE",
          "body": "I thought that libsodium used threads for Argon2 (just look you're right). I thought PHP used libsodium for Argon2, but it looks like they use a different implementation because PHP's Argon2 uses threads.\r\n\r\nFor fewer parameters, you could define a simplified API function for Balloon:\r\n```\r\nballoon_hash(pw, m, t, p, extraSalts, pepper)\r\nballoon_verify(hash, pw, extraSalts, pepper)\r\nballoon_kdf(pw, salt, m, t, p, extraSalts, pepper)\r\n\r\nballoon_hashSimple(pw, cost)      // convert cost into m and t and calls balloon_hash(pw, m, t, 1, NULL, NULL)\r\nballoon_verifySimple(hash, pw)    //                               calls balloon_verify(hash, pw, NULL, NULL)\r\nballoon_kdfSimple(pw, salt, cost) // convert cost into m and t and calls balloon_kdf(pw, salt, m, t, 2, NULL, NULL)\r\n```\r\n\r\nFor \"convert cost into m and t\", you could do something like this (increasing cost by 1 increases the costs by a factor of about square root 2):\r\n```\r\nm = 1 << (cost / 2 + 14)\r\nt = 5 + 2 * (cost % 2) // 5 * 2^0.5 ~ 7.071\r\n```\r\nOr instead of cost have m and t. Or pick m to be 2 MiB for hashing and 8 MiB for KDF (or something) and instead of cost have t.",
          "createdAt": "2024-06-28T13:58:41Z",
          "updatedAt": "2024-06-28T13:58:41Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "I'm going to close this because I think it's sensible to keep parallelism. If anyone disagrees, feel free to reopen this issue.",
          "createdAt": "2024-07-27T13:49:27Z",
          "updatedAt": "2024-07-27T13:49:27Z"
        }
      ]
    },
    {
      "number": 18,
      "id": "I_kwDOK_bi8M6NRZSA",
      "title": "Support associated data",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/18",
      "state": "CLOSED",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "As discussed in #7:\r\n\r\n> I agree. But you might want to have \"extra salts\". This is useful for PAKEs where you include the user ID, server ID, OPRF salt (or salt), and local/secret salt (if there is one). This is just to avoid collisions for H(salt || userId || serverId) like H(salt || \"user1\" || \"server\") and H(salt || \"user\" || \"1server\") etc. It doesn't matter how you do it but the simplest is salt' = H(H(salt) || H(userId) || H(serverId) || ... ).\r\n\r\n> Yes, but having it as an option prevents the user of the API from needing to think about encoding lengths or other proper separation methods and maybe messing it up. Also it gives a common implemented method for this.\r\n\r\nIt adds a little complexity and not sure how to define the max lengths, like the max number of associated data parameters and the max length of each. The length encoding would also need to be changed to keep the loop code tidy. For example:\r\n\r\n```\r\nkey = PRF(key, LE64(password.Length) || password || LE64(salt.Length) || salt || LE64(associatedData1.Length) || associatedData1 || ...)\r\n```",
      "createdAt": "2024-06-24T12:38:47Z",
      "updatedAt": "2024-07-13T14:04:15Z",
      "closedAt": "2024-07-13T14:04:15Z",
      "comments": []
    },
    {
      "number": 19,
      "id": "I_kwDOK_bi8M6VUOH-",
      "title": "Non-Parallel Option",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/19",
      "state": "CLOSED",
      "author": "daxpedda",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "https://samuellucas.com/draft-lucas-bkdf/draft-lucas-bkdf.html#section-3-4:\r\n> Note that the internal function calls **MUST** be implemented in parallel, not serially. Otherwise, the `parallelism` parameter essentially becomes another `timeCost` parameter.\r\n\r\nIt is often desirable to provide a single-threaded implementation as well for platforms without multi-threading support, but this sentence would make this non-standard.\r\n\r\nI would propose one of the following:\r\n- Define an error that is returned if `parallelism` is not 1 but the implementation only supports single-threaded.\r\n- Add a separate single-threaded function, e.g. `BKDF_single` (terrible name ... I know).\r\n\r\nUnless this was intentional and the idea is that this algorithm should never be used without multi-threading, in which case I would add as much to the specification and also consider disallowing `parallelism` set to 1.",
      "createdAt": "2024-09-04T11:42:40Z",
      "updatedAt": "2024-09-08T10:45:30Z",
      "closedAt": "2024-09-08T10:45:30Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Thanks for looking at the draft/your feedback.\r\n\r\nI debated putting this for that reason. My thinking was an implementation would just support `parallelism` set to 1, like libsodium, in which case that can't be implemented in parallel. However, I think you're right that the wording should be changed to make that clear or this should be removed completely. I was just trying to avoid what happened with scrypt.\r\n\r\nAre you happy to be listed in the Acknowledgements section?",
          "createdAt": "2024-09-04T17:59:58Z",
          "updatedAt": "2024-09-04T17:59:58Z"
        },
        {
          "author": "daxpedda",
          "authorAssociation": "NONE",
          "body": "> Are you happy to be listed in the Acknowledgements section?\r\n\r\nSure!",
          "createdAt": "2024-09-07T16:34:33Z",
          "updatedAt": "2024-09-07T16:34:33Z"
        }
      ]
    },
    {
      "number": 20,
      "id": "I_kwDOK_bi8M6XdOPL",
      "title": "Salt-based memory accesses",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/20",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "I'm still unsure whether the memory access pattern should depend on the salt. This means a unique access pattern per user, which helps against attacks. However, there was concern on the [PHC mailing list](https://github.com/samuel-lucas6/phc-discussions) that a cache-timing attack may leak who has logged in (see #14).\r\n\r\nFrom the wording in the Balloon paper and comments on the PHC mailing list, it sounds like Balloon was the first algorithm to propose using the salt. Therefore, I'm not sure there's any literature on this.\r\n\r\nThe next best thing if the salt isn't used would be getting the user to specify a [context string](https://crypto.stackexchange.com/a/112587) (e.g., the website/application name) alongside the other parameters to make the access pattern unique to that service. However, this means yet another parameter for the user (in addition to the `associatedData` as well), and the length would need to be restricted for performance.",
      "createdAt": "2024-09-22T11:02:42Z",
      "updatedAt": "2024-11-16T12:37:18Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "I too am concerned about possible side-channel leaks of the salt being used, and firstly I would like to explain my use-case:  as per the discussion I had with @samuel-lucas6 on <https://github.com/samuel-lucas6/Cahir/issues/1#issuecomment-2478233358>, sometimes the \"salt\" isn't independent of the password (or other input parameters), thus should be treated with the same care as the actual \"password\".\r\n\r\nHowever, perhaps in my use-case I kind of miss-use the \"salt\", and perhaps the \"salt\" argument to any derivation function should be treated exactly as the general expectation:  namely as a publicly known value that holds nothing secret and has no security impact if found out.\r\n\r\n----\r\n\r\nThus, potential solutions to the \"should the algorithm be independent on **both the salt and the password**\" problem might be the following:\r\n\r\n(A) As @samuel-lucas6 suggested, having a constant \"context string\" (or \"customization string\"), perhaps mashed together with some constant-ish user arguments (i.e. \"associated data\", e.g. file-name, site name, etc.).\r\n\r\nHowever, and assuming most of the time the same context string is used (for example if the attacker targets a specific application), and the same default \"associated data\" is used, then the attacker has a deterministic flow through the hashes, thus perhaps he can get some advantages by employing ASICS or other hardware-based implementations;\r\n\r\n(B) Perhaps the developer should take the password and the salt, and generate a new pair that can be then used as input for the algorithm, like for example:\r\n~~~~\r\nlet _input_password, _input_salt = ...\r\nlet _hashed_password = hash (\"balloon-password-hashed\", _input_password)\r\nlet _hashed_salt = hash (\"balloon-salt-hashed\", _input_salt)\r\nlet _intermediate_key = keyed_hash (_hashed_salt, _hashed_password)\r\nlet _balloon_password = hash (\"balloon-password\", _intermediate_key)\r\nlet _balloon_salt = hash (\"balloon-salt\", _intermediate_key)\r\n~~~~\r\n\r\nObservations:\r\n* `hash` and `keyed_hash` are the same as the hash function used in the rest of the algorithm;  (if there isn't a \"keyed\" variant, then HMAC can be used);\r\n* the intermediary hash step might seem superfluous (i.e. computing `_hashed_*`), but some keyed hash algorithms might allow only fixed size inputs;  (for example Blake3's variant of keyed hash expects a 32 bytes, 256 bits, input which is exactly the default output of the function;)\r\n* given the original algorithm description, the `_balloon_password` could in fact be used directly as the `b[0]` value (which is the single place where the password is used);\r\n\r\nThus, even if the internal salt or password is leaked, they are in fact hashes of the actual inputs, thus a separate brute-force attack has to be undertaken.\r\n\r\n----\r\n\r\nOn a second thought, given the original paper description where the salt is used to choose the dependent blocks:\r\n~~~~\r\nint other = to_int(hash(cnt++, salt, idx_block)) mod s_cost\r\n~~~~\r\n\r\nGiven it is hashed, the side-channel leaks would be in fact about the hash of the salt, which furthermore reduced in entropy by the modulo `s_cost`.\r\n\r\nThus, perhaps in real terms, there is no leak at all, and just a theoretical problem?  (I don't know, I'm not a cryptographer.)\r\n",
          "createdAt": "2024-11-15T15:50:39Z",
          "updatedAt": "2024-11-15T15:50:39Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> However, and assuming most of the time the same context string is used (for example if the attacker targets a specific application), and the same default \"associated data\" is used, then the attacker has a deterministic flow through the hashes, thus perhaps he can get some advantages by employing ASICS or other hardware-based implementations;\r\n\r\nThis is the problem with data-independent schemes. Having a context parameter should be better than Argon2i and is I think the best you can do without relying on the salt or changing the access pattern each time but somehow resulting in the same output, which I think there's a paper for that I haven't read but would be a lot more complicated. Someone I spoke to also suggested relying on the salt wouldn't help much anyway.\r\n\r\n> Thus, even if the internal salt or password is leaked, they are in fact hashes of the actual inputs, thus a separate brute-force attack has to be undertaken.\r\n\r\nThis is quite confusing to reason about. It's a lot of hashing, and the only thing that helps is if the salt is unknown. But what's the goal here? The scheme is already password-independent.\r\n\r\n> Thus, perhaps in real terms, there is no leak at all, and just a theoretical problem? (I don't know, I'm not a cryptographer.)\r\n\r\nI'm obviously not a cryptographer either, and this topic hasn't been properly discussed. However, the people I've spoken to have said using the salt is a bad idea, which would explain why no algorithm besides Balloon (as far as I know) uses the salt.",
          "createdAt": "2024-11-16T12:37:17Z",
          "updatedAt": "2024-11-16T12:37:17Z"
        }
      ]
    },
    {
      "number": 21,
      "id": "I_kwDOK_bi8M6XdPN9",
      "title": "Hybrid memory access pattern",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/21",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "There's a general dislike of password-independent access patterns because they're weaker and slower than password-dependent. However, password-dependent access patterns mean side-channel attacks leak information about the password. Therefore, a hybrid access pattern seems like the best approach to get some of the benefits of both. This is supported by Argon2id's adoption compared to Argon2i and Argon2d.\r\n\r\nThe downsides are that you lose proper cache-timing attack resistance and implementation becomes slightly more complicated. But the algorithm will probably be viewed more favourably if full password-independent access is abandoned.",
      "createdAt": "2024-09-22T11:13:06Z",
      "updatedAt": "2024-09-22T11:13:06Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 22,
      "id": "I_kwDOK_bi8M6XdQH9",
      "title": "spaceCost and timeCost compared to other algorithms",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/22",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "`timeCost` is a misleading name because increasing `spaceCost` also increases the delay. Then `spaceCost` is the number of blocks when it would be more intuitive if the memory size (e.g., in bytes or KiB) was specified. This saves the user having to compute the number of blocks from their target memory size and the hash function output length. Because the weird thing at the moment is that you can have the same `spaceCost` with two different hash functions and you'll get a different memory size.\r\n\r\nThe problem is what to call these (e.g., `iterations` and `memorySize` perhaps) and how changing `spaceCost` affects the domain separation.",
      "createdAt": "2024-09-22T11:23:01Z",
      "updatedAt": "2024-11-16T13:03:50Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "With regard to `timeCost` the original paper actually calls it everywhere as \"rounds\".\r\n\r\nAnd, at least given the cryptography context, I think its more clearer to anyone what \"rounds\" means.  (Or even \"iterations\", but I think that the whole literature uses the word \"round\".)\r\n\r\nOn the other side, calling something \"time\" might be misleading, because as with `spaceCost`, it doesn't actually translate to a physical unit, but instead the actual \"time\" depends on the `spaceCost`, the efficiency of the chosen hash, and hardware performance of the machine running the code.\r\n\r\n----\r\n\r\nWith regard to `spaceCost`, I personally think of it as the \"width\" of the process.\r\n\r\nHowever, with regard to the proposal to be expressed in MiB (or anything directly translatable into memory), is perhaps problematic because:\r\n* given that `timeCost` is \"logical\", if `spaceCost` is physical, there is a mismatch between the two;  (they should be perhaps both physical or both logical;)\r\n* given that the `timeCost` and `spaceCost` directly impact the number of hashes computed, they are perhaps less about \"memory\" and more about \"total hash iterations\";\r\n\r\n----\r\n\r\nOr, form another perspective, there could be two functions standardized:\r\n* a generic one, that takes the generic hash function as input, and the \"logical\" `rouds` / `width` arguments;\r\n* a set of standard instantiations of the generic function, with concrete hashes (say SHA3-512, Blake3(-256), etc.), which should take `memoryCost` in terms of MiB (and deduce the `width` automatically) and `timeCost` which should be tweaked in accordance to the speed or complexity of the hash function, so that keeping `memoryCost` and `timeCost` constant, and varying the standard instantiation, the total resource consumption (on a \"standard computer\") should be \"kind of the same\";\r\n\r\n----\r\n\r\nAnd finally, how about a \"radical\" approach (which seems to be the current \"best practice\") of providing a few pre-defined levels (or purposes), so that users don't shoot themselves in the foot:\r\n* \"authentication\";  tailored for online authentication, where the total time should be under 100ms on an \"average modile\";  (or whatever the current UX standards are today;)\r\n* \"throttling\";  for example when the hard-hash-function is used as a work-factor to thwart attackers and DoS;  (the focus is not on cryptographic strength, but on wasting the attacker's time and resources;)\r\n* \"NIST-level-1\";  as per <https://csrc.nist.gov/projects/post-quantum-cryptography/post-quantum-cryptography-standardization/evaluation-criteria/security-(evaluation-criteria)> -- the amount of work needed to brute-force a password at this level, should \"require computational resources comparable to or greater than those required for key search on a block cipher with a 128-bit key (e.g. AES128)>\";\r\n* \"NIST-level-x\" (2 to 5) -- similar as above;  (perhaps only level 3 and 5 which are defined in terms of AES, the others being defined in terms of SHA;)\r\n",
          "createdAt": "2024-11-15T17:06:35Z",
          "updatedAt": "2024-11-15T17:06:35Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> With regard to timeCost the original paper actually calls it everywhere as \"rounds\".\r\n\r\nThe pseudocode and reference implementation use `t_cost` for time cost though.\r\n\r\n> And, at least given the cryptography context, I think its more clearer to anyone what \"rounds\" means. (Or even \"iterations\", but I think that the whole literature uses the word \"round\".)\r\n\r\nI like iterations because it matches PBKDF2. Argon2 calls it passes.\r\n\r\n> On the other side, calling something \"time\" might be misleading, because as with spaceCost, it doesn't actually translate to a physical unit, but instead the actual \"time\" depends on the spaceCost, the efficiency of the chosen hash, and hardware performance of the machine running the code.\r\n\r\nI definitely don't like `timeCost` and `spaceCost`.\r\n\r\n> However, with regard to the proposal to be expressed in MiB (or anything directly translatable into memory), is perhaps problematic because:\r\n\r\nThe issue I realised with having KiB or MiB for the memory is that it doesn't work well with the power of 2 to avoid modulo bias, so I might have to leave the memory parameter as blocks.\r\n\r\n> And finally, how about a \"radical\" approach (which seems to be the current \"best practice\") of providing a few pre-defined levels (or purposes), so that users don't shoot themselves in the foot\r\n\r\nThis isn't a good idea because of the performance difference depending on the implementation/device and how the parameters should be adjusted over time.",
          "createdAt": "2024-11-16T13:03:48Z",
          "updatedAt": "2024-11-16T13:03:48Z"
        }
      ]
    },
    {
      "number": 23,
      "id": "I_kwDOK_bi8M6XdRKa",
      "title": "Taking from the buffer for key derivation",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/23",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "An alternative to the current KDF approach mentioned by Henry is to take bytes from the final buffer. If `length` is less than the buffer size, you take from the final buffer (e.g., midway through to the end). If it's larger than the buffer size, you would additionally do further mixing of the buffer to retrieve the remaining bytes. Because of `parallelism`, you would then XOR these (potentially larger than a block) outputs to produce the derived key material for the user.\r\n\r\nThis apparently has better memory hardness because you have to keep more data in memory until the end. It also has better performance for outputs smaller than the buffer size. However, there's a performance penalty for larger outputs since it requires more mixing, which is more expensive than a regular KDF. It also sounds more annoying to implement due to the potential extra mixing.",
      "createdAt": "2024-09-22T11:34:28Z",
      "updatedAt": "2024-11-17T12:28:20Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "Given that the hash algorithm is expressed in terms of a hash function, why not just do the following:\r\n* the final output is the hash of the entire memory (i.e. the blocks) with the chosen hash function;\r\n* the size of the output is whatever the chosen hash function yields; or,\r\n* if the hash function offers variable outputs (like Blake3), then use that feature by passing the desired output length to the underlying hash function;\r\n\r\nThis proposal has a few nice properties:\r\n* it keeps the overall algorithm simple;  (no password extension at the end;)\r\n* it doesn't hide from the user the \"quality\" of the underlying hash function;  (i.e. the user wants 1024 bytes of output, but he has chosen SHA2 which actually only offers 192 bits of entropy);\r\n",
          "createdAt": "2024-11-15T17:12:25Z",
          "updatedAt": "2024-11-15T17:12:25Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> the final output is the hash of the entire memory (i.e. the blocks) with the chosen hash function;\r\n\r\nThis would be very expensive and is unnecessary.\r\n\r\n> the size of the output is whatever the chosen hash function yields; or,\r\n> if the hash function offers variable outputs (like Blake3), then use that feature by passing the desired output length to the underlying hash function;\r\n\r\nIt would be nice to use XOF functionality but this isn't possible because of supporting non-XOFs. Limiting the output to the hash function output length means it loses KDF functionality, a common feature in existing algorithms.\r\n\r\n> it doesn't hide from the user the \"quality\" of the underlying hash function; (i.e. the user wants 1024 bytes of output, but he has chosen SHA2 which actually only offers 192 bits of entropy);\r\n\r\nYou could make this kind of argument about any KDF though.",
          "createdAt": "2024-11-16T19:27:58Z",
          "updatedAt": "2024-11-16T19:27:58Z"
        },
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": ">> the final output is the hash of the entire memory (i.e. the blocks) with the chosen hash function;\r\n>\r\n> This would be very expensive and is unnecessary.\r\n\r\nExpensive compared to what?\r\n\r\nIs cost should be less than 1/4 the cost of an entire round.  (In a round all the blocks are sequencially hashed, plus for each block we hash three others, thus for each round, we hash 4 times the entire memory, although in different steps.)\r\n\r\nUnnecessary, perhaps, but I don't think it can hurt the overall security...\r\n",
          "createdAt": "2024-11-16T19:34:05Z",
          "updatedAt": "2024-11-16T19:34:05Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> Expensive compared to what?\r\n\r\nYou'd end up hashing MiBs to GiBs and multiple times if parallelism is used. By worsening performance, you harm security because the parameters have to be reduced for the same delay.\r\n\r\nThe design is inspired by existing designs I've looked at, and using a KDF at the end is done by Argon2/scrypt and some other schemes in the PHC. It's intuitive and relatively cheap.",
          "createdAt": "2024-11-17T12:28:19Z",
          "updatedAt": "2024-11-17T12:28:19Z"
        }
      ]
    },
    {
      "number": 24,
      "id": "I_kwDOK_bi8M6XdbSv",
      "title": "Design rationale",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/24",
      "state": "OPEN",
      "author": "samuel-lucas6",
      "authorAssociation": "OWNER",
      "assignees": [],
      "labels": [],
      "body": "There should either be a section on the design rationale or this should be explained in a [paper](https://eprint.iacr.org/) that gets linked. A paper would be more academic and advertise the algorithm to get feedback but would require duplicating work on the draft and probably doing a more thorough literature review.",
      "createdAt": "2024-09-22T13:08:05Z",
      "updatedAt": "2024-09-22T13:08:05Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 25,
      "id": "I_kwDOK_bi8M6eti4V",
      "title": "Mismatch between how the draft handles dependent blocks, and how the paper describes it",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/25",
      "state": "CLOSED",
      "author": "cipriancraciun",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Looking at the initial paper, it describes the following algorithm for choosing the \"dependent blocks\":\r\n~~~~\r\nfor i from 0 to delta-1:\r\n    block_t idx_block = ints_to_block(t, m, i)\r\n    int other = to_int(hash(cnt++, salt, idx_block)) mod s_cost\r\n    buf[m] = hash(cnt++, buf[m], buf[other])\r\n~~~~\r\n\r\nLooking at the current draft, it gives the following steps:\r\n~~~~\r\npseudorandom = ByteArray(0)\r\nreps = (spaceCost * timeCost * 3) / (HASH_LEN / 4)\r\nfor i = 0 to reps - 1\r\n    pseudorandom = pseudorandom || PRF(emptyKey, LE32(VERSION) || personalization || LE32(spaceCost) || LE32(timeCost) || LE32(parallelism) || LE32(iteration) || LE64(counter++))\r\n\r\n[...]\r\n\r\n        other1 = ReadLE32(pseudorandom.Slice(offset, 4)) % spaceCost\r\n        other2 = ReadLE32(pseudorandom.Slice(offset + 4, 4)) % spaceCost\r\n        other3 = ReadLE32(pseudorandom.Slice(offset + 8, 4)) % spaceCost\r\n        buffer[m] = PRF(key, previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3] || LE64(counter++))\r\n        previous = buffer[m]\r\n        offset = offset + 12\r\n~~~~\r\n\r\nThese two, not only aren't similar, I don't think they even have the same properties.\r\n\r\nFor example:\r\n* in the initial paper, the choice of each dependent block depends on the current block (i.e. `buffer[m]`;  meanwhile in the draft, the order seems to be completely independent of the current block;\r\n* in the initial paper, each dependent block depends on the contents of the previously chosen dependent block (i.e. there is a sequential process);  in the current draft the three are independent of each other;\r\n* in the initial paper, if one notes the indices of the blocks throughout the execution, they are most likely random;  meanwhile in the current draft, they are completely predictable parametrized only by generally constant parameters like `version`, `personalization`, `spaceCost`, etc. (i.e. the inputs used to generate the `pseudorandom` vector).\r\n\r\nThus, I would say these changes, that greatly simplify the implementation of the round, perhaps greatly impact the security guarantees provided by the initial paper?\r\n",
      "createdAt": "2024-11-15T17:59:50Z",
      "updatedAt": "2024-11-16T16:22:49Z",
      "closedAt": "2024-11-16T16:22:49Z",
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "These changes were done for performance rather than simplicity since hashing like that in the original barely uses any of each hash output when computing the memory accesses, and performance is everything with password hashing. Even with these types of changes, this is not a performant algorithm unfortunately.\r\n\r\nIn both cases, the `other` values can be precomputed, so the difference is:\r\n\r\n```\r\nbuf[m] = hash(cnt++, buf[m], buf[other1])\r\nbuf[m] = hash(cnt++, buf[m], buf[other2])\r\nbuf[m] = hash(cnt++, buf[m], buf[other3])\r\n```\r\n\r\nvs\r\n\r\n```\r\nbuffer[m] = PRF(key, previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3] || LE64(counter++))\r\n```\r\n\r\nIn both cases, the current block depends on the current block and 3 other blocks, and you can't process `other2` before `other1` and `other3` before `other2`.\r\n\r\nI think this was just a consequence of the pseudocode loop. The textual description in the paper doesn't mention dependency between current blocks, and the reference implementation [doesn't](https://github.com/henrycg/balloon/blob/master/libballoon/hash_state.c#L165) appear to care about this.",
          "createdAt": "2024-11-16T15:17:34Z",
          "updatedAt": "2024-11-16T15:17:34Z"
        },
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "> In both cases, the other values can be precomputed, so the difference is: [...]\r\n\r\nThis is partially true, and now I see your reasoning, but on closer inspection of the paper I also see my reasoning:\r\n* indeed, `other{1..3}` can be precomputed at each iteration, because it doesn't depend on `buf[m]` (my mistake here);\r\n* however, there is one in `s_const` chance that one of the `otherX` variables is `m`, thus there is a chance where the the two algorithms aren't actually the same;  (i.e. `buf[m]` might depend on its \"new self\" at one of the previous `other` steps;)\r\n\r\n----\r\n\r\nHowever, the way the current draft is written, is quite different than the paper when it comes to the PRF usage.  (I've opened ticket #26 about this.)\r\n",
          "createdAt": "2024-11-16T16:22:49Z",
          "updatedAt": "2024-11-16T16:22:49Z"
        }
      ]
    },
    {
      "number": 26,
      "id": "I_kwDOK_bi8M6e0nVr",
      "title": "Usage of the `PRF` (in the draft) and `hash` (in the original paper) diverges in non trivial ways",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/issues/26",
      "state": "OPEN",
      "author": "cipriancraciun",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "If one looks at the original paper, and how the `hash` function (`PRF` in our case) is used:\r\n* `buf[0] = hash(cnt++, passwd, salt)`\r\n* `buf[m] = hash(cnt++, buf[m-1])`\r\n* `buf[m] = hash(cnt++, prev, buf[m])`\r\n* `int other = to_int(hash(cnt++, salt, idx_block)) mod s_cost` (where `block_t idx_block = ints_to_block(t, m, i)`)\r\n* `buf[m] = hash(cnt++, buf[m], buf[other])`\r\n\r\nOne (with the exception of the first usage, and perhaps partially the second one), could conclude that the signature of `hash` is similar to `block_t hash (counter:usize, block_1:block_t, block_2:block_t)`, i.e. it always takes a counter and two blocks, and compresses them into a single block.\r\n\r\nIn fact, the paper states:\r\n> Since H maps blocks of 2k bits down to blocks of k bits, we sometimes refer to H as a cryptographic compression function.\r\n\r\n(And personally, I find the simplicity of the initial Balloon algorithm, and the simplicity of its building blocks, namely the single one `hash`, quite appealing.)\r\n\r\n----\r\n\r\nHowever, the draft has the following usages of `PRF`:\r\n* `key = PRF(key, password || salt || personalization || associatedData || LE32(pepper.Length) || LE32(password.Length) || LE32(salt.Length) || LE32(personalization.Length) || LE32(associatedData.Length))`\r\n* `previous = PRF(key, previous || UTF8(\"bkdf\") || LE32(counter++))`\r\n* `pseudorandom = pseudorandom || PRF(emptyKey, LE32(VERSION) || personalization || LE32(spaceCost) || LE32(timeCost) || LE32(parallelism) || LE32(iteration) || LE64(counter++))`\r\n* `buffer[0] = PRF(key, LE32(VERSION) || LE32(spaceCost) || LE32(timeCost) || LE32(parallelism) || LE32(iteration) || LE64(counter++))`\r\n* `buffer[m] = PRF(key, buffer[m - 1] || LE64(counter++))`\r\n* `buffer[m] = PRF(key, previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3] || LE64(counter++))`\r\n\r\nNamely:\r\n* it introduces the concept of `key`, which doesn't exist in the initial algorithm;\r\n* sometimes there is a counter, sometimes there isn't one;\r\n* sometimes the `VERSION` is included, sometimes not;\r\n* sometimes the order of included parameters is one way, sometimes it is not;\r\n\r\n----\r\n\r\nDoesn't it seem that the draft drifts quite a bit from the original paper?\r\n\r\nI'm not saying it's wrong to have a different take, but I do see two problems:\r\n* the major one being that the paper gives some proofs for what was specified in the paper, meanwhile the draft makes some changes that I'm not sure they are equivalent;\r\n* the way `PRF` is used (with a lot of inline canonicalization) is error prone to this types of problems;\r\n* the way the inputs of the `PRF` are computed, might have performance impacts (as compared to the initial version, more in a different paragraph);\r\n\r\n----\r\n\r\nMany hash functions, especially the \"modern\" ones (I don't know about Blake, but for example Xxh3, which although is not a cryptographic hash function) might have optimized assembly implementations when they work on fixed blocks.\r\n\r\nThus, from this point of view, perhaps the original paper might yield a performance boost (because it uses fixed inputs) that the current draft `PRF` usage that has to concatenate a lot of data.\r\n",
      "createdAt": "2024-11-16T16:22:06Z",
      "updatedAt": "2024-11-17T12:50:40Z",
      "closedAt": null,
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> (And personally, I find the simplicity of the initial Balloon algorithm, and the simplicity of its building blocks, namely the single one hash, quite appealing.)\r\n\r\nThere are some benefits to using an unkeyed algorithm. The reason this was changed was purely to allow HMAC for NIST compliance since that's closer to PBKDF2. By supporting a keyed algorithm, you can also support unkeyed algorithms, whereas this isn't the case the other way around. The trouble is trying to support all these different algorithms is messy because of the design differences.\r\n\r\n> sometimes there is a counter, sometimes there isn't one;\r\n\r\nThere's a counter in most places. There's no need for a counter when deriving the PRF key because it's a single output and basically HKDF-Extract. You could get rid of the counter for the final key derivation as well, but I think it's better to keep one, aligning with HKDF-Expand.\r\n\r\n> sometimes the VERSION is included, sometimes not;\r\n\r\nWhere else do you think this should be included? When deriving the PRF key or for the output?\r\n\r\n> sometimes the order of included parameters is one way, sometimes it is not;\r\n\r\nI'm not sure what you mean by this.\r\n\r\n> the major one being that the paper gives some proofs for what was specified in the paper, meanwhile the draft makes some changes that I'm not sure they are equivalent;\r\n\r\nThe fundamental approach to memory hardness should be the same. If that's the case, you can think of the rest more as cosmetic changes that have some pros and cons.\r\n\r\n> the way PRF is used (with a lot of inline canonicalization) is error prone to this types of problems;\r\n\r\nWhat type of problem? This type of canonicalization is common with KDFs/MACs. If something is fixed length, you don't need to encode the length. Encoding the length of fixed length parameters is kind of like encoding the length of the length encodings.\r\n\r\n> Thus, from this point of view, perhaps the original paper might yield a performance boost (because it uses fixed inputs) that the current draft PRF usage that has to concatenate a lot of data.\r\n\r\nSome of the concatenation is a one off cost or can be cached. You can generally figure out how many blocks there are going to be rather than it being a variable number. The `personalization` is the main thing that's interfered with that, but it can be cached. I have debated whether to prehash everything but the counter and use that as the PRF key for the pseudorandom bytes derivation. I'm not convinced that's worth it though.\r\n\r\nI would think more calls to the hash functions is slower, but I haven't implemented this version of the draft to do benchmarks.",
          "createdAt": "2024-11-16T17:37:56Z",
          "updatedAt": "2024-11-16T17:37:56Z"
        },
        {
          "author": "cipriancraciun",
          "authorAssociation": "NONE",
          "body": "Citing all the places where `PRF` is used:\r\n~~~~\r\nkey = PRF(key, password || salt || personalization || associatedData || LE32(pepper.Length) || LE32(password.Length) || LE32(salt.Length) || LE32(personalization.Length) || LE32(associatedData.Length))\r\n## uses \"parameters\" (i.e. salt, persolalization, associated data, etc.)\r\n## misses the VERSION, timeCost, parallelism, etc.\r\n\r\npseudorandom = pseudorandom || PRF(emptyKey, LE32(VERSION) || personalization || LE32(spaceCost) || LE32(timeCost) || LE32(parallelism) || LE32(iteration) || LE64(counter++))\r\n## uses VERSION\r\n## misses cost, parallelism, etc.\r\n\r\nbuffer[0] = PRF(key, LE32(VERSION) || LE32(spaceCost) || LE32(timeCost) || LE32(parallelism) || LE32(iteration) || LE64(counter++))\r\n## uses VERSION, uses cost\r\n## misses personalization\r\n~~~~\r\n\r\n>> sometimes the VERSION is included, sometimes not;\r\n>\r\n>> sometimes the order of included parameters is one way, sometimes it is not;\r\n\r\nPersonally, I would just take all possible context that is either public (personalization, version, etc.) or mostly constant (costs, parallelism, etc.) and just just mix them into a single value that is to be used wherever \"parameters\" (or part of the parameters) might be needed.\r\n\r\nFor example, rewriting the above:\r\n~~~~\r\ncontext = PRF(emptyKey,\r\n    salt || LE32(salt.Length)      ## let's assume it's public\r\n || pepper || LE32(pepper.Length)  ## let's also assume it's public\r\n || associatedData || LE32(associatedData.Length)\r\n || personalization || LE32(personalization.Length)\r\n || LE32(VERSION)\r\n || LE32(parallelism)\r\n || LE32(timeCost)\r\n || LE32(spaceCost)\r\n)\r\n \r\n\r\nkey = PRF(key, context || password)\r\n\r\npseudorandom = pseudorandom\r\n         || PRF(emptyKey, context || LE32(iteration) || LE64(counter++))\r\nbuffer[0] = PRF(key     , context || LE32(iteration) || LE64(counter++))\r\n~~~~\r\n\r\nSee how \"nice\" the PRF usage looks?\r\n* there is some \"key\";\r\n* the first input is some \"context\";\r\n* then follows the data;\r\n\r\n----\r\n\r\n\r\n\r\n>> the way `PRF` is used (with a lot of inline canonicalization) is error prone to this types of problems;\r\n>\r\n> What type of problem? This type of canonicalization is common with KDFs/MACs. If something is fixed length, you don't need to encode the length. Encoding the length of fixed length parameters is kind of like encoding the length of the length encodings.\r\n\r\nIndeed canonicalization is common, however the usual flavour of canonicalization is either:\r\n* `length(data_x) || data_x || ...`\r\n* `data_x || length(data_x) || ...`\r\n* (this was even standardized by NIST as `TupleHash` in <https://csrc.nist.gov/pubs/sp/800/185/final>;)\r\n\r\nMeanwhile the current draft puts the lengths at the end, thus it's error prone to implement correctly.  (Perhaps it doesn't break the cryptography, but it does offer enough opportunities to mix things and have broken outputs that don't match the test vectors.)\r\n\r\n----\r\n\r\n> I would think more calls to the hash functions is slower, but I haven't implemented this version of the draft to do benchmarks.\r\n\r\nLooking in the Blake3 paper there is the following graph:\r\n![image](https://github.com/user-attachments/assets/8e1f5181-e98c-4f72-a868-531fef136f23)\r\n\r\nAs you can see, for small hashes (although here is the full hash computation, but perhaps it also extends to discrete individual `update(some_data)` calls), there is a smal cost for 64 bytes, then it goes up in between 64-128, then goes down for 128, up again until 256 bytes, and then there is a plateou in between 256 and 2K (perhaps some CPU pipelining or branch-prediction kicks-in).\r\n\r\nThus, assuming one uses Blake3 or another algorithm that has a similar behaviour (strangely enough also SHA2 follows a similar pattern), if the PRF is used as I've proposed above (plus the other two usages), i.e.:\r\n~~~~\r\nPRF(key, context || LE32(iteration) || LE64(counter++))\r\n## let's assume we pad iteration and counter to fit in 16 bytes each\r\n=> PRF(key, 32 bytes || 32 bytes)\r\n=> PRF(key, 64 bytes)\r\n\r\nbuffer[m] = PRF(key, buffer[m - 1] || LE64(counter++))\r\n## let's assume we pad counter to 16 bytes, and we imagine we have an iteration of 0\r\n=> PRF(key, 32 bytes || 32 bytes)\r\n=> PRF(key, 64 bytes)\r\n\r\nbuffer[m] = PRF(key, previous || buffer[m] || buffer[other1] || buffer[other2] || buffer[other3] || LE64(counter++))\r\n## let's also pad counter to 16 bytes, plus iteration of 0\r\n=> PRF(key, 32 bytes || x6)\r\n=> PRF(key, 192 bytes)\r\n~~~~\r\n\r\nWe get almost the optimal behaviour for Blake3.\r\n",
          "createdAt": "2024-11-16T19:29:58Z",
          "updatedAt": "2024-11-16T19:29:58Z"
        },
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "> misses the VERSION, timeCost, parallelism, etc.\r\n\r\nThe parallelism loop iteration can't be included in the key derivation since the key is static.\r\n\r\n> misses cost, parallelism, etc.\r\n\r\nThose are included when computing the pseudorandom bytes.\r\n\r\n> misses personalization\r\n\r\nThis is unnecessary if it's in the key.\r\n\r\n> Personally, I would just take all possible context that is either public (personalization, version, etc.) or mostly constant (costs, parallelism, etc.) and just just mix them into a single value that is to be used wherever \"parameters\" (or part of the parameters) might be needed.\r\n\r\nIt's unfortunately not that simple because you don't want things like the salt/pepper/associated data in the pseudorandom bytes derivation. There's also no need to process those multiple times.\r\n\r\nYou could do it for the VERSION, personalization, parallelism, timeCost, spaceCost, and parallelism iteration, but it's pretty ugly because you need to use an empty key. You also end up potentially hashing more data because a hash is larger than those encoded parameters.\r\n\r\nBut what you're talking about is what I was thinking about with prehashing the personalization so the pseudorandom bytes input fits into a block (that isn't guaranteed if the personalization length is variable).\r\n\r\n> Meanwhile the current draft puts the lengths at the end, thus it's error prone to implement correctly. (Perhaps it doesn't break the cryptography, but it does offer enough opportunities to mix things and have broken outputs that don't match the test vectors.)\r\n\r\nIt's also normal to put the lengths at the end. For example, see the ChaCha20-Poly1305 [RFC](https://www.rfc-editor.org/rfc/rfc8439#section-2.8.1). It allows you to process inputs without knowing their length in advance, which admittedly isn't relevant here. If this is done incorrectly, the test vectors shouldn't pass.\r\n\r\n> Looking in the Blake3 paper there is the following graph\r\n\r\nYes, I've seen that graph. The question is how do repeated small calls do vs one slightly longer call.\r\n\r\nI definitely don't want to include padding because it depends on the algorithm and that gets messy.",
          "createdAt": "2024-11-17T12:50:39Z",
          "updatedAt": "2024-11-17T12:50:39Z"
        }
      ]
    }
  ],
  "pulls": [
    {
      "number": 11,
      "id": "PR_kwDOK_bi8M5nra-D",
      "title": "Add implementations for Dart, Julia, Kotlin, Ruby",
      "url": "https://github.com/samuel-lucas6/draft-lucas-bkdf/pull/11",
      "state": "MERGED",
      "author": "elliotwutingfeng",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "I've implemented Balloon in Dart, Julia, Kotlin, and Ruby. Mostly as programming exercises to familiarise myself with said languages. They are all direct ports of [nachonavarro/balloon-hashing](https://github.com/nachonavarro/balloon-hashing). Feel free to include them in the README.",
      "createdAt": "2024-02-22T18:11:59Z",
      "updatedAt": "2024-02-23T18:41:17Z",
      "baseRepository": "samuel-lucas6/draft-lucas-bkdf",
      "baseRefName": "main",
      "baseRefOid": "de520e78f3fb57cbbbb5b150d9a5d39227c74f21",
      "headRepository": "elliotwutingfeng/draft-lucas-balloon-hashing",
      "headRefName": "patch-1",
      "headRefOid": "2b8021f9f66ad95136376375d3ff6b11c3aaf59c",
      "closedAt": "2024-02-23T18:33:58Z",
      "mergedAt": "2024-02-23T18:33:58Z",
      "mergedBy": "samuel-lucas6",
      "mergeCommit": {
        "oid": "aebec5f69d1fc31108afa098a5152143d2bab61b"
      },
      "comments": [
        {
          "author": "samuel-lucas6",
          "authorAssociation": "OWNER",
          "body": "Awesome, sorry I missed them.\r\n\r\nPlease keep an eye on this repository because there will eventually be breaking changes to the algorithm.",
          "createdAt": "2024-02-23T18:33:27Z",
          "updatedAt": "2024-02-23T18:33:27Z"
        }
      ],
      "reviews": []
    }
  ]
}